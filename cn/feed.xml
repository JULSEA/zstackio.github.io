<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>ZStack</title>
    <description>ZStack is open source IaaS software managing resources of compute, storage, networking throughout a datacenter all by APIs.</description>
    <link>http://zstack.org/</link>
    <atom:link href="http://zstack.org/feed.xml" rel="self" type="application/rss+xml" />
    <pubDate>Tue, 01 Sep 2015 15:56:50 +0800</pubDate>
    <lastBuildDate>Tue, 01 Sep 2015 15:56:50 +0800</lastBuildDate>
    <generator>Jekyll v2.5.3</generator>
    
      <item>
        <title>ZStack登录台湾——第一个繁体中文网站 zstack.tw 上线</title>
        <description>&lt;p&gt;近日，来自台湾的&lt;strong&gt;百原科技公司&lt;/strong&gt;推出了第一个&lt;strong&gt;ZStack繁体中文网站&lt;/strong&gt; &lt;code&gt;http://zstack.tw&lt;/code&gt; 。
该网站是继ZStack社区官网之后，世界上第二个以ZStack为主题的网站。
目前虽然该网站的主要内容来自于ZStack官网，但是通过百原工程师对网站内容进行繁体中文的加工，
辅以修改了部分IT用词之后，使得该网站更符合台、港、澳以及部分海外地区中文用户的阅读使用习惯，大大方便他们学习和使用ZStack。&lt;/p&gt;

&lt;p&gt;台湾百原科技是一家网络科技公司。他们在服务器虚拟化、
云计算解决方案（ZStack、seafile、Docker、KVM、VMWare、Xen、Hyper-V）、SaaS（Citrix XenApp），
分布式存储（GlusterFS、Ceph、Rockstor）等领域有深厚的实战经验。
他们客户的需求主要覆盖了信息安全，网络购物、以及云端商城建设。
百原科技也曾使用过OpenStack和CloudStack的解决方案，不过ZStack的方便快捷的能力更加合适该公司的发展方向。
基于以往的实战经验，他们快速的构建了ZStack解决方案，并开始在台湾地区推广ZStack项目。&lt;/p&gt;

&lt;p&gt;ZStack社区期待ZStack可以帮助台港澳地区云计算的发展和普及，
并期望ZStack的社区活动&lt;strong&gt;台湾站&lt;/strong&gt;能够在今年晚些时候顺利成行。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;相关链接：&lt;/strong&gt;
  ZStack台灣http://www.zstack.tw
  百原公司官网：http://www.baiyuan.com.tw
  聯繫方式info@baiyuan.com.tw&lt;/p&gt;
</description>
        <pubDate>Tue, 01 Sep 2015 00:00:00 +0800</pubDate>
        <link>http://zstack.org/cn_blog/zstack-tw-online.html</link>
        <guid isPermaLink="true">http://zstack.org/cn_blog/zstack-tw-online.html</guid>
        
        
        <category>cn_blog</category>
        
      </item>
    
      <item>
        <title>ZStack v0.9 RC2 发布</title>
        <description>&lt;p&gt;ZStack 0.9 RC2版本今天发布，欢迎大家测试试用。在这个版本里，ZStack新加了两大重量级的功能：&lt;/p&gt;

&lt;h2&gt;支持分布式存储Ceph&lt;/h2&gt;

&lt;p&gt;从0.9版本开始，ZStack正式支持Ceph作为主存储和备份存储的设备。为了最大化的利用Ceph存储的高级能力，
在一个Zone内，用户需要使用一个Ceph Cluster同时作为主存储和备份存储。这样做的好处是，
避免了用户在创建新的云主机、备份Volume等操作时，主存储和备份存储之间不必要的数据拷贝，
所有的数据操作都是通过COW（copy on write）来实现的。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/0.9/1.png&quot; class=&quot;center-img img-responsive&quot;&gt;&lt;/p&gt;

&lt;p&gt;ZStack和Ceph之间的交互是通过部署在Ceph Mon服务器上的Agent来完成的。用户可以动态的添加或删除Ceph的Mon服务器。&lt;/p&gt;

&lt;h3&gt;Ceph 备份存储&lt;/h3&gt;

&lt;div class=&quot;bs-callout bs-callout-info&quot;&gt;
  &lt;h4&gt;Ceph 备份存储只能和Ceph主存储配合使用&lt;/h4&gt;
  
  使用Ceph的一个主要的好处是因为Ceph支持COW，所以在ZStack中，如果使用了Ceph的备份存储，那么主存储也必须是同一个Ceph。
  由于Ceph备份存储和主存储都使用相同的Ceph cluster，所以用户不能把一个Ceph的备份存储挂载到多个ZStack的Zones上。  最好的使用方法是每一个Zone使用独立的Ceph cluster作为同一套主存储和备份存储。
  
  换句话说，当ZStack的Zone仅仅挂载了Ceph作为备份存储的时候，你不能再使用NFS、本地存储以及ISCSI作为该Zone的主存储。
  当一个Zone同时挂载Ceph备份存储和SFTP备份存储的时候，可以混用多种主存储类型。但是需要特别注意的是，
  如果云主机的镜像文件只存在于Ceph备份存储的时候，该云主机只能在Ceph主存储上创建成功。
  假设创建云主机时选择的L3网络所在的Cluster上没有挂载Ceph主存储，但是该云主机的镜像文件只存在在Ceph备份存储
  上，那么创建云主机将会发生找不到合适主存储的失败。
&lt;/div&gt;


&lt;h4&gt;从UI添加Ceph备份存储&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;/images/0.9/2.png&quot; class=&quot;center-img img-responsive&quot;&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;选择类型 &#39;Ceph&#39;&lt;/li&gt;
&lt;li&gt;输入Ceph mon server的 IP/hostname&lt;/li&gt;
&lt;li&gt;输入Ceph mon server的 SSH 用户名&lt;/li&gt;
&lt;li&gt;输入Ceph mon server的 SSH 密码&lt;/li&gt;
&lt;li&gt;点击 &#39;Add&#39;&lt;/li&gt;
&lt;li&gt;重复步骤 3 ~ 5 来添加其他的Ceph Mon服务器&lt;/li&gt;
&lt;li&gt;点击 &#39;Next&#39;&lt;/li&gt;
&lt;/ol&gt;


&lt;h4&gt;通过CLI添加Ceph备份存储&lt;/h4&gt;

&lt;p&gt;你可以使用 AddCephBackupStorage 来添加 Ceph 备份存储. 例如：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt;AddCephBackupStorage name=ceph monUrls=root:密码@192.168.0.123,root:password@192.168.0.124,root:password@192.168.0.125 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;monUrls&lt;/code&gt; 是一个字符串列表，每一个Mon服务器的信息通过逗号来分割，每一个Mon服务器的信息遵从如下的格式：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ssh_用户名:ssh_密码@mon_server_ip:[ssh_port][/?monPort=ceph_mon_port]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;ssh_用户名&lt;/code&gt;, &lt;code&gt;ssh_密码&lt;/code&gt;, &lt;code&gt;mon_server_ip&lt;/code&gt; 是必须的内容，而&lt;code&gt;ssh_port&lt;/code&gt; 和 &lt;code&gt;ceph_mon_port&lt;/code&gt;是选填的。
&lt;code&gt;ceph_mon_port&lt;/code&gt; 是Ceph Mon服务器的端口，默认值为6789. 一个完整的monUrl的例子是：&lt;code&gt;root:password@192.168.0.123:22/?monPort=6789&lt;/code&gt;.&lt;/p&gt;

&lt;div class=&quot;bs-callout bs-callout-info&quot;&gt;
  &lt;h4&gt;指定 pool&lt;/h4&gt;
  &lt;code&gt;AddCephBackupStorage&lt;/code&gt; 有一个特别的参数&lt;code&gt;poolName&lt;/code&gt;。通过它，用户可以指定一个存在的Ceph Pool。 
  当用户指定一个pool的名字的时候，ZStack会使用这个pool。当这个pool不存在的时候，ZStack将会报告一个添加失败的错误。
  当用户不指定特别的pool名字的时候，ZStack会自动创建一个新的pool。
  
  你可以利用这个功能预先创建一个合适的pool。
&lt;/div&gt;


&lt;h4&gt;动态添加Mon服务器&lt;/h4&gt;

&lt;p&gt;在添加了Ceph备份存储后，用户还可以给该备份存储添加新的Ceph Mon服务器：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt;AddMonToCephBackupStorage uuid=d914841733fa499c9dc6d63ea339469d monUrls=root:password@192.168.0.123,root:password@192.168.0.124,root:password@192.168.0.125
&lt;/code&gt;&lt;/pre&gt;

&lt;h4&gt;动态删除Mon服务器&lt;/h4&gt;

&lt;p&gt;你还可以使用 RemoveMonFromCephBackupStorage 来删除一个Ceph Mon服务器。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt;RemoveMonFromCephBackupStorage uuid=d914841733fa499c9dc6d63ea339469d monHostnames=192.168.0.123,192.168.0.124
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;monHostnames&lt;/code&gt; 是一个通过逗号分割的字符串列表，里面是Mon的IP地址。&lt;/p&gt;

&lt;h4&gt;查询Ceph备份存储&lt;/h4&gt;

&lt;p&gt;使用QueryCephBackupStorage可以查询所有Ceph备份存储的详情:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/0.9/4.png&quot; class=&quot;center-img img-responsive&quot;&gt;&lt;/p&gt;

&lt;h3&gt;Ceph主存储&lt;/h3&gt;

&lt;p&gt;Ceph主存储既可以和Ceph备份存储协同工作，也可以使用SFTP备份存储。&lt;/p&gt;

&lt;h4&gt;通过UI添加&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;/images/0.9/3.png&quot; class=&quot;center-img img-responsive&quot;&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;选择类型 &#39;Ceph&#39;&lt;/li&gt;
&lt;li&gt;输入Ceph mon server的IP/hostname&lt;/li&gt;
&lt;li&gt;输入Ceph mon server的SSH 用户名&lt;/li&gt;
&lt;li&gt;输入Ceph mon server的SSH 密码&lt;/li&gt;
&lt;li&gt;点击 &#39;Add&#39;&lt;/li&gt;
&lt;li&gt;重复步骤 3 ~ 5 来添加其他的Ceph Mon服务器&lt;/li&gt;
&lt;li&gt;点击 &#39;Next&#39;&lt;/li&gt;
&lt;/ol&gt;


&lt;h4&gt;Add through CLI&lt;/h4&gt;

&lt;p&gt;你可以使用 AddCephPrimaryStorage 来添加一个 Ceph 主存储。 例如：:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt;AddCephPrimaryStorage name=ceph zoneUuid=d914841733fa499c9dc6d63ea339469d monUrls=root:password@192.168.0.123,root:password@192.168.0.124,root:password@192.168.0.125
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;monUrls&lt;/code&gt; 是一个字符串列表，每一个Mon服务器的信息通过逗号来分割，每一个Mon服务器的信息遵从如下的格式：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ssh_用户名:ssh_密码@mon_server_ip:[ssh_port][/?monPort=ceph_mon_port]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;ssh_用户名&lt;/code&gt;, &lt;code&gt;ssh_密码&lt;/code&gt;, &lt;code&gt;mon_server_ip&lt;/code&gt; 是必须的内容，而&lt;code&gt;ssh_port&lt;/code&gt; 和 &lt;code&gt;ceph_mon_port&lt;/code&gt;是选填的。
&lt;code&gt;ceph_mon_port&lt;/code&gt; 是Ceph Mon服务器的端口，默认值为6789. 一个完整的monUrl的例子是：&lt;code&gt;root:password@192.168.0.123:22/?monPort=6789&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;  &lt;h4&gt;指定 pool&lt;/h4&gt;
  &lt;code&gt;AddCephPrimaryStorage&lt;/code&gt; 有三个个特别的参数&lt;code&gt;imageCachePoolName, rootVolumePoolName, dataVolumePoolName&lt;/code&gt;。
  通过它们，用户可以指定存在的Ceph Pool作为主存储的Pool。
  当用户指定pool的名字的时候，ZStack会使用这个pool。当pool不存在的时候，ZStack将会报告一个添加失败的错误。
  当用户不指定特别的pool名字的时候，ZStack会自动创建三个新的pool。&lt;/p&gt;

&lt;p&gt;  你可以利用这个功能预先创建合适的pool。在指定Pool的时候，你可以只指定其中的一个或者两个，然后由ZStack来创建其余的Pool。
&lt;/div&gt;&lt;/p&gt;

&lt;h4&gt;动态添加Mon服务器&lt;/h4&gt;

&lt;p&gt;在添加了Ceph主存储后，用户还可以给该主存储添加新的Ceph Mon服务器：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt;AddMonToCephBackupStorage uuid=d914841733fa499c9dc6d63ea339469d monUrls=root:password@192.168.0.123,root:password@192.168.0.124,root:password@192.168.0.125
&lt;/code&gt;&lt;/pre&gt;

&lt;h4&gt;动态删除Mon服务器&lt;/h4&gt;

&lt;p&gt;你还可以使用 RemoveMonFromCephPrimaryStorage 来删除一个Ceph Mon服务器。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt;RemoveMonFromCephPrimaryStorage uuid=d914841733fa499c9dc6d63ea339469d monHostnames=192.168.0.123,192.168.0.124
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The &lt;code&gt;monHostnames&lt;/code&gt; is a list of IPs of mon servers that you want to remove.&lt;/p&gt;

&lt;h4&gt;查询Ceph主存储&lt;/h4&gt;

&lt;p&gt;你可以使用QueryCephPrimaryStorage来查询所有的Ceph主存储的详细信息：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/0.9/5.png&quot; class=&quot;center-img img-responsive&quot;&gt;&lt;/p&gt;

&lt;h2&gt;动态负载均衡&lt;/h2&gt;

&lt;p&gt;从0.9开始，ZStack支持全新的动态负载均衡网络服务。详细的负载均衡介绍请访问&lt;a href=&quot;http://zstackdoc.readthedocs.org/en/latest/userManual/lb.html&quot;&gt;负载均衡用户手册&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;需要说明的是，RC2版本中有一个&lt;a href=&quot;https://github.com/zstackorg/zstack/issues/117&quot;&gt;Bug&lt;/a&gt;，导致通过无缝升级的ZStack无法使用负载均衡的功能。
用户暂时需要重新安装ZStack才可以使用。我们将在正式版中修复这个Bug。&lt;/p&gt;

&lt;h2&gt;安装 0.9 RC2&lt;/h2&gt;

&lt;h3&gt;单节点一键安装&lt;/h3&gt;

&lt;p&gt;目前官网的安装脚本只会安装0.8正式版的ZStack。安装0.9 RC2版本的ZStack需要单独下载安装包，并通过安装脚本指定安装包路径：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;mkdir -p zstack-0.9-rc2
cd zstack-0.9-rc2
wget http://download.zstack.org/releases/0.9/rc2/zstack-install.sh
wget http://download.zstack.org/releases/0.9/rc2/zstack-all-in-one-0.9.0-rc2.tgz
bash zstack-install.sh -a -f zstack-all-in-one-0.9.0-rc2.tgz
&lt;/code&gt;&lt;/pre&gt;

&lt;h3&gt;多节点安装&lt;/h3&gt;

&lt;p&gt;ZStack 0.9 RC2多节点安装的步骤可以参考&lt;a href=&quot;../installation/multi-node.html&quot;&gt;多节点安装手册&lt;/a&gt;。注意的是，需要提前下载0.9 RC2的安装包，并在安装的时候通过 &lt;code&gt;-f zstack-all-in-one-0.9.0-rc2.tgz&lt;/code&gt; 来指定。&lt;/p&gt;

&lt;h2&gt;无缝升级&lt;/h2&gt;

&lt;div class=&quot;bs-callout bs-callout-warning&quot;&gt;
  &lt;h4&gt;请格外留意在文章最后的虚拟路由器的升级指令&lt;/h4&gt;
  
  由于ZStack0.9在制裁动态路由功能的时候，添加了新的虚拟路由功能。所以不论是否使用虚拟路由功能，用户都应该升级
  虚拟路由。详细的升级办法，会写在升级这章的最后。
&lt;/div&gt;




&lt;div class=&quot;bs-callout bs-callout-warning&quot;&gt;
  &lt;h4&gt;备份数据库&lt;/h4&gt;
  
  虽然ZStack升级程序会进行备份，不过在升级数据库前，强烈建议用户手动&lt;b&gt;备份数据库!&lt;/b&gt;
  您可以使用以下的命令来备份当前zstack的数据库，以防之后的误操作：
  
  &lt;pre&gt;&lt;code&gt;mysqldump -u root -proot_password --host mysql_ip --port mysql_port zstack &gt; path_to_db_dump.sql&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;


&lt;h3&gt;快速升级&lt;/h3&gt;

&lt;p&gt;如果你仅仅只有一个管理节点，数据库和Dashboard也装在相同的节点上，那么你就可以用下面的方法快速升级：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;zstack-ctl stop_node
mkdir -p zstack-0.9-rc2
cd zstack-0.9-rc2
wget http://download.zstack.org/releases/0.9/rc2/zstack-install.sh
wget http://download.zstack.org/releases/0.9/rc2/zstack-all-in-one-0.9.0-rc2.tgz
bash zstack-install.sh -u -f zstack-all-in-one-0.9.0-rc2.tgz
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;正常情况，你大概只需要等待2分钟，zstack就会帮你升级完成。&lt;/p&gt;

&lt;h3&gt;使用zstack-ctl升级多节点&lt;/h3&gt;

&lt;h4&gt;1. 升级第一个节点&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;mkdir -p zstack-0.9-rc2
cd zstack-0.9-rc2
&lt;/code&gt;&lt;/pre&gt;

&lt;div class=&quot;bs-callout bs-callout-info&quot;&gt;
  &lt;h4&gt;请重新安装zstack-ctl，如果你还在使用zstack v0.6系列的产品&lt;/h4&gt;
  
  wget http://download.zstack.org/releases/0.7/rc2/zstackctl-0.7.tar.gz
  /var/lib/zstack/virtualenv/zstackctl/bin/pip install --ignore-installed zstackctl-0.7.tar.gz
  
&lt;/div&gt;


&lt;pre&gt;&lt;code&gt;wget http://download.zstack.org/releases/0.9/rc2/zstack.war
zstack-ctl upgrade_management_node --war-file zstack.war
&lt;/code&gt;&lt;/pre&gt;

&lt;h4&gt;2. 升级数据库&lt;/h4&gt;

&lt;p&gt;请确保你已经成功备份了数据库！&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;zstack-ctl upgrade_db
&lt;/code&gt;&lt;/pre&gt;

&lt;div class=&quot;bs-callout bs-callout-info&quot;&gt;
  &lt;h4&gt;如果只有一个管理节点，您可以立刻启动该节点&lt;/h4&gt;
  使用命令&lt;pre&gt;&lt;code&gt;zstack-ctl start_node&lt;/code&gt;&lt;/pre&gt;启动zstack管理节点。如果还有其他管理节点，请继续完成步骤三。
&lt;/div&gt;


&lt;h4&gt;3. 升级其他管理节点&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;zstack-ctl upgrade_management_node --war-file path_to_the_war --host remote_host_ip
&lt;/code&gt;&lt;/pre&gt;

&lt;h4&gt;4. 升级UI&lt;/h4&gt;

&lt;div class=&quot;bs-callout bs-callout-info&quot;&gt;
  &lt;h4&gt;停止UI服务&lt;/h4&gt;
  
  如果还在使用0.6版本，请使用命令：&lt;code&gt;/etc/init.d/zstack-dashboard stop&lt;/code&gt;; 
  对于0.6以后的版本，请使用命令：&lt;code&gt;zstack-ctl stop_ui&lt;/code&gt;
&lt;/div&gt;


&lt;p&gt;升级本地UI服务：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;zstack-ctl install_ui
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;或者升级远端UI服务：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;zstack-ctl install_ui --host remote_machine_ip
&lt;/code&gt;&lt;/pre&gt;

&lt;h4&gt;5. 启动管理节点&lt;/h4&gt;

&lt;p&gt;启动本地管理节点：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;`zstack-ctl start_node --host remote_host_ip`
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;启动远程管理节点：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;`zstack-ctl start_node --host remote_host_ip`
&lt;/code&gt;&lt;/pre&gt;

&lt;div class=&quot;bs-callout bs-callout-info&quot;&gt;
  &lt;h4&gt;所有的Agent都会随着管理节点的启动而自动升级&lt;/h4&gt;
  当管理节点启动后，会重新连接并升级包括计算节点，备份存储，虚拟路由等等一系列的ZStack Agents。
  用户在创建新的云主机之前，需要确保计算节点的状态已经变成Connected
&lt;/div&gt;


&lt;h4&gt;6. 启动UI服务&lt;/h4&gt;

&lt;p&gt;启动本地UI：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;`zstack-ctl start_ui`
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;启动远端UI：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;`zstack-ctl start_ui --host remote_host_ip`
&lt;/code&gt;&lt;/pre&gt;

&lt;h4&gt;7. 升级虚拟路由&lt;/h4&gt;

&lt;h5&gt;升级正在运行的虚拟路由器(Virtual Router VMs）&lt;/h5&gt;

&lt;p&gt;&lt;img src=&quot;/images/0.9/6.png&quot; class=&quot;center-img img-responsive&quot;&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;选择 虚拟路由器 VM&lt;/li&gt;
&lt;li&gt;点击 &quot;Action&quot;&lt;/li&gt;
&lt;li&gt;点击 &quot;Reconnect&quot;&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;待重连之后，虚拟路由器会更新到最新的版本。&lt;/p&gt;

&lt;h5&gt;更新虚拟路由器镜像以及虚拟路由器模板&lt;/h5&gt;

&lt;ol&gt;
&lt;li&gt;添加新的虚拟路由器镜像 http://download.zstack.org/releases/0.9/rc2/zstack-virtualrouter-0.9.0-rc.qcow2:&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;&lt;img src=&quot;/images/0.9/6.png&quot; class=&quot;center-img img-responsive&quot;&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;通过CLI更新虚拟路由器模板:&lt;/p&gt;

&lt;p&gt; UpdateVirtualRouterOffering uuid=vr_offering_uuid imageUuid=new_image_uuid&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;


&lt;div class=&quot;bs-callout bs-callout-warning&quot;&gt;
  &lt;h4&gt;你将不能在0.9版本的ZStack中成功使用0.8版本的虚拟路由器镜像创建一个虚拟路由器！&lt;/h4&gt;
  如果你不更新现有的虚拟路由器模板和镜像，当你添加一个新的具有虚拟路由器的L3网络，并用其创建一个新的云主机的时候，
  你将会遇到虚拟路由器连接失败，新的云主机无法创建等错误。所以在正常使用0.9版本之前，务必要更新虚拟路由器镜像。
&lt;/div&gt;


&lt;h2&gt;报告bug&lt;/h2&gt;

&lt;p&gt;如果你在使用中发现任何问题或者有任何建议，请你到我们的&lt;a href=&quot;https://github.com/zstackorg/zstack/issues&quot;&gt;GitHub&lt;/a&gt;上告诉我们，谢谢！&lt;/p&gt;

&lt;p&gt;Enjoy～
ZStack 开发团队&lt;/p&gt;
</description>
        <pubDate>Sun, 30 Aug 2015 00:00:00 +0800</pubDate>
        <link>http://zstack.org/cn/blog/v0.9-rc2.html</link>
        <guid isPermaLink="true">http://zstack.org/cn/blog/v0.9-rc2.html</guid>
        
        
        <category>blog</category>
        
      </item>
    
      <item>
        <title>Announcing ZStack v0.9 RC2</title>
        <description>&lt;p&gt;Hello everyone, I am Frank Zhang, the architect of ZStack. Today I am happy to announce that ZStack v0.9 is in the release cycle.
Today we release 0.9 RC2 for you test. In this release, ZStack introduces two new features:&lt;/p&gt;

&lt;h2&gt;Ceph Integration&lt;/h2&gt;

&lt;p&gt;Beginning at this version, ZStack supports Ceph as backup storage and primary storage. To leverage the advantages of Ceph,
users should use a Ceph cluster for both backup storage and primary storage in the same zone; by doing so, there will be
no data copy between backup storage and primary storage when users perform operations like creating VM, creating image,
creating a data volume from an image, all are done through COW(copy on write).&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/0.9/1.png&quot; class=&quot;center-img img-responsive&quot;&gt;&lt;/p&gt;

&lt;p&gt;ZStack interoperates with Ceph by deploying agents on Ceph mon servers. Users can dynamically add/remove a Ceph mon server
into/from ZStack.&lt;/p&gt;

&lt;h3&gt;Ceph Backup Storage&lt;/h3&gt;

&lt;div class=&quot;bs-callout bs-callout-info&quot;&gt;
  &lt;h4&gt;Ceph backup storage only works with Ceph primary storage&lt;/h4&gt;
  
  Given the a main advantage of using Ceph is COW, Ceph backup storage is designed to only work with Ceph primary storage.
  Because the Ceph backup storage and primary storage use the same Ceph cluster, users should not attach a Ceph backup storage
  to multiple zones. The best practice is to use a Ceph cluster for both backup storage and primary storage in the same zone.
  
  That is to say, you CANNOT use Ceph backup storage with primary storage of NFS, local storage, ISCSI.
&lt;/div&gt;


&lt;h4&gt;Add through UI&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;/images/0.9/2.png&quot; class=&quot;center-img img-responsive&quot;&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;select the type &#39;Ceph&#39;&lt;/li&gt;
&lt;li&gt;input IP/hostname of a Ceph mon server&lt;/li&gt;
&lt;li&gt;input SSH user name of the Ceph mon server&lt;/li&gt;
&lt;li&gt;input SSH password of the Ceph mon server&lt;/li&gt;
&lt;li&gt;click button &#39;Add&#39;&lt;/li&gt;
&lt;li&gt;repeat steps 3 ~ 5 to add other Ceph mon servers&lt;/li&gt;
&lt;li&gt;click button &#39;Next&#39;&lt;/li&gt;
&lt;/ol&gt;


&lt;h4&gt;Add through CLI&lt;/h4&gt;

&lt;p&gt;You can use AddCephBackupStorage to add a Ceph backup storage. For example:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt;AddCephBackupStorage name=ceph monUrls=root:password@192.168.0.123,root:password@192.168.0.124,root:password@192.168.0.125 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The &lt;code&gt;monUrls&lt;/code&gt; is a list of string containing Ceph mon server information, which is in format of:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ssh_username:ssh_password@mon_server_ip:[ssh_port][/?monPort=ceph_mon_port]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;ssh_username&lt;/code&gt;, &lt;code&gt;ssh_password&lt;/code&gt;, &lt;code&gt;mon_server_ip&lt;/code&gt; are mandatory while &lt;code&gt;ssh_port&lt;/code&gt; and &lt;code&gt;ceph_mon_port&lt;/code&gt; are optional. &lt;code&gt;ceph_mon_port&lt;/code&gt; is
the Ceph mon server port which is default to 6789. A full example of monUrl is &lt;code&gt;root:password@192.168.0.123:22/?monPort=6789&lt;/code&gt;.&lt;/p&gt;

&lt;div class=&quot;bs-callout bs-callout-info&quot;&gt;
  &lt;h4&gt;Specifying the pool&lt;/h4&gt;
  &lt;code&gt;AddCephBackupStorage&lt;/code&gt; receives an optional parameter &lt;code&gt;poolName&lt;/code&gt; which allows you to specify an existing
  Ceph pool for the backup storage. If the parameter is provided, ZStack will use the pool instead of creating a new one;
  if the pool is not existing, an error will be raised and the backup storage will fail to be added. If the parameter is omitted,
  ZStack will automatically create a new pool with the default Ceph pool setting.
  
  You can use this feature to create a well-tuned Ceph pool for the backup storage.
&lt;/div&gt;


&lt;h4&gt;Dynamically add new Ceph mon servers&lt;/h4&gt;

&lt;p&gt;You can use AddMonToCephBackupStorage to add new Ceph mon servers to a Ceph backup storage:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt;AddMonToCephBackupStorage uuid=d914841733fa499c9dc6d63ea339469d monUrls=root:password@192.168.0.123,root:password@192.168.0.124,root:password@192.168.0.125
&lt;/code&gt;&lt;/pre&gt;

&lt;h4&gt;Dynamically remove Ceph mon servers&lt;/h4&gt;

&lt;p&gt;You can use RemoveMonFromCephBackupStorage to remove Ceph mon servers from a Ceph backup storage:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt;RemoveMonFromCephBackupStorage uuid=d914841733fa499c9dc6d63ea339469d monHostnames=192.168.0.123,192.168.0.124
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The &lt;code&gt;monHostnames&lt;/code&gt; is a list of IPs of mon servers that you want to remove.&lt;/p&gt;

&lt;h4&gt;Query&lt;/h4&gt;

&lt;p&gt;You can use QueryCephBackupStorage to query Ceph backup storage:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/0.9/4.png&quot; class=&quot;center-img img-responsive&quot;&gt;&lt;/p&gt;

&lt;h3&gt;Ceph Primary Storage&lt;/h3&gt;

&lt;p&gt;The Ceph primary storage works with both SFTP backup storage and Ceph backup storage.&lt;/p&gt;

&lt;h4&gt;Add through UI&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;/images/0.9/3.png&quot; class=&quot;center-img img-responsive&quot;&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;select the type &#39;Ceph&#39;&lt;/li&gt;
&lt;li&gt;input IP/hostname of a Ceph mon server&lt;/li&gt;
&lt;li&gt;input SSH user name of the Ceph mon server&lt;/li&gt;
&lt;li&gt;input SSH password of the Ceph mon server&lt;/li&gt;
&lt;li&gt;click button &#39;Add&#39;&lt;/li&gt;
&lt;li&gt;repeat steps 3 ~ 5 to add other Ceph mon servers&lt;/li&gt;
&lt;li&gt;click button &#39;Next&#39;&lt;/li&gt;
&lt;/ol&gt;


&lt;h4&gt;Add through CLI&lt;/h4&gt;

&lt;p&gt;You can use AddCephPrimaryStorage to add a Ceph primary storage. For example::&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt;AddCephPrimaryStorage name=ceph zoneUuid=d914841733fa499c9dc6d63ea339469d monUrls=root:password@192.168.0.123,root:password@192.168.0.124,root:password@192.168.0.125
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The &lt;code&gt;monUrls&lt;/code&gt; is a list of string containing Ceph mon server information, which is in format of:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ssh_username:ssh_password@mon_server_ip:[ssh_port][/?monPort=ceph_mon_port]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;ssh_username&lt;/code&gt;, &lt;code&gt;ssh_password&lt;/code&gt;, &lt;code&gt;mon_server_ip&lt;/code&gt; are mandatory while &lt;code&gt;ssh_port&lt;/code&gt; and &lt;code&gt;ceph_mon_port&lt;/code&gt; are optional. &lt;code&gt;ceph_mon_port&lt;/code&gt; is
the Ceph mon server port which is default to 6789. A full example of monUrl is &lt;code&gt;root:password@192.168.0.123:22/?monPort=6789&lt;/code&gt;.&lt;/p&gt;

&lt;div class=&quot;bs-callout bs-callout-info&quot;&gt;
  &lt;h4&gt;Specifying pools&lt;/h4&gt;
  &lt;code&gt;AddCephPrimaryStorage&lt;/code&gt; receives three optional parameters &lt;code&gt;imageCachePoolName, rootVolumePoolName, dataVolumePoolName&lt;/code&gt;
  all of which allow you to specify existing Ceph pools for the primary storage. If the parameters are provided, ZStack will use the existing pools instead of creating new ones;
  if the pools are not existing, an error will be raised and the primary storage will fail to be added. If the parameters are omitted,
  ZStack will automatically create new pools with the default Ceph pool setting.
  
  You can use this feature to create well-tuned Ceph pools for the primary storage. You can choose to only specify parameters(e.g. rootVolumePoolName) for existing pools
  you want to use, and let ZStack to automatically create the rest.
&lt;/div&gt;


&lt;h4&gt;Dynamically add new Ceph mon servers&lt;/h4&gt;

&lt;p&gt;You can use AddMonToCephPrimaryStorage to add new Ceph mon servers to a Ceph primary storage:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt;AddMonToCephBackupStorage uuid=d914841733fa499c9dc6d63ea339469d monUrls=root:password@192.168.0.123,root:password@192.168.0.124,root:password@192.168.0.125
&lt;/code&gt;&lt;/pre&gt;

&lt;h4&gt;Dynamically remove Ceph mon servers&lt;/h4&gt;

&lt;p&gt;You can use RemoveMonFromCephPrimaryStorage to remove Ceph mon servers from a Ceph primary storage:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt;RemoveMonFromCephPrimaryStorage uuid=d914841733fa499c9dc6d63ea339469d monHostnames=192.168.0.123,192.168.0.124
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The &lt;code&gt;monHostnames&lt;/code&gt; is a list of IPs of mon servers that you want to remove.&lt;/p&gt;

&lt;h4&gt;Query&lt;/h4&gt;

&lt;p&gt;You can use QueryCephPrimaryStorage to query Ceph primary storage:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/0.9/5.png&quot; class=&quot;center-img img-responsive&quot;&gt;&lt;/p&gt;

&lt;h2&gt;Elastic Load Balancer&lt;/h2&gt;

&lt;p&gt;Beginning at 0.9, ZStack supports the elastic load balancer. Details can be found at &lt;a href=&quot;http://zstackdoc.readthedocs.org/en/latest/userManual/lb.html&quot;&gt;User Manual - Elastic Load Balancer&lt;/a&gt;&lt;/p&gt;

&lt;h2&gt;Seamless Upgrade&lt;/h2&gt;

&lt;div class=&quot;bs-callout bs-callout-warning&quot;&gt;
  &lt;h4&gt;Pay attention to the virtual router upgrade instructions at the end&lt;/h4&gt;
  
  To support the elastic load balancer, you need to upgrade the virtual router VMs in your current ZStack setup.
  Please do read the virtual router upgrade instructions at the end of the upgrade chapter.
&lt;/div&gt;




&lt;div class=&quot;bs-callout bs-callout-warning&quot;&gt;
  &lt;h4&gt;Backup Database&lt;/h4&gt;
  
  Before performing any upgrade instructions, please backup the current database. This is very &lt;b&gt;IMPORTANT&lt;/b&gt;!
  Though ZStack will automatically backup the current database during upgrade, we strongly recommend you to manually backup the
  database in case any error happens. You can backup the database following:
  
  &lt;pre&gt;&lt;code&gt;mysqldump -u root -proot_password --host mysql_ip --port mysql_port zstack &gt; path_to_db_dump.sql&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;


&lt;h3&gt;Upgrade by quick script&lt;/h3&gt;

&lt;p&gt;If you have only one management node, you can upgrade it by ZStack&#39;s installation script:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;zstack-ctl stop_node
mkdir -p zstack-0.9-rc2
cd zstack-0.9-rc2
wget http://download.zstack.org/releases/0.9/rc2/zstack-install.sh
wget http://download.zstack.org/releases/0.9/rc2/zstack-all-in-one-0.9.0-rc2.tgz
bash zstack-install.sh -u -f zstack-all-in-one-0.9.0-rc2.tgz
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Be patient for a few minutes, the script will upgrade the database, management node, zstack-cli, zstack-ctl and zstack-dashboard.&lt;/p&gt;

&lt;h3&gt;Upgrade by zstack-ctl&lt;/h3&gt;

&lt;h4&gt;1. Upgrade the first management node&lt;/h4&gt;

&lt;p&gt;Perform below instructions on one of your management node:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;mkdir -p zstack-0.9-rc2
cd zstack-0.9-rc2
&lt;/code&gt;&lt;/pre&gt;

&lt;div class=&quot;bs-callout bs-callout-info&quot;&gt;
  &lt;h4&gt;Install zstack-ctl if you are using 0.6 version&lt;/h4&gt;
  
  wget --no-check-certificate https://download.zstack.org/releases/0.7/rc2/zstackctl-0.7.tar.gz
  /var/lib/zstack/virtualenv/zstackctl/bin/pip install --ignore-installed zstackctl-0.7.tar.gz
  
&lt;/div&gt;


&lt;pre&gt;&lt;code&gt;wget http://download.zstack.org/releases/0.9/rc2/zstack.war
zstack-ctl upgrade_management_node --war-file zstack.war
&lt;/code&gt;&lt;/pre&gt;

&lt;h4&gt;2. Upgrade the database&lt;/h4&gt;

&lt;p&gt;Make sure you have backup the current database following instructions on the top of this page. Then perform:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;zstack-ctl upgrade_db
&lt;/code&gt;&lt;/pre&gt;

&lt;div class=&quot;bs-callout bs-callout-info&quot;&gt;
  &lt;h4&gt;You can start the node now if you only have one management node&lt;/h4&gt;
  If you have only one management node, you can run &lt;pre&gt;&lt;code&gt;zstack-ctl start_node&lt;/code&gt;&lt;/pre&gt; to start the ZStack now. If you have
  other management nodes to upgrade, continue to perform following instructions.
&lt;/div&gt;


&lt;h4&gt;3. Upgrade other management nodes&lt;/h4&gt;

&lt;p&gt;If you have management nodes running on remote machines, run below commands for each node&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;zstack-ctl upgrade_management_node --war-file path_to_the_war --host remote_host_ip
&lt;/code&gt;&lt;/pre&gt;

&lt;h4&gt;4. Upgrade UI&lt;/h4&gt;

&lt;div class=&quot;bs-callout bs-callout-info&quot;&gt;
  &lt;h4&gt;Stop UI&lt;/h4&gt;
  
  If you are using 0.6, stop the UI by &lt;code&gt;/etc/init.d/zstack-dashboard stop&lt;/code&gt;; for 0.7 and 0.8, stop the UI by &lt;code&gt;zstack-ctl stop_ui&lt;/code&gt;
&lt;/div&gt;


&lt;p&gt;Upgrade your UI on local machine by:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;zstack-ctl install_ui
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;or&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;zstack-ctl install_ui --host remote_machine_ip
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;if the UI is installed on a remote machine.&lt;/p&gt;

&lt;h4&gt;5. Start management nodes&lt;/h4&gt;

&lt;p&gt;Now all your management nodes have been successfully upgraded to the 0.8 RC2. You can start them by &lt;code&gt;zstack-ctl start_node&lt;/code&gt; and
&lt;code&gt;zstack-ctl start_node --host remote_host_ip&lt;/code&gt;&lt;/p&gt;

&lt;div class=&quot;bs-callout bs-callout-info&quot;&gt;
  &lt;h4&gt;Agents will be automatically upgraded after starting management nodes&lt;/h4&gt;
  You don&#39;t need to bother with agent upgrade; they will be upgraded after management nodes reconnect them.
&lt;/div&gt;


&lt;h4&gt;6. Start UI&lt;/h4&gt;

&lt;p&gt;Now you can start the UI by &lt;code&gt;zstack-ctl start_ui&lt;/code&gt; on the local host or &lt;code&gt;zstack-ctl start_ui --host remote_host_ip&lt;/code&gt; on the remote host.&lt;/p&gt;

&lt;h4&gt;7. Upgrade Virtual Router&lt;/h4&gt;

&lt;h5&gt;Upgrade running virtual router VMs&lt;/h5&gt;

&lt;p&gt;&lt;img src=&quot;/images/0.9/6.png&quot; class=&quot;center-img img-responsive&quot;&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;select the virtual router VM&lt;/li&gt;
&lt;li&gt;click button &quot;Action&quot;&lt;/li&gt;
&lt;li&gt;click &quot;Reconnect&quot;&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;After reconnecting, the virtual router VM will be upgraded to the latest version.&lt;/p&gt;

&lt;h5&gt;Upgrade virtual router image and virtual router offering&lt;/h5&gt;

&lt;ol&gt;
&lt;li&gt;add the 0.9 virtual router image http://download.zstack.org/releases/0.9/rc2/zstack-virtualrouter-0.9.0-rc.qcow2 to the backup storage:&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;&lt;img src=&quot;/images/0.9/6.png&quot; class=&quot;center-img img-responsive&quot;&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;update the existing virtual router offering to the new virtual router image by CLI&lt;/p&gt;

&lt;p&gt; UpdateVirtualRouterOffering uuid=vr_offering_uuid imageUuid=new_image_uuid&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;


&lt;div class=&quot;bs-callout bs-callout-warning&quot;&gt;
  &lt;h4&gt;You cannot create new virtual router VMs if you don&#39;t upgrade the virtual offerings&lt;/h4&gt;
  If you don&#39;t upgrade existing virtual router offerings, new virtual router VMs will fail to be created because the old
  0.8(or 0.7, 0.6) image doesn&#39;t contain the agent required by the ZStack 0.9. You can use above CLI command to update existing
  offerings, or simply delete them and create new ones.
&lt;/div&gt;


&lt;h2&gt;Bug Report&lt;/h2&gt;

&lt;p&gt;If you find any bugs, please open a ticket on &lt;a href=&quot;https://github.com/zstackorg/zstack/issues&quot;&gt;GitHub&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Sat, 29 Aug 2015 00:00:00 +0800</pubDate>
        <link>http://zstack.org/blog/v0.9-rc2.html</link>
        <guid isPermaLink="true">http://zstack.org/blog/v0.9-rc2.html</guid>
        
        
        <category>blog</category>
        
      </item>
    
      <item>
        <title>更改VM hostname和静态IP地址</title>
        <description>&lt;h2&gt;简介&lt;/h2&gt;

&lt;p&gt;ZStack在创建VM Instance的时候可以设定VM的hostname和静态IP地址。那么我们怎么在创建VM Instance之后修改这个云主机的hostname和IP地址呢？&lt;/p&gt;

&lt;p&gt;答案要从ZStack是如何支持云主机的hostname和静态IP地址说起。ZStack是通过特有的System Tags（系统标签）来支持这两个功能的。
&lt;a href=&quot;http://zstackdoc.readthedocs.org/en/latest/userManual/tag.html#system-tags&quot;&gt;System Tags&lt;/a&gt;是ZStack特有的标签。
它的出现主要是为了解决IaaS架构稳定性的问题，保证ZStack在添加新功能的时候不必修改原有的代码。
用户在创建特定hostname和静态IP地址的云主机的时候，ZStack会创建两个特别的系统标签。ZStack对应的模块在创建云主机的过程中，
通过读取系统标签里的内容就可以把所需的内容设置上。所以，如果用户需要修改云主机的hostname和静态ip地址，
只需要修改之前的系统标签，再通过ZStack重启（不能在VM里面用reboot命令重启）云主机即可。&lt;/p&gt;

&lt;p&gt;目前ZStack的版本（0.8）里，还不支持UpdateSystemTags的API，只能通过Delete原有System Tages，再增加一个新的System Tags的方式。
ZStack 0.9版本会添加UpdateSystemTags的API。&lt;/p&gt;

&lt;h2&gt;查询System Tags&lt;/h2&gt;

&lt;p&gt;首先我们假定用户已经通过ZStack的UI界面或者zstack-cli创建了一台指定hostname和静态IP地址的云主机。&lt;/p&gt;

&lt;p&gt;例如创建了一台云主机，该云主机的hostname为vm1，静态IP地址是10.11.0.100：&lt;/p&gt;

&lt;pre&gt;
&lt;code&gt;
&gt;&gt;&gt;QueryVmInstance name~=vm1 
{
    &quot;inventories&quot;: [
        {
            &quot;allVolumes&quot;: [
                {
                    &quot;createDate&quot;: &quot;Aug 20, 2015 5:46:16 PM&quot;,
                    &quot;description&quot;: &quot;Root volume for VM[uuid:beda91e5c2474ab9bc5e15ce7c83de91]&quot;,
                    &quot;deviceId&quot;: 0,
                    &quot;format&quot;: &quot;qcow2&quot;,
                    &quot;installPath&quot;: &quot;/opt/zstack/nfsprimarystorage/prim-5b4d7483ba3b4d109c8d35c971fd2c24/rootVolumes/acct-36c27e8ff05c4780bf6d2fa65700f22e/vol-38d9adae6422474786d14d66672bcc9a/38d9adae6422474786d14d66672bcc9a.qcow2&quot;,
                    &quot;lastOpDate&quot;: &quot;Aug 20, 2015 5:46:16 PM&quot;,
                    &quot;name&quot;: &quot;ROOT-for-vm1&quot;,
                    &quot;primaryStorageUuid&quot;: &quot;5b4d7483ba3b4d109c8d35c971fd2c24&quot;,
                    &quot;rootImageUuid&quot;: &quot;589c8795fbdf45549be1c7a9ebdda70b&quot;,
                    &quot;size&quot;: 209715200,
                    &quot;state&quot;: &quot;Enabled&quot;,
                    &quot;status&quot;: &quot;Ready&quot;,
                    &quot;type&quot;: &quot;Root&quot;,
                    &quot;uuid&quot;: &quot;38d9adae6422474786d14d66672bcc9a&quot;,
                    &quot;vmInstanceUuid&quot;: &quot;beda91e5c2474ab9bc5e15ce7c83de91&quot;
                }
            ],
            &quot;allocatorStrategy&quot;: &quot;DefaultHostAllocatorStrategy&quot;,
            &quot;clusterUuid&quot;: &quot;1fae9d050a60441eac7e15d09d7a57e0&quot;,
            &quot;cpuNum&quot;: 1,
            &quot;cpuSpeed&quot;: 512,
            &quot;createDate&quot;: &quot;Aug 20, 2015 5:46:16 PM&quot;,
            &quot;defaultL3NetworkUuid&quot;: &quot;31fd0dba47ee472481ee4edc9ab9d6ee&quot;,
            &quot;hostUuid&quot;: &quot;15d0f76c5989472e83d264a1bc408355&quot;,
            &quot;hypervisorType&quot;: &quot;KVM&quot;,
            &quot;imageUuid&quot;: &quot;589c8795fbdf45549be1c7a9ebdda70b&quot;,
            &quot;instanceOfferingUuid&quot;: &quot;db2320b776ca4365962870f371db7c5c&quot;,
            &quot;lastHostUuid&quot;: &quot;15d0f76c5989472e83d264a1bc408355&quot;,
            &quot;lastOpDate&quot;: &quot;Aug 20, 2015 5:46:16 PM&quot;,
            &quot;memorySize&quot;: 134217728,
            &quot;name&quot;: &quot;vm1&quot;,
            &quot;platform&quot;: &quot;Linux&quot;,
            &quot;rootVolumeUuid&quot;: &quot;38d9adae6422474786d14d66672bcc9a&quot;,
            &quot;state&quot;: &quot;Running&quot;,
            &quot;type&quot;: &quot;UserVm&quot;,
            &quot;uuid&quot;: &quot;beda91e5c2474ab9bc5e15ce7c83de91&quot;,
            &quot;vmNics&quot;: [
                {
                    &quot;createDate&quot;: &quot;Aug 20, 2015 5:46:16 PM&quot;,
                    &quot;deviceId&quot;: 0,
                    &quot;gateway&quot;: &quot;10.11.0.1&quot;,
                    &quot;ip&quot;: &quot;10.11.0.100&quot;,
                    &quot;l3NetworkUuid&quot;: &quot;31fd0dba47ee472481ee4edc9ab9d6ee&quot;,
                    &quot;lastOpDate&quot;: &quot;Aug 20, 2015 5:46:16 PM&quot;,
                    &quot;mac&quot;: &quot;fa:1f:45:81:f4:00&quot;,
                    &quot;netmask&quot;: &quot;255.255.0.0&quot;,
                    &quot;uuid&quot;: &quot;c9ba9bc674084ac39a02a680ba6752fa&quot;,
                    &quot;vmInstanceUuid&quot;: &quot;beda91e5c2474ab9bc5e15ce7c83de91&quot;
                }
            ],
            &quot;zoneUuid&quot;: &quot;fb92b33a29bc42a8990f5db0356493b8&quot;
        }
    ],
    &quot;success&quot;: true
}
&lt;/code&gt;
&lt;/pre&gt;


&lt;p&gt;如果还没有登录，请用下面的方法登录系统：&lt;/p&gt;

&lt;pre&gt;
&lt;code&gt;
&gt;&gt;&gt;LogInByAccount accountName=admin password=password
{
    &quot;inventory&quot;: {
        &quot;accountUuid&quot;: &quot;36c27e8ff05c4780bf6d2fa65700f22e&quot;,
        &quot;createDate&quot;: &quot;Aug 20, 2015 7:29:33 PM&quot;,
        &quot;expiredDate&quot;: &quot;Aug 20, 2015 9:29:33 PM&quot;,
        &quot;userUuid&quot;: &quot;36c27e8ff05c4780bf6d2fa65700f22e&quot;,
        &quot;uuid&quot;: &quot;84ec1c14f1574806afe2ae2b1c963ab3&quot;
    },
    &quot;success&quot;: true
}
&lt;/code&gt;
&lt;/pre&gt;


&lt;p&gt;我们可以通过查询系统标签来，得到该VM的hostname和静态IP的设置。查询vm1的System Tags，也就是查询resourceUuid为vm1的UUID的系统标签：&lt;/p&gt;

&lt;pre&gt;
&lt;code&gt;
&gt;&gt;&gt;QuerySystemTag resourceUuid=beda91e5c2474ab9bc5e15ce7c83de91
{
    &quot;inventories&quot;: [
        {
            &quot;createDate&quot;: &quot;Aug 20, 2015 5:46:16 PM&quot;,
            &quot;inherent&quot;: false,
            &quot;lastOpDate&quot;: &quot;Aug 20, 2015 5:46:16 PM&quot;,
            &quot;resourceType&quot;: &quot;VmInstanceVO&quot;,
            &quot;resourceUuid&quot;: &quot;beda91e5c2474ab9bc5e15ce7c83de91&quot;,
            &quot;tag&quot;: &quot;staticIp::31fd0dba47ee472481ee4edc9ab9d6ee::10.11.0.100&quot;,
            &quot;type&quot;: &quot;System&quot;,
            &quot;uuid&quot;: &quot;0dc36ae8dad24409bfca5c8d307dc8d9&quot;
        },
        {
            &quot;createDate&quot;: &quot;Aug 20, 2015 5:46:16 PM&quot;,
            &quot;inherent&quot;: false,
            &quot;lastOpDate&quot;: &quot;Aug 20, 2015 5:46:16 PM&quot;,
            &quot;resourceType&quot;: &quot;VmInstanceVO&quot;,
            &quot;resourceUuid&quot;: &quot;beda91e5c2474ab9bc5e15ce7c83de91&quot;,
            &quot;tag&quot;: &quot;hostname::vm1&quot;,
            &quot;type&quot;: &quot;System&quot;,
            &quot;uuid&quot;: &quot;bde1ac5f07e04e5d93849c07875ea1ff&quot;
        }
    ],
    &quot;success&quot;: true
}
&lt;/code&gt;
&lt;/pre&gt;


&lt;h2&gt;删除hostname和静态IP地址&lt;/h2&gt;

&lt;p&gt;删除hostname和静态IP地址的方法就是删除设定的系统标签。删除系统标签和删除用户普通标签（资源别名）的方法一样都是使用DeleteTag API：&lt;/p&gt;

&lt;pre&gt;
&lt;code&gt;
&gt;&gt;&gt;DeleteTag uuid=0dc36ae8dad24409bfca5c8d307dc8d9
{
    &quot;success&quot;: true
}

&gt;&gt;&gt;DeleteTag uuid=bde1ac5f07e04e5d93849c07875ea1ff
{
    &quot;success&quot;: true
}
&lt;/code&gt;
&lt;/pre&gt;


&lt;p&gt;删除标签之后，我们将不会查询到和云主机vm1相关的标签:&lt;/p&gt;

&lt;pre&gt;
&lt;code&gt;
&gt;&gt;&gt;QuerySystemTag resourceUuid=beda91e5c2474ab9bc5e15ce7c83de91
{
    &quot;inventories&quot;: [],
    &quot;success&quot;: true
}
&lt;/code&gt;
&lt;/pre&gt;


&lt;h2&gt;设置新的hostname和静态IP地址&lt;/h2&gt;

&lt;p&gt;创建系统标签的API是CreateSystemTag，这个API需要输入几个参数：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;resourceUuid： 这里就是云主机vm1的UUID&lt;/li&gt;
&lt;li&gt;resourceType: 这里的类型是VmInstanceVO , 更多类型可以访问&lt;a href=&quot;http://zstackdoc.readthedocs.org/en/latest/userManual/tag.html#resource-type&quot;&gt;系统标签介绍&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;tag: 就是具体的标签。每个系统标签的定义是不同的，这个需要根据System的定义来指定。我们稍后还会看到两个不同的系统标签。&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;先来创建新的hostname为newVm1：&lt;/p&gt;

&lt;pre&gt;
&lt;code&gt;
&gt;&gt;&gt;CreateSystemTag resourceUuid=beda91e5c2474ab9bc5e15ce7c83de91 resourceType=VmInstanceVO tag=hostname::newVm1
{
    &quot;inventory&quot;: {
        &quot;createDate&quot;: &quot;Aug 20, 2015 7:29:34 PM&quot;,
        &quot;inherent&quot;: false,
        &quot;lastOpDate&quot;: &quot;Aug 20, 2015 7:29:34 PM&quot;,
        &quot;resourceType&quot;: &quot;VmInstanceVO&quot;,
        &quot;resourceUuid&quot;: &quot;beda91e5c2474ab9bc5e15ce7c83de91&quot;,
        &quot;tag&quot;: &quot;hostname::newVm1&quot;,
        &quot;type&quot;: &quot;System&quot;,
        &quot;uuid&quot;: &quot;775f6655e6604c46ad6509c0270e4249&quot;
    },
    &quot;success&quot;: true
}
&lt;/code&gt;
&lt;/pre&gt;


&lt;p&gt;再来创建新的静态IP地址为10.11.0.101（需要在对应的L3的IP地址范围内）：&lt;/p&gt;

&lt;pre&gt;
&lt;code&gt;
&gt;&gt;&gt;CreateSystemTag resourceUuid=beda91e5c2474ab9bc5e15ce7c83de91 resourceType=VmInstanceVO tag=staticIp::31fd0dba47ee472481ee4edc9ab9d6ee::10.11.0.101
{
    &quot;inventory&quot;: {
        &quot;createDate&quot;: &quot;Aug 20, 2015 7:36:18 PM&quot;,
        &quot;inherent&quot;: false,
        &quot;lastOpDate&quot;: &quot;Aug 20, 2015 7:36:18 PM&quot;,
        &quot;resourceType&quot;: &quot;VmInstanceVO&quot;,
        &quot;resourceUuid&quot;: &quot;beda91e5c2474ab9bc5e15ce7c83de91&quot;,
        &quot;tag&quot;: &quot;staticIp::31fd0dba47ee472481ee4edc9ab9d6ee::10.11.0.101&quot;,
        &quot;type&quot;: &quot;System&quot;,
        &quot;uuid&quot;: &quot;85d75b94b78f4fccb4c5ca8ab95a5e3f&quot;
    },
    &quot;success&quot;: true
}
&lt;/code&gt;
&lt;/pre&gt;


&lt;p&gt;这里的31fd0dba47ee472481ee4edc9ab9d6ee是VM所在L3网络的UUID。然后让我们来重启vm1。需要注意的是，
我们需要使用StopVmInstacne 和StartVmInstance来重启VM，而不是RebootVmInstacne。&lt;/p&gt;

&lt;pre&gt;
&lt;code&gt;
StopVmInstance uuid=beda91e5c2474ab9bc5e15ce7c83de91
StartVmInstance uuid=beda91e5c2474ab9bc5e15ce7c83de91
&lt;/code&gt;
&lt;/pre&gt;


&lt;p&gt;待vm1重新启动后，我们就会发现vm1的hostname变成了newVm1，IP地址也变成了10.11.0.101。如果是通过
UI面板重启的VM，还需要刷新一下UI面板，vm1的IP地址就会显示正常。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;0.8版本中有一个bug会导致云主机在重启后，不能更改的静态IP地址。这个Bug会在0.9版本中修复&lt;/strong&gt;&lt;/p&gt;

&lt;h2&gt;更新系统标签&lt;/h2&gt;

&lt;p&gt;在0.9版本之后，我们还会支持直接更新系统标签，这样可以节省更改云主机信息的步骤。更改hostname
系统标签的方法是：&lt;/p&gt;

&lt;pre&gt;
&lt;code&gt;
UpdateSystemTag tag=hostname::newVm1 uuid=bde1ac5f07e04e5d93849c07875ea1ff
&lt;/code&gt;
&lt;/pre&gt;


&lt;p&gt;这里的UUID是之前通过QuerySystemTag 查到的hostname的Tag的UUID。&lt;/p&gt;

&lt;p&gt;更改静态IP地址系统标签的方法是：
&lt;code&gt;
UpdateSystemTag tag=staticIp::31fd0dba47ee472481ee4edc9ab9d6ee::10.11.0.101 uuid=0dc36ae8dad24409bfca5c8d307dc8d9
&lt;/code&gt;
&lt;/pre&gt;&lt;/p&gt;

&lt;p&gt;需要注意的是，这里有两个UUID。其中31fd0dba47ee472481ee4edc9ab9d6ee，
是云主机网卡所在的L3 Network的UUID。而0dc36ae8dad24409bfca5c8d307dc8d9
是之前通过QuerySystemTag API查询到的静态IP地址Tag的UUID。&lt;/p&gt;

&lt;h2&gt;添加新的网络并设置静态IP地址&lt;/h2&gt;

&lt;p&gt;在0.8版本之后，ZStack支持给云主机动态的添加网卡。通常动态添加的网卡也是一个动态的IP地址，
如果需要给动态添加的网卡提前配置一个静态的IP地址，那么我们也需要依赖静态IP地址的系统标签。&lt;/p&gt;

&lt;p&gt;我们假设需要添加的网卡所属的L3网络的UUID是：31fd0dba47ee472481ee4edc9ab9d6ee&lt;/p&gt;

&lt;p&gt;云主机的UUID是：beda91e5c2474ab9bc5e15ce7c83de91&lt;/p&gt;

&lt;p&gt;需要设定的静态IP地址是：10.11.0.102&lt;/p&gt;

&lt;p&gt;那么我们添加的系统标签的方法是：&lt;/p&gt;

&lt;pre&gt;
&lt;code&gt;
&gt;&gt;&gt;CreateSystemTag resourceUuid=beda91e5c2474ab9bc5e15ce7c83de91 resourceType=VmInstanceVO tag=staticIp::31fd0dba47ee472481ee4edc9ab9d6ee::10.11.0.102
{
    &quot;inventory&quot;: {
        &quot;createDate&quot;: &quot;Aug 20, 2015 7:36:18 PM&quot;,
        &quot;inherent&quot;: false,
        &quot;lastOpDate&quot;: &quot;Aug 20, 2015 7:36:18 PM&quot;,
        &quot;resourceType&quot;: &quot;VmInstanceVO&quot;,
        &quot;resourceUuid&quot;: &quot;beda91e5c2474ab9bc5e15ce7c83de91&quot;,
        &quot;tag&quot;: &quot;staticIp::31fd0dba47ee472481ee4edc9ab9d6ee::10.11.0.102&quot;,
        &quot;type&quot;: &quot;System&quot;,
        &quot;uuid&quot;: &quot;85d75b94b78f4fccb4c5ca8ab95a5e3f&quot;
    },
    &quot;success&quot;: true
}
&lt;/code&gt;
&lt;/pre&gt;


&lt;p&gt;在添加完系统标签后，我们再添加网卡的时候，ZStack就会使用刚刚设置的静态IP地址了。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;参考：&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;a href=&quot;http://zstackdoc.readthedocs.org/en/latest/userManual/tag.html#system-tags&quot;&gt;系统标签手册&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;./v0.7.html&quot;&gt;静态IP地址功能介绍&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;./attach-detach-l3-tutorials.html&quot;&gt;给云主机动态的添加删除网卡&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

</description>
        <pubDate>Sat, 22 Aug 2015 00:00:00 +0800</pubDate>
        <link>http://zstack.org/cn_blog/update-system-tags-by-delete-add.html</link>
        <guid isPermaLink="true">http://zstack.org/cn_blog/update-system-tags-by-delete-add.html</guid>
        
        
        <category>cn_blog</category>
        
      </item>
    
      <item>
        <title>ZStack 2015 技术分享会【上海站】</title>
        <description>&lt;p&gt;&lt;strong&gt;“用最纯粹的技术回馈IaaS社区”&lt;/strong&gt;，是整个ZStack团队的信仰。ZStack开发团队将计划借0.9版本发布之际，首次在国内举办几场技术交流会。
继&lt;a href=&quot;./zstack-meetup-beijing-2015.html&quot;&gt;北京站&lt;/a&gt;开始报名后，上海站也公布了报名的详细情况。
上海站交流会会于9月12号周六下午1点在上海长宁区福泉路111号上海神州数码有限公司1楼大视频会议室举行。
为保证技术交流的质量，我们设置了活动报名人数的上限为50人，请关心ZStack现状和发展的开发者和用户们务必提前报名。&lt;/p&gt;

&lt;p&gt;本次研讨会的主题包括：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;ZStack技术架构详解&lt;/li&gt;
&lt;li&gt;ZStack实战分享&lt;/li&gt;
&lt;li&gt;现场互动问答&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;ZStack （zstack.org） 是全新一代开源IaaS，具有快速安装，快速部署，易维护，易升级，高性能等特点。
自2015年4月公开发布0.6版本后，陆续发布了0.7和0.8版本，9月初前后会发布支持ceph的 0.9版本。
目前ZStack的功能已经覆盖了大部分的企业私有云应用场景，国内外也有不少用户在测试使用。ZStack的首批客户也于7、8月份陆续部署上线运行。
对于希望使用IaaS软件，但是由于种种技术上的原因还没有成功部署私有云的企业来说，ZStack提供了全新的选择和云端体验。&lt;/p&gt;

&lt;p&gt;本次上海站技术交流会，我们要特别感谢&lt;strong&gt;上海神州数码有限公司&lt;/strong&gt;提供场地！&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;大家可以扫描下面的二维码报名ZStack技术交流会：&lt;/strong&gt;
&lt;img src=&quot;/images/meetups/2015/shanghai/registeration.png&quot; class=&quot;center-img img-responsive&quot;&gt;&lt;/p&gt;
</description>
        <pubDate>Thu, 20 Aug 2015 00:00:00 +0800</pubDate>
        <link>http://zstack.org/cn_blog/zstack-meetup-shanghai-2015.html</link>
        <guid isPermaLink="true">http://zstack.org/cn_blog/zstack-meetup-shanghai-2015.html</guid>
        
        
        <category>cn_blog</category>
        
      </item>
    
      <item>
        <title>ZStack 编译手册</title>
        <description>&lt;h2&gt;前言&lt;/h2&gt;

&lt;p&gt;最近越来越多的云端开发者开始阅读&lt;a href=&quot;http://zstackdoc.readthedocs.org/en/latest/&quot;&gt;ZStack API手册&lt;/a&gt;和&lt;a href=&quot;https://github.com/zstackorg/zstack&quot;&gt;ZStack在GitHub上的源代码&lt;/a&gt;。
其中部分开发者尝试基于ZStack进行二次开发（例如把传输云主机图像的VNC协议换成Spice协议，需要让ZStack创建的云主机拥有嵌套虚拟化，
给ZStack加上特别的监控程序，让ZStack管理非硬件虚拟化支持的Qemu虚拟机，更改UI界面等等）。
这些工作可能需要在ZStack中添加新的代码，并重新编译安装包。本文将会介绍标准的ZStack的编译打包方法。
使用该方法，开发人员可以快速的添加新的功能，并生成自己新的ZStack安装包。&lt;/p&gt;

&lt;hr /&gt;

&lt;h2&gt;下载ZStack源代码&lt;/h2&gt;

&lt;p&gt;目前ZStack的源代码由三个软件仓库构成：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/zstackorg/zstack&quot;&gt;zstack&lt;/a&gt;使用Java编写，是ZStack的核心，负责IaaS各种资源管理调度和消息通讯；&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/zstackorg/zstack-utility&quot;&gt;zstack-utility&lt;/a&gt;目前主要使用Python编写，包含ZStack的各种终端代理和其他工具。
这些终端代理负责接收来自ZStack核心的消息并执行对应的操作，例如和Libvirt通讯来管理VM的生命周期、各种存储（例如Ceph，iSCSI，SFTP）的管理、
虚拟路由器里管理VM的IP地址等等。除了终端代理工具外，这个软件仓库还包含了ZStack其他的工具，例如ZStack的编辑打包工具、
ZStack安装程序、ZStack命令行工具、ZStack管控工具等等。&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/zstackorg/zstack-dashboard&quot;&gt;zstack-dashboard&lt;/a&gt;使用JavaScript编写，是ZStack的图形界面。&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;编译ZStack All In One Package，你需要先从github上下载上面三个源代码。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;
mkdir /root/zstack-repos
cd zstack-repos
git clone https://github.com/zstackorg/zstack.git
git clone https://github.com/zstackorg/zstack-utility.git
git clone https://github.com/zstackorg/zstack-dashboard.git 
&lt;/code&gt;&lt;/pre&gt;


&lt;hr /&gt;

&lt;h2&gt;下载安装编译依赖&lt;/h2&gt;

&lt;p&gt;编译OS最好是在CentOS6.6或者CentOS7.1里进行。在编译之前，需要确保系统上已经安装了ant，maven，java-1.7.0-openjdk-devel，bzip2，gzip等工具。
另外由于ZStack核心是Java代码，里面需要很多maven的依赖库，但是很多maven的依赖库的第一选择都是放在google管理的软件仓库。
由于总所周知的原因，会导致第一次编译ZStack的时候异常缓慢，甚至是无法通过。不过maven的.m2/库是可以在不同机器上共享的。
我们在百度云盘里放置了一份编译的依赖包：http://pan.baidu.com/s/1eQvUmWU。
大家下载之后，可以根据说明，把依赖库的内容放到/root/.m2 的目录里即可（随着ZStack的开发，ZStack可能会引入一些新的库文件，
有可能在编译新的ZStack的时候，还是会遇到动态下载少量的依赖包，不过由于新的依赖包数量不多，所以下载速度应该可以接收）。&lt;/p&gt;

&lt;p&gt;另外如果有条件，大家也可以使用http代理服务器加速maven依赖包的下载，设置的方法可以参考：https://maven.apache.org/guides/mini/guide-proxies.html&lt;/p&gt;

&lt;hr /&gt;

&lt;h2&gt;预编译ZStack的Java代码&lt;/h2&gt;

&lt;p&gt;验证一下Java和Maven相关的依赖是不是已经解决正常，我们先来编译一下ZStack的Java源码：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;
cd zstack
mvn -DskipTests clean install
&lt;/code&gt;&lt;/pre&gt;


&lt;p&gt;如果一切顺利，我们大概只需要等待5分钟。&lt;/p&gt;

&lt;hr /&gt;

&lt;h2&gt;编译ZStack All In One安装包&lt;/h2&gt;

&lt;p&gt;如果ZStack的Java源码已经编译通过，我们就可以开始尝试编译ZStack All In One安装包了：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;
cd ~/zstack-repos/
wget -c http://archive.apache.org/dist/tomcat/tomcat-7/v7.0.35/bin/apache-tomcat-7.0.35.zip
cd zstack-utility/zstackbuild
ant -Dzstack_build_root=/root/zstack-repos all-in-one
&lt;/code&gt;&lt;/pre&gt;


&lt;p&gt;编译完成，安装包会放在zstack-utility/zstackbuild/target/目录中，例如：
zstack-utility/zstackbuild/target/zstack-all-in-one-0.8.0-qa.tgz
All In One安装包包含了ZStack核心功能，ZStack终端代理，ZStack管控工具和ZStack Web界面。&lt;/p&gt;

&lt;p&gt;如果用户只是改变了Java代码，其实只需要更新ZStack核心功能即可。ZStack的核心代码是编译打包到zstack.war中，
该文件会放在 zstack-utility/zstackbuild/target/zstack.war&lt;/p&gt;

&lt;p&gt;有了新编译完成的ZStack包，用户便可以参考我们的&lt;a href=&quot;http://zstack.org/cn_blog/v0.8-release.html&quot;&gt;安装升级手册&lt;/a&gt;来安装自己编译的ZStack安装包了。&lt;/p&gt;

&lt;hr /&gt;

&lt;h2&gt;ZStack 集成测试用例&lt;/h2&gt;

&lt;p&gt;在开发新功能的时候，不要忘记添加自己的集成测试用例。ZStack的集成测试用例都是放在zstack/test/ 目录下的。
开发者可以学习之前的集成测试用例来创建自己的测试用例。在成功完成&lt;strong&gt;预编译ZStack的Java代码&lt;/strong&gt;之后，
我们可以使用如下的方法来运行集成测试用例：&lt;/p&gt;

&lt;p&gt;运行一个测试用例：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;
cd zstack/test/
mvn test -Dtest=test_case_name 
#for example: for TestChangeHostState.java, the name is TestChangeHostState
mvn test -Dtest=TestChangeHostState
&lt;/code&gt;&lt;/pre&gt;


&lt;p&gt;运行一组测试用例：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;
cd zstack/test/
mvn test -Dtest=UnitTestSuite -Dconfig=unitTestSuiteXml/AccountManager.xml 
#all group test configures are in zstack_source/test/src/test/resources/unitTestSuiteXml/
&lt;/code&gt;&lt;/pre&gt;


&lt;p&gt;运行全部的测试用例：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;
cd zstack/test/
mvn test -Dtest=UnitTestSuite
&lt;/code&gt;&lt;/pre&gt;

</description>
        <pubDate>Sat, 15 Aug 2015 00:00:00 +0800</pubDate>
        <link>http://zstack.org/cn_blog/build-zstack.html</link>
        <guid isPermaLink="true">http://zstack.org/cn_blog/build-zstack.html</guid>
        
        
        <category>cn_blog</category>
        
      </item>
    
      <item>
        <title>ZStack 2015 技术分享会【北京站】</title>
        <description>&lt;p&gt;&lt;strong&gt;“用最纯粹的技术回馈IaaS社区”&lt;/strong&gt;，是整个ZStack团队的信仰。ZStack开发团队将计划借0.9版本发布之际，首次在国内举办几场技术交流会。
本次交流会的首站将会于9月5号周六下午13：30在北京海淀区东北旺西路8号中关村软件园内软件广场C座三楼极客演播厅举行。
为保证技术交流的质量，我们设置了活动报名人数的上限为100人，请关心ZStack现状和发展的开发者和用户们务必提前报名。&lt;/p&gt;

&lt;p&gt;本次研讨会的主题包括：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;ZStack技术架构详解&lt;/li&gt;
&lt;li&gt;ZStack实战分享&lt;/li&gt;
&lt;li&gt;ZStack合作伙伴技术分享&lt;/li&gt;
&lt;li&gt;现场互动问答&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;ZStack （zstack.org） 是全新一代开源IaaS，具有快速安装，快速部署，易维护，易升级，高性能等特点。
自2015年4月公开发布0.6版本后，陆续发布了0.7和0.8版本，9月初前后会发布支持ceph的 0.9版本。
目前ZStack的功能已经覆盖了大部分的企业私有云应用场景，国内外也有不少用户在测试使用。ZStack的首批客户也于7、8月份陆续部署上线运行。
对于希望使用IaaS软件，但是由于种种技术上的原因还没有成功部署私有云的企业来说，ZStack提供了全新的选择和云端体验。&lt;/p&gt;

&lt;p&gt;本次北京站技术交流会，我们要特别感谢&lt;strong&gt;北京云端时代科技有限公司&lt;/strong&gt;全程提供场地和茶歇！&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;大家可以扫描下面的二维码报名ZStack技术交流会：&lt;/strong&gt;
&lt;img src=&quot;/images/meetups/2015/beijing/registeration.png&quot; class=&quot;center-img img-responsive&quot;&gt;&lt;/p&gt;
</description>
        <pubDate>Sun, 09 Aug 2015 00:00:00 +0800</pubDate>
        <link>http://zstack.org/cn_blog/zstack-meetup-beijing-2015.html</link>
        <guid isPermaLink="true">http://zstack.org/cn_blog/zstack-meetup-beijing-2015.html</guid>
        
        
        <category>cn_blog</category>
        
      </item>
    
      <item>
        <title>ZStack v0.8 发布</title>
        <description>&lt;p&gt;ZStack的新版本v0.8 今天正式发布。v0.8版本里包含了4个重要功能：本地硬盘主存储、动态添加删除云主机网卡、账号用户权限系统和修改云主机的硬件配置。让我们来一一看一下他们的功能：&lt;/p&gt;

&lt;h2&gt;本地硬盘主存储&lt;/h2&gt;

&lt;p&gt;用户可以不必预先创建任何的网络共享存储，而使用计算节点的本地存储作为主存储设备。本地存储具有方便、快捷、适中性能等特点。
用户可以选择一个Cluster同时支持网络共享存储和本地硬盘主存储。如果同时选择了这两种类型的存储，ZStack会指定本地硬盘主存储
存放云主机的Root Volume（系统盘），网络共享存储存放云主机的Data Volume（数据盘）。这个是我们研究大部分私有云的实际使用方法后
得出的较好的使用方式，用户需要格外注意！
如果用户需要一部分计算节点的系统盘使用本地硬盘主存储，而另外一部分计算节点的系统盘使用网络共享存储，
那么请把这两类计算节点分入不同的Cluster。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/0.8/localstorage.png&quot; class=&quot;center-img img-responsive&quot;&gt;&lt;/p&gt;

&lt;p&gt;更多关于本地硬盘主存储的介绍可以访问&lt;a href=&quot;./local-stroage-tutorials.html&quot;&gt;本地存储教程&lt;/a&gt;&lt;/p&gt;

&lt;h2&gt;动态添加、删除云主机网卡（三层网络）&lt;/h2&gt;

&lt;p&gt;用户可以对一个正在运行的或是停止的云主机动态的添加和删除三层网络。这对于需要改变云主机网络拓扑结构的用户来说非常重要。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/0.8/2.png&quot; class=&quot;center-img img-responsive&quot;&gt;&lt;/p&gt;

&lt;hr&gt;


&lt;p&gt;&lt;img src=&quot;/images/0.8/3.png&quot; class=&quot;center-img img-responsive&quot;&gt;&lt;/p&gt;

&lt;p&gt;关于如何添加和删除网卡的详细信息可以访问&lt;a href=&quot;./attach-detach-l3-tutorials.html&quot;&gt;添加删除三层网络教程&lt;/a&gt;&lt;/p&gt;

&lt;h2&gt;用户账号权限管理系统&lt;/h2&gt;

&lt;p&gt;从0.8版本开始，ZStack开放了完善的用户账号权限系统API。ZStack的账号用户系统和亚马逊的AWS采用相同的管理方式，
同时提供了Account和User。用户不仅可以创建，修改用户密码，还可以创建不同用户组并加以不同的权限限制。
公有云也可以基于ZStack的账号系统对接自身的billing系统。&lt;/p&gt;

&lt;p&gt;详细用户权限介绍可以访问&lt;a href=&quot;./zstack-account-user-tutorials.html&quot;&gt;账号用户系统手册&lt;/a&gt;
或者可以直接访问&lt;a href=&quot;http://zstackdoc.readthedocs.org/en/latest/userManual/identity.html&quot;&gt;账号用户权限API手册&lt;/a&gt;&lt;/p&gt;

&lt;h2&gt;修改云主机配置模板&lt;/h2&gt;

&lt;p&gt;当用户选择某个模板（CPU/内存配置）创建云主机之后，如果需要增加CPU或者内存的数量，可以根据需求修改当前云主机的模板。
更改模板后修改后，仅需要重启云主机即可。该功能支持通过UI和命令行界面来修改模板。&lt;/p&gt;

&lt;p&gt;详细信息可以参阅&lt;a href=&quot;./change-vm-offering.html&quot;&gt;修改云主机配置模板手册&lt;/a&gt;&lt;/p&gt;

&lt;h2&gt;从0.7版本无缝升级&lt;/h2&gt;

&lt;div class=&quot;bs-callout bs-callout-warning&quot;&gt;
  &lt;h4&gt;升级数据库&lt;/h4&gt;
  
  虽然ZStack升级程序会进行备份，不过在升级数据库前，还是希望用户手动&lt;b&gt;做好数据库的备份!&lt;/b&gt;
  您可以使用以下的命令来备份当前zstack的数据库：
  
  &lt;pre&gt;&lt;code&gt;mysqldump -u root -proot_password --host mysql_ip --port mysql_port zstack &gt; path_to_db_dump.sql&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;


&lt;h3&gt;快速升级&lt;/h3&gt;

&lt;p&gt;如果你仅仅只有一个管理节点，数据库和Dashboard也装在相同的节点上，那么你就可以用下面的方法快速升级：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;wget http://download.zstack.org/releases/0.8/0.8.0/zstack-install-0.8.0.sh
wget http://download.zstack.org/releases/0.8/0.8.0/zstack-all-in-one-0.8.0.tgz
bash zstack-install-0.8.0.sh -u -f zstack-all-in-one-0.8.0.tgz
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;正常情况，你大概只需要等待2分钟，zstack就会帮你升级完成。&lt;/p&gt;

&lt;h3&gt;使用zstack-ctl升级多节点&lt;/h3&gt;

&lt;h4&gt;1. 升级第一个节点&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;mkdir zstack-0.8
cd zstack-0.8
&lt;/code&gt;&lt;/pre&gt;

&lt;div class=&quot;bs-callout bs-callout-info&quot;&gt;
  &lt;h4&gt;请重新安装zstack-ctl，如果你还在使用zstack v0.6系列的产品&lt;/h4&gt;
  
  wget http://download.zstack.org/releases/0.7/rc2/zstackctl-0.7.tar.gz
  /var/lib/zstack/virtualenv/zstackctl/bin/pip install --ignore-installed zstackctl-0.7.tar.gz
  
&lt;/div&gt;


&lt;pre&gt;&lt;code&gt;wget http://download.zstack.org/releases/0.8/0.8.0/zstack.war
zstack-ctl upgrade_management_node --war-file zstack.war
&lt;/code&gt;&lt;/pre&gt;

&lt;h4&gt;2. 升级数据库&lt;/h4&gt;

&lt;p&gt;备份数据库&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;zstack-ctl upgrade_db
&lt;/code&gt;&lt;/pre&gt;

&lt;div class=&quot;bs-callout bs-callout-info&quot;&gt;
  &lt;h4&gt;如果只有一个管理节点，您可以立刻启动该节点&lt;/h4&gt;
  使用命令&lt;pre&gt;&lt;code&gt;zstack-ctl start_node&lt;/code&gt;&lt;/pre&gt;启动zstack管理节点。如果还有其他管理节点，请继续完成步骤三。
&lt;/div&gt;


&lt;h4&gt;3. 升级其他管理节点&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;zstack-ctl upgrade_management_node --war-file path_to_the_war --host remote_host_ip
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;需要注意从 v0.8开始，zstack-ctl 统一了命令参数，所有原有--remote 指令都统一成了--host. &lt;/strong&gt;&lt;/p&gt;

&lt;h4&gt;4. 升级UI&lt;/h4&gt;

&lt;div class=&quot;bs-callout bs-callout-info&quot;&gt;
  &lt;h4&gt;停止UI服务&lt;/h4&gt;
  
  &lt;code&gt;/etc/init.d/zstack-dashboard stop&lt;/code&gt;; 

&lt;/div&gt;


&lt;p&gt;升级本地UI服务：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;zstack-ctl install_ui
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;或者升级远端UI服务：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;zstack-ctl install_ui --host remote_machine_ip
&lt;/code&gt;&lt;/pre&gt;

&lt;h4&gt;5. 启动管理节点&lt;/h4&gt;

&lt;p&gt;启动本地管理节点：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;`zstack-ctl start_node`
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;启动远程管理节点：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;`zstack-ctl start_node --host remote_host_ip`
&lt;/code&gt;&lt;/pre&gt;

&lt;div class=&quot;bs-callout bs-callout-info&quot;&gt;
  &lt;h4&gt;所有的Agent都会随着管理节点的启动而自动升级&lt;/h4&gt;
  当管理节点启动后，会重新连接并升级包括计算节点，备份存储，虚拟路由等等一系列的ZStack Agents。
  用户在创建新的云主机之前，需要确保计算节点的状态已经变成Connected
&lt;/div&gt;


&lt;h4&gt;6. 启动UI服务&lt;/h4&gt;

&lt;p&gt;启动本地UI：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;`zstack-ctl start_ui`
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;启动远端UI：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;`zstack-ctl start_ui --host remote_host_ip`
&lt;/code&gt;&lt;/pre&gt;

&lt;h2&gt;修复的Bugs&lt;/h2&gt;

&lt;p&gt;除了开发了4个新功能，v0.8还修复了超过23个之前的bugs：&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/zstackorg/zstack/issues/87&quot;&gt;VM is not able to be created, if VROffering is not set to isDefault=true&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/zstackorg/zstack/issues/86&quot;&gt;Need add UpdateVirtualRouterInstanceOffering API to update vr offering &lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/zstackorg/zstack/issues/85&quot;&gt;Delete L2 Failed: no matching network device was found&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/zstackorg/zstack/issues/84&quot;&gt;Delete VM&#39;s 2nd L3 won&#39;t stop VM&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/zstackorg/zstack/issues/82&quot;&gt;Delete normal account will delete private L3 VR (L3 is shared by admin)&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/zstackorg/zstack/issues/79&quot;&gt;Need set no live snapshot for CentOS 7&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/zstackorg/zstack/issues/78&quot;&gt;create volume template from snapshot failed when original volume is deleted in NFS ps&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/zstackorg/zstack/issues/77&quot;&gt;keep attach/detach nic might fail&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/zstackorg/zstack/issues/76&quot;&gt;If attach Nic failed in libvirt attach stage, the allocated ip will not return to database&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/zstackorg/zstack/issues/75&quot;&gt;Change VM Instance list UI: replace Hypervisor column to VmNic0 IP address&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/zstackorg/zstack/issues/74&quot;&gt;PS available capacity is not correct&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/zstackorg/zstack/issues/73&quot;&gt;Can&#39;t set fields=totalCapacity,availableCapacity,availablePhysicalCapacity for QueryPrimaryStorage&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/zstackorg/zstack/issues/72&quot;&gt;after iso installation, the root volume shows format &#39;raw&#39; while the real format is qcow2&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/zstackorg/zstack/issues/69&quot;&gt;VM console connection will be timeout, if ManagementNode use iptables to reject port access&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/zstackorg/zstack/issues/68&quot;&gt;Delete VM&#39;s last L3 uuid wont&#39; destroy VM&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/zstackorg/zstack/issues/66&quot;&gt;VR VM&#39;s volume size is not counted in Primary Storage space&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/zstackorg/zstack/issues/64&quot;&gt;Create Data Volume From Volume Snapshot failed when origianl voluem is deleted in Local Primary Storage&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/zstackorg/zstack/issues/62&quot;&gt;UpdateL3Network should be able to update &quot;system&quot; attribution&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/zstackorg/zstack/issues/61&quot;&gt;Qcow Volume image size is full size, when creating from volume offering&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/zstackorg/zstack/issues/57&quot;&gt;[API Request] APIUpdateHostMsg is required to update Host&#39;s information&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/zstackorg/zstack/issues/56&quot;&gt;URL format hint is wrong for IscsiFileSystemBackendPrimaryStorage&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/zstackorg/zstack/issues/30&quot;&gt;[0.7-preview] Add Storage Reconnect Action on UI&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/zstackorg/zstack/issues/29&quot;&gt;Add local disk support&lt;/a&gt;&lt;/p&gt;

&lt;h2&gt;报告bug&lt;/h2&gt;

&lt;p&gt;如果你在使用中发现任何问题或者有任何建议，请你到我们的&lt;a href=&quot;https://github.com/zstackorg/zstack/issues&quot;&gt;GitHub&lt;/a&gt;上告诉我们，谢谢！&lt;/p&gt;

&lt;p&gt;Enjoy～
ZStack 开发团队&lt;/p&gt;
</description>
        <pubDate>Tue, 04 Aug 2015 00:00:00 +0800</pubDate>
        <link>http://zstack.org/cn_blog/v0.8-release.html</link>
        <guid isPermaLink="true">http://zstack.org/cn_blog/v0.8-release.html</guid>
        
        
        <category>cn_blog</category>
        
      </item>
    
      <item>
        <title>Announcing ZStack v0.8</title>
        <description>&lt;p&gt;Hello everyone, I am Frank Zhang, the architect of ZStack. Today I am happy to announce that ZStack v0.8 is released.
In this release, ZStack introduces four new features:&lt;/p&gt;

&lt;h2&gt;Local Primary Storage&lt;/h2&gt;

&lt;p&gt;Users can use local disks of hosts as primary storage.&lt;/p&gt;

&lt;h3&gt;Add through UI&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/images/0.8/localstorage.png&quot; class=&quot;center-img img-responsive&quot;&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;select the type to &#39;LocalStorage&#39;&lt;/li&gt;
&lt;li&gt;input the hosts&#39; folder path.&lt;/li&gt;
&lt;/ol&gt;


&lt;h3&gt;Add through CLI&lt;/h3&gt;

&lt;p&gt;You can use AddLocalPrimaryStorage to add the local primary storage. For example:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;AddLocalPrimaryStorage zoneUuid=15d546efe84a499caa36b2f6a95d6b81 name=local url=/home/volumes
&lt;/code&gt;&lt;/pre&gt;

&lt;div class=&quot;bs-callout bs-callout-default&quot;&gt;
  &lt;h4&gt;URL&lt;/h4&gt;
  
  The local primary storage uses a folder to store VM volumes and images on hosts. When being attached to a cluster,
  the folder specified by the URL will be created on all hosts in the cluster if not existing.
&lt;/div&gt;




&lt;div class=&quot;bs-callout bs-callout-default&quot;&gt;
  &lt;h4&gt;Capacity&lt;/h4&gt;
  
  The total capacity and available capacity are summed from the corresponding capacity of each hosts. Unlike pool-based
  primary storage(e.g. NFS), you may encounter an allocation failure(not enough capacity) even if the total available capacity is bigger than
  the capacity you ask, because no host can solely provide that capacity. For example, say you have 2 hosts each of which has 10G available
  capacity, and you are creating a 15G volume; though the total available capacity is 20G, the case will fail because each host cannot
  provide the 15G capacity.
&lt;/div&gt;




&lt;div class=&quot;bs-callout bs-callout-warning&quot;&gt;
  &lt;h4&gt;No live migration and limited volume attaching&lt;/h4&gt;
  
  Because local primary storage is not network shared storage, it&#39;s not possible to lively migrate a VM from one host to another 
  until the storage migration feature is supported in future ZStack releases. Data volumes, whose states are Ready, can only be
  attached to VMs on the same host; that is to say, once a data volume is instantiated on a local storage, it can only be attached
  to VMs on the same host where it is instantiated.
&lt;/div&gt;


&lt;h2&gt;Dynamically attaching/detaching L3 networks&lt;/h2&gt;

&lt;p&gt;Beginning at this version, users can dynamically attach/detach a L3 network to/from a VM.&lt;/p&gt;

&lt;h3&gt;Attach through UI&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/images/0.8/2.png&quot; class=&quot;center-img img-responsive&quot;&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;select a VM and click button &#39;Action&#39;&lt;/li&gt;
&lt;li&gt;click &#39;Attach L3 Network&#39; on the drop-down menu&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;&lt;img src=&quot;/images/0.8/3.png&quot; class=&quot;center-img img-responsive&quot;&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;select the L3 networks you want to attach&lt;/li&gt;
&lt;li&gt;click button &#39;Attach&#39;&lt;/li&gt;
&lt;/ol&gt;


&lt;h3&gt;Attach through CLI&lt;/h3&gt;

&lt;p&gt;You can use AttachL3NetworkToVm to attach a L3 network to a VM. For example:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt;AttachL3NetworkToVm l3NetworkUuid=d791a3f662ac48a99b9e998136eed2a1 vmInstanceUuid=15d546efe84a499caa36b2f6a95d6b81
&lt;/code&gt;&lt;/pre&gt;

&lt;h3&gt;Detach through UI&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/images/0.8/4.png&quot; class=&quot;center-img img-responsive&quot;&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;select a VM and click button &#39;Action&#39;&lt;/li&gt;
&lt;li&gt;click &#39;Detach L3 Network&#39; on the drop-down menu&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;&lt;img src=&quot;/images/0.8/5.png&quot; class=&quot;center-img img-responsive&quot;&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;select the L3 networks you want to detach&lt;/li&gt;
&lt;li&gt;click button &#39;Detach&#39;&lt;/li&gt;
&lt;/ol&gt;


&lt;h3&gt;Detach through CLI&lt;/h3&gt;

&lt;p&gt;You can use &lt;code&gt;DetachL3NetworkFromVm&lt;/code&gt; to detach a L3 network from a VM. For example:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt;DetachL3NetworkFromVm vmNicUuid=d791a3f662ac48a99b9e998136eed2a1
&lt;/code&gt;&lt;/pre&gt;

&lt;div class=&quot;bs-callout bs-callout-info&quot;&gt;
  &lt;h4&gt;VM Nic UUID&lt;/h4&gt;
  
  Instead of a L3 network UUID and a VM UUID, `the DetachL3NetworkFromVm`
  use the `vmNicUuid` as the parameter because it implies both VM UUID and
  L3 network UUID.
&lt;/div&gt;


&lt;h2&gt;Identity Management&lt;/h2&gt;

&lt;p&gt;In this version, ZStack opens the identity management APIs which provide similar functions to AWS IAM. The details
of the identity management system can be found in &lt;a href=&quot;http://zstackdoc.readthedocs.org/en/latest/userManual/identity.html&quot;&gt;user manual -- identity chapter&lt;/a&gt;&lt;/p&gt;

&lt;h2&gt;Change the instance offering of the VM&lt;/h2&gt;

&lt;p&gt;In this version, users can change the instance offering of a VM.&lt;/p&gt;

&lt;h3&gt;Change through UI&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;../../images/0.8/6.png&quot; class=&quot;center-img img-responsive&quot;&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;select a VM and click button &#39;Action&#39;&lt;/li&gt;
&lt;li&gt;click &#39;Change Instance Offering&#39; on the drop-down menu&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;&lt;img src=&quot;../../images/0.8/7.png&quot; class=&quot;center-img img-responsive&quot;&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;select the instance offering you want to change&lt;/li&gt;
&lt;li&gt;click the button &#39;Change&#39;&lt;/li&gt;
&lt;/ol&gt;


&lt;h3&gt;Change through CLI&lt;/h3&gt;

&lt;p&gt;You can use ChangeInstanceOffering to change the instance offering of a VM. For example:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt;ChangeInstanceOffering vmInstanceUuid=f9837cfbde574a7ab512ab3283d8da60 instanceOfferingUuid=d791a3f662ac48a99b9e998136eed2a1
&lt;/code&gt;&lt;/pre&gt;

&lt;div class=&quot;bs-callout bs-callout-info&quot;&gt;
  &lt;h4&gt;A stop/start is required&lt;/h4&gt;
  
  If you change the instance offering while the VM is running, you need to stop/start the VM to make the change takes effect.
&lt;/div&gt;


&lt;h2&gt;Seamless Upgrade&lt;/h2&gt;

&lt;div class=&quot;bs-callout bs-callout-warning&quot;&gt;
  &lt;h4&gt;Backup Database&lt;/h4&gt;
  
  Before performing any upgrade instructions, please backup the current database. This is very &lt;b&gt;IMPORTANT&lt;/b&gt;!
  Though ZStack will automatically backup the current database during upgrade, we strongly recommend you to manually backup the
  database in case any error happens. You can backup the database following:
  
  &lt;pre&gt;&lt;code&gt;mysqldump -u root -proot_password --host mysql_ip --port mysql_port zstack &gt; path_to_db_dump.sql&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;




&lt;div class=&quot;bs-callout bs-callout-info&quot;&gt;
  &lt;h4&gt;Cleanup browser cache after upgrading the UI&lt;/h4&gt;
  
  Yoy may need to clean up the browser cache after upgrading the UI, otherwise the new UI features may not be available.
&lt;/div&gt;


&lt;h3&gt;Upgrade by quick script&lt;/h3&gt;

&lt;p&gt;If you have only one management node, you can upgrade it by ZStack&#39;s installation script:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;zstack-ctl stop_node
wget --no-check-certificate https://download.zstack.org/releases/0.8/0.8.0/zstack-install-0.8.0.sh
wget --no-check-certificate https://download.zstack.org/releases/0.8/0.8.0/zstack-all-in-one-0.8.0.tgz
bash zstack-install-0.8.0.sh -u -f zstack-all-in-one-0.8.0.tgz
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Be patient for a few minutes, the script will upgrade the database, management node, zstack-cli, zstack-ctl and zstack-dashboard.&lt;/p&gt;

&lt;h3&gt;Upgrade by zstack-ctl&lt;/h3&gt;

&lt;h4&gt;1. Upgrade the first management node&lt;/h4&gt;

&lt;p&gt;Perform below instructions on one of your management node:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;mkdir -p zstack-0.8
cd zstack-0.8
&lt;/code&gt;&lt;/pre&gt;

&lt;div class=&quot;bs-callout bs-callout-info&quot;&gt;
  &lt;h4&gt;Install zstack-ctl if you are using 0.6 version&lt;/h4&gt;
  
  wget --no-check-certificate https://download.zstack.org/releases/0.7/rc2/zstackctl-0.7.tar.gz
  /var/lib/zstack/virtualenv/zstackctl/bin/pip install --ignore-installed zstackctl-0.7.tar.gz
  
&lt;/div&gt;


&lt;pre&gt;&lt;code&gt;wget --no-check-certificate https://download.zstack.org/releases/0.8/0.8.0/zstack.war
zstack-ctl upgrade_management_node --war-file zstack.war
&lt;/code&gt;&lt;/pre&gt;

&lt;h4&gt;2. Upgrade the database&lt;/h4&gt;

&lt;p&gt;Make sure you have backup the current database following instructions on the top of this page. Then perform:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;zstack-ctl upgrade_db
&lt;/code&gt;&lt;/pre&gt;

&lt;div class=&quot;bs-callout bs-callout-info&quot;&gt;
  &lt;h4&gt;You can start the node now if you only have one management node&lt;/h4&gt;
  If you have only one management node, you can run &lt;pre&gt;&lt;code&gt;zstack-ctl start_node&lt;/code&gt;&lt;/pre&gt; to start the ZStack now. If you have
  other management nodes to upgrade, continue to perform following instructions.
&lt;/div&gt;


&lt;h4&gt;3. Upgrade other management nodes&lt;/h4&gt;

&lt;p&gt;If you have management nodes running on remote machines, run below commands for each node&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;zstack-ctl upgrade_management_node --war-file path_to_the_war --host remote_host_ip
&lt;/code&gt;&lt;/pre&gt;

&lt;h4&gt;4. Upgrade UI&lt;/h4&gt;

&lt;div class=&quot;bs-callout bs-callout-info&quot;&gt;
  &lt;h4&gt;Stop UI&lt;/h4&gt;
  
  If you are using 0.6, stop the UI by &lt;code&gt;/etc/init.d/zstack-dashboard stop&lt;/code&gt;; if 0.7, stop the UI by &lt;code&gt;zstack-ctl stop_ui&lt;/code&gt;
&lt;/div&gt;


&lt;p&gt;Upgrade your UI on local machine by:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;zstack-ctl install_ui
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;or&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;zstack-ctl install_ui --host remote_machine_ip
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;if the UI is installed on a remote machine.&lt;/p&gt;

&lt;h4&gt;5. Start management nodes&lt;/h4&gt;

&lt;p&gt;Now all your management nodes have been successfully upgraded to the 0.8 RC2. You can start them by &lt;code&gt;zstack-ctl start_node&lt;/code&gt; and
&lt;code&gt;zstack-ctl start_node --host remote_host_ip&lt;/code&gt;&lt;/p&gt;

&lt;div class=&quot;bs-callout bs-callout-info&quot;&gt;
  &lt;h4&gt;Agents will be automatically upgraded after starting management nodes&lt;/h4&gt;
  You don&#39;t need to bother with agent upgrade; they will be upgraded after management nodes reconnect them.
&lt;/div&gt;


&lt;h4&gt;6. Start UI&lt;/h4&gt;

&lt;p&gt;Now you can start the UI by &lt;code&gt;zstack-ctl start_ui&lt;/code&gt; on the local host or &lt;code&gt;zstack-ctl start_ui --host remote_host_ip&lt;/code&gt; on the remote host.&lt;/p&gt;

&lt;h2&gt;Bug fixes&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/zstackorg/zstack/issues/87&quot;&gt;VM is not able to be created, if VROffering is not set to isDefault=true&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/zstackorg/zstack/issues/86&quot;&gt;Need add UpdateVirtualRouterInstanceOffering API to update vr offering &lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/zstackorg/zstack/issues/85&quot;&gt;Delete L2 Failed: no matching network device was found&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/zstackorg/zstack/issues/84&quot;&gt;Delete VM&#39;s 2nd L3 won&#39;t stop VM&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/zstackorg/zstack/issues/82&quot;&gt;Delete normal account will delete private L3 VR (L3 is shared by admin)&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/zstackorg/zstack/issues/79&quot;&gt;Need set no live snapshot for CentOS 7&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/zstackorg/zstack/issues/78&quot;&gt;create volume template from snapshot failed when original volume is deleted in NFS ps&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/zstackorg/zstack/issues/77&quot;&gt;keep attach/detach nic might fail&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/zstackorg/zstack/issues/76&quot;&gt;If attach Nic failed in libvirt attach stage, the allocated ip will not return to database&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/zstackorg/zstack/issues/75&quot;&gt;Change VM Instance list UI: replace Hypervisor column to VmNic0 IP address&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/zstackorg/zstack/issues/74&quot;&gt;PS available capacity is not correct&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/zstackorg/zstack/issues/73&quot;&gt;Can&#39;t set fields=totalCapacity,availableCapacity,availablePhysicalCapacity for QueryPrimaryStorage&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/zstackorg/zstack/issues/72&quot;&gt;after iso installation, the root volume shows format &#39;raw&#39; while the real format is qcow2&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/zstackorg/zstack/issues/69&quot;&gt;VM console connection will be timeout, if ManagementNode use iptables to reject port access&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/zstackorg/zstack/issues/68&quot;&gt;Delete VM&#39;s last L3 uuid wont&#39; destroy VM&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/zstackorg/zstack/issues/66&quot;&gt;VR VM&#39;s volume size is not counted in Primary Storage space&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/zstackorg/zstack/issues/64&quot;&gt;Create Data Volume From Volume Snapshot failed when origianl voluem is deleted in Local Primary Storage&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/zstackorg/zstack/issues/62&quot;&gt;UpdateL3Network should be able to update &quot;system&quot; attribution&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/zstackorg/zstack/issues/61&quot;&gt;Qcow Volume image size is full size, when creating from volume offering&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/zstackorg/zstack/issues/57&quot;&gt;[API Request] APIUpdateHostMsg is required to update Host&#39;s information&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/zstackorg/zstack/issues/56&quot;&gt;URL format hint is wrong for IscsiFileSystemBackendPrimaryStorage&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/zstackorg/zstack/issues/30&quot;&gt;[0.7-preview] Add Storage Reconnect Action on UI&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/zstackorg/zstack/issues/29&quot;&gt;Add local disk support&lt;/a&gt;&lt;/p&gt;

&lt;h2&gt;Bug Report&lt;/h2&gt;

&lt;p&gt;If you find any bugs, please open a ticket on &lt;a href=&quot;https://github.com/zstackorg/zstack/issues&quot;&gt;GitHub&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Mon, 03 Aug 2015 00:00:00 +0800</pubDate>
        <link>http://zstack.org/blog/v0.8.html</link>
        <guid isPermaLink="true">http://zstack.org/blog/v0.8.html</guid>
        
        
        <category>blog</category>
        
      </item>
    
      <item>
        <title>Announcing ZStack v0.8</title>
        <description>&lt;p&gt;Hello everyone, I am Frank Zhang, the architect of ZStack. Today I am happy to announce that ZStack v0.8 is released.
In this release, ZStack introduces four new features:&lt;/p&gt;

&lt;h2&gt;Local Primary Storage&lt;/h2&gt;

&lt;p&gt;Users can use local disks of hosts as primary storage.&lt;/p&gt;

&lt;h3&gt;Add through UI&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/images/0.8/localstorage.png&quot; class=&quot;center-img img-responsive&quot;&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;select the type to &#39;LocalStorage&#39;&lt;/li&gt;
&lt;li&gt;input the hosts&#39; folder path.&lt;/li&gt;
&lt;/ol&gt;


&lt;h3&gt;Add through CLI&lt;/h3&gt;

&lt;p&gt;You can use AddLocalPrimaryStorage to add the local primary storage. For example:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;AddLocalPrimaryStorage zoneUuid=15d546efe84a499caa36b2f6a95d6b81 name=local url=/home/volumes
&lt;/code&gt;&lt;/pre&gt;

&lt;div class=&quot;bs-callout bs-callout-default&quot;&gt;
  &lt;h4&gt;URL&lt;/h4&gt;
  
  The local primary storage uses a folder to store VM volumes and images on hosts. When being attached to a cluster,
  the folder specified by the URL will be created on all hosts in the cluster if not existing.
&lt;/div&gt;




&lt;div class=&quot;bs-callout bs-callout-default&quot;&gt;
  &lt;h4&gt;Capacity&lt;/h4&gt;
  
  The total capacity and available capacity are summed from the corresponding capacity of each hosts. Unlike pool-based
  primary storage(e.g. NFS), you may encounter an allocation failure(not enough capacity) even if the total available capacity is bigger than
  the capacity you ask, because no host can solely provide that capacity. For example, say you have 2 hosts each of which has 10G available
  capacity, and you are creating a 15G volume; though the total available capacity is 20G, the case will fail because each host cannot
  provide the 15G capacity.
&lt;/div&gt;




&lt;div class=&quot;bs-callout bs-callout-warning&quot;&gt;
  &lt;h4&gt;No live migration and limited volume attaching&lt;/h4&gt;
  
  Because local primary storage is not network shared storage, it&#39;s not possible to lively migrate a VM from one host to another 
  until the storage migration feature is supported in future ZStack releases. Data volumes, whose states are Ready, can only be
  attached to VMs on the same host; that is to say, once a data volume is instantiated on a local storage, it can only be attached
  to VMs on the same host where it is instantiated.
&lt;/div&gt;


&lt;h2&gt;Dynamically attaching/detaching L3 networks&lt;/h2&gt;

&lt;p&gt;Beginning at this version, users can dynamically attach/detach a L3 network to/from a VM.&lt;/p&gt;

&lt;h3&gt;Attach through UI&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/images/0.8/2.png&quot; class=&quot;center-img img-responsive&quot;&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;select a VM and click button &#39;Action&#39;&lt;/li&gt;
&lt;li&gt;click &#39;Attach L3 Network&#39; on the drop-down menu&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;&lt;img src=&quot;/images/0.8/3.png&quot; class=&quot;center-img img-responsive&quot;&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;select the L3 networks you want to attach&lt;/li&gt;
&lt;li&gt;click button &#39;Attach&#39;&lt;/li&gt;
&lt;/ol&gt;


&lt;h3&gt;Attach through CLI&lt;/h3&gt;

&lt;p&gt;You can use AttachL3NetworkToVm to attach a L3 network to a VM. For example:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt;AttachL3NetworkToVm l3NetworkUuid=d791a3f662ac48a99b9e998136eed2a1 vmInstanceUuid=15d546efe84a499caa36b2f6a95d6b81
&lt;/code&gt;&lt;/pre&gt;

&lt;h3&gt;Detach through UI&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/images/0.8/4.png&quot; class=&quot;center-img img-responsive&quot;&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;select a VM and click button &#39;Action&#39;&lt;/li&gt;
&lt;li&gt;click &#39;Detach L3 Network&#39; on the drop-down menu&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;&lt;img src=&quot;/images/0.8/5.png&quot; class=&quot;center-img img-responsive&quot;&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;select the L3 networks you want to detach&lt;/li&gt;
&lt;li&gt;click button &#39;Detach&#39;&lt;/li&gt;
&lt;/ol&gt;


&lt;h3&gt;Detach through CLI&lt;/h3&gt;

&lt;p&gt;You can use &lt;code&gt;DetachL3NetworkFromVm&lt;/code&gt; to detach a L3 network from a VM. For example:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt;DetachL3NetworkFromVm vmNicUuid=d791a3f662ac48a99b9e998136eed2a1
&lt;/code&gt;&lt;/pre&gt;

&lt;div class=&quot;bs-callout bs-callout-info&quot;&gt;
  &lt;h4&gt;VM Nic UUID&lt;/h4&gt;
  
  Instead of a L3 network UUID and a VM UUID, `the DetachL3NetworkFromVm`
  use the `vmNicUuid` as the parameter because it implies both VM UUID and
  L3 network UUID.
&lt;/div&gt;


&lt;h2&gt;Identity Management&lt;/h2&gt;

&lt;p&gt;In this version, ZStack opens the identity management APIs which provide similar functions to AWS IAM. The details
of the identity management system can be found in &lt;a href=&quot;http://zstackdoc.readthedocs.org/en/latest/userManual/identity.html&quot;&gt;user manual -- identity chapter&lt;/a&gt;&lt;/p&gt;

&lt;h2&gt;Change the instance offering of the VM&lt;/h2&gt;

&lt;p&gt;In this version, users can change the instance offering of a VM.&lt;/p&gt;

&lt;h3&gt;Change through UI&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;../../images/0.8/6.png&quot; class=&quot;center-img img-responsive&quot;&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;select a VM and click button &#39;Action&#39;&lt;/li&gt;
&lt;li&gt;click &#39;Change Instance Offering&#39; on the drop-down menu&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;&lt;img src=&quot;../../images/0.8/7.png&quot; class=&quot;center-img img-responsive&quot;&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;select the instance offering you want to change&lt;/li&gt;
&lt;li&gt;click the button &#39;Change&#39;&lt;/li&gt;
&lt;/ol&gt;


&lt;h3&gt;Change through CLI&lt;/h3&gt;

&lt;p&gt;You can use ChangeInstanceOffering to change the instance offering of a VM. For example:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt;ChangeInstanceOffering vmInstanceUuid=f9837cfbde574a7ab512ab3283d8da60 instanceOfferingUuid=d791a3f662ac48a99b9e998136eed2a1
&lt;/code&gt;&lt;/pre&gt;

&lt;div class=&quot;bs-callout bs-callout-info&quot;&gt;
  &lt;h4&gt;A stop/start is required&lt;/h4&gt;
  
  If you change the instance offering while the VM is running, you need to stop/start the VM to make the change takes effect.
&lt;/div&gt;


&lt;h2&gt;Seamless Upgrade&lt;/h2&gt;

&lt;div class=&quot;bs-callout bs-callout-warning&quot;&gt;
  &lt;h4&gt;Backup Database&lt;/h4&gt;
  
  Before performing any upgrade instructions, please backup the current database. This is very &lt;b&gt;IMPORTANT&lt;/b&gt;!
  Though ZStack will automatically backup the current database during upgrade, we strongly recommend you to manually backup the
  database in case any error happens. You can backup the database following:
  
  &lt;pre&gt;&lt;code&gt;mysqldump -u root -proot_password --host mysql_ip --port mysql_port zstack &gt; path_to_db_dump.sql&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;




&lt;div class=&quot;bs-callout bs-callout-info&quot;&gt;
  &lt;h4&gt;Cleanup browser cache after upgrading the UI&lt;/h4&gt;
  
  Yoy may need to clean up the browser cache after upgrading the UI, otherwise the new UI features may not be available.
&lt;/div&gt;


&lt;h3&gt;Upgrade by quick script&lt;/h3&gt;

&lt;p&gt;If you have only one management node, you can upgrade it by ZStack&#39;s installation script:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;zstack-ctl stop_node
wget --no-check-certificate https://download.zstack.org/releases/0.8/0.8.0/zstack-install-0.8.0.sh
wget --no-check-certificate https://download.zstack.org/releases/0.8/0.8.0/zstack-all-in-one-0.8.0.tgz
bash zstack-install-0.8.0.sh -u -f zstack-all-in-one-0.8.0.tgz
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Be patient for a few minutes, the script will upgrade the database, management node, zstack-cli, zstack-ctl and zstack-dashboard.&lt;/p&gt;

&lt;h3&gt;Upgrade by zstack-ctl&lt;/h3&gt;

&lt;h4&gt;1. Upgrade the first management node&lt;/h4&gt;

&lt;p&gt;Perform below instructions on one of your management node:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;mkdir -p zstack-0.8
cd zstack-0.8
&lt;/code&gt;&lt;/pre&gt;

&lt;div class=&quot;bs-callout bs-callout-info&quot;&gt;
  &lt;h4&gt;Install zstack-ctl if you are using 0.6 version&lt;/h4&gt;
  
  wget --no-check-certificate https://download.zstack.org/releases/0.7/rc2/zstackctl-0.7.tar.gz
  /var/lib/zstack/virtualenv/zstackctl/bin/pip install --ignore-installed zstackctl-0.7.tar.gz
  
&lt;/div&gt;


&lt;pre&gt;&lt;code&gt;wget --no-check-certificate https://download.zstack.org/releases/0.8/0.8.0/zstack.war
zstack-ctl upgrade_management_node --war-file zstack.war
&lt;/code&gt;&lt;/pre&gt;

&lt;h4&gt;2. Upgrade the database&lt;/h4&gt;

&lt;p&gt;Make sure you have backup the current database following instructions on the top of this page. Then perform:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;zstack-ctl upgrade_db
&lt;/code&gt;&lt;/pre&gt;

&lt;div class=&quot;bs-callout bs-callout-info&quot;&gt;
  &lt;h4&gt;You can start the node now if you only have one management node&lt;/h4&gt;
  If you have only one management node, you can run &lt;pre&gt;&lt;code&gt;zstack-ctl start_node&lt;/code&gt;&lt;/pre&gt; to start the ZStack now. If you have
  other management nodes to upgrade, continue to perform following instructions.
&lt;/div&gt;


&lt;h4&gt;3. Upgrade other management nodes&lt;/h4&gt;

&lt;p&gt;If you have management nodes running on remote machines, run below commands for each node&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;zstack-ctl upgrade_management_node --war-file path_to_the_war --host remote_host_ip
&lt;/code&gt;&lt;/pre&gt;

&lt;h4&gt;4. Upgrade UI&lt;/h4&gt;

&lt;div class=&quot;bs-callout bs-callout-info&quot;&gt;
  &lt;h4&gt;Stop UI&lt;/h4&gt;
  
  If you are using 0.6, stop the UI by &lt;code&gt;/etc/init.d/zstack-dashboard stop&lt;/code&gt;; if 0.7, stop the UI by &lt;code&gt;zstack-ctl stop_ui&lt;/code&gt;
&lt;/div&gt;


&lt;p&gt;Upgrade your UI on local machine by:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;zstack-ctl install_ui
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;or&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;zstack-ctl install_ui --host remote_machine_ip
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;if the UI is installed on a remote machine.&lt;/p&gt;

&lt;h4&gt;5. Start management nodes&lt;/h4&gt;

&lt;p&gt;Now all your management nodes have been successfully upgraded to the 0.8 RC2. You can start them by &lt;code&gt;zstack-ctl start_node&lt;/code&gt; and
&lt;code&gt;zstack-ctl start_node --host remote_host_ip&lt;/code&gt;&lt;/p&gt;

&lt;div class=&quot;bs-callout bs-callout-info&quot;&gt;
  &lt;h4&gt;Agents will be automatically upgraded after starting management nodes&lt;/h4&gt;
  You don&#39;t need to bother with agent upgrade; they will be upgraded after management nodes reconnect them.
&lt;/div&gt;


&lt;h4&gt;6. Start UI&lt;/h4&gt;

&lt;p&gt;Now you can start the UI by &lt;code&gt;zstack-ctl start_ui&lt;/code&gt; on the local host or &lt;code&gt;zstack-ctl start_ui --host remote_host_ip&lt;/code&gt; on the remote host.&lt;/p&gt;

&lt;h2&gt;Bug fixes&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/zstackorg/zstack/issues/87&quot;&gt;VM is not able to be created, if VROffering is not set to isDefault=true&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/zstackorg/zstack/issues/86&quot;&gt;Need add UpdateVirtualRouterInstanceOffering API to update vr offering &lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/zstackorg/zstack/issues/85&quot;&gt;Delete L2 Failed: no matching network device was found&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/zstackorg/zstack/issues/84&quot;&gt;Delete VM&#39;s 2nd L3 won&#39;t stop VM&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/zstackorg/zstack/issues/82&quot;&gt;Delete normal account will delete private L3 VR (L3 is shared by admin)&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/zstackorg/zstack/issues/79&quot;&gt;Need set no live snapshot for CentOS 7&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/zstackorg/zstack/issues/78&quot;&gt;create volume template from snapshot failed when original volume is deleted in NFS ps&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/zstackorg/zstack/issues/77&quot;&gt;keep attach/detach nic might fail&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/zstackorg/zstack/issues/76&quot;&gt;If attach Nic failed in libvirt attach stage, the allocated ip will not return to database&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/zstackorg/zstack/issues/75&quot;&gt;Change VM Instance list UI: replace Hypervisor column to VmNic0 IP address&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/zstackorg/zstack/issues/74&quot;&gt;PS available capacity is not correct&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/zstackorg/zstack/issues/73&quot;&gt;Can&#39;t set fields=totalCapacity,availableCapacity,availablePhysicalCapacity for QueryPrimaryStorage&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/zstackorg/zstack/issues/72&quot;&gt;after iso installation, the root volume shows format &#39;raw&#39; while the real format is qcow2&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/zstackorg/zstack/issues/69&quot;&gt;VM console connection will be timeout, if ManagementNode use iptables to reject port access&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/zstackorg/zstack/issues/68&quot;&gt;Delete VM&#39;s last L3 uuid wont&#39; destroy VM&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/zstackorg/zstack/issues/66&quot;&gt;VR VM&#39;s volume size is not counted in Primary Storage space&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/zstackorg/zstack/issues/64&quot;&gt;Create Data Volume From Volume Snapshot failed when origianl voluem is deleted in Local Primary Storage&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/zstackorg/zstack/issues/62&quot;&gt;UpdateL3Network should be able to update &quot;system&quot; attribution&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/zstackorg/zstack/issues/61&quot;&gt;Qcow Volume image size is full size, when creating from volume offering&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/zstackorg/zstack/issues/57&quot;&gt;[API Request] APIUpdateHostMsg is required to update Host&#39;s information&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/zstackorg/zstack/issues/56&quot;&gt;URL format hint is wrong for IscsiFileSystemBackendPrimaryStorage&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/zstackorg/zstack/issues/30&quot;&gt;[0.7-preview] Add Storage Reconnect Action on UI&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/zstackorg/zstack/issues/29&quot;&gt;Add local disk support&lt;/a&gt;&lt;/p&gt;

&lt;h2&gt;Bug Report&lt;/h2&gt;

&lt;p&gt;If you find any bugs, please open a ticket on &lt;a href=&quot;https://github.com/zstackorg/zstack/issues&quot;&gt;GitHub&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Mon, 03 Aug 2015 00:00:00 +0800</pubDate>
        <link>http://zstack.org/cn/blog/v0.8.html</link>
        <guid isPermaLink="true">http://zstack.org/cn/blog/v0.8.html</guid>
        
        
        <category>blog</category>
        
      </item>
    
  </channel>
</rss>
