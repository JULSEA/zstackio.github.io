<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>ZStack</title>
    <description>ZStack is open source IaaS software managing resources of compute, storage, networking throughout a datacenter all by APIs.</description>
    <link>http://zstack.org/</link>
    <atom:link href="http://zstack.org/feed.xml" rel="self" type="application/rss+xml" />
    <pubDate>Wed, 25 May 2016 10:34:39 +0800</pubDate>
    <lastBuildDate>Wed, 25 May 2016 10:34:39 +0800</lastBuildDate>
    <generator>Jekyll v2.5.3</generator>
    
      <item>
        <title>ZStack v1.2 release</title>
        <description>&lt;p&gt;Hello everyone, I am Frank Zhang, the architect of ZStack. Today I am happy to
announce that ZStack v1.2 is released.&lt;/p&gt;

&lt;h1&gt;New Features And Enhancements&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#eip&quot;&gt;Distributed EIP&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#smp&quot;&gt;Shared Mount Point Primary Storage&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#db&quot;&gt;Database Periodical Backup&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#systemd&quot;&gt;Systemd Support&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#cachemode&quot;&gt;KVM Cache Mode&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#userdata&quot;&gt;AWS EC2 Like Userdata&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;h1&gt;Installation And Upgrade&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#install&quot;&gt;Installation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#upgrade&quot;&gt;Upgrade&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;h2 id=&quot;eip&quot;&gt; 1. Distributed EIP &lt;/h2&gt;


&lt;p&gt;Distributed EIP is added as a new service type of flat network provider in this version. Users can apply an EIP(normally a public IP) to a VM on a private network dynamically without using a virtual router VM, since the EIP is created on the host where the VM is running. As the EIPs are scattered on different hosts we call it distributed EIP. Below is an overall architecutre showing that the distributed EIP is implemented through the Linux network namspace.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/1.2/eipoverview.png&quot; class=&quot;center-img img-responsive&quot;&gt;&lt;/p&gt;

&lt;p&gt;To enable the distributed EIP, users need to select the EIP service of the flat network service provider at the last step of creating a L3 network.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/1.2/eip1.png&quot; class=&quot;center-img img-responsive&quot;&gt;
&lt;img src=&quot;/images/1.2/eip2.png&quot; class=&quot;center-img img-responsive&quot;&gt;&lt;/p&gt;

&lt;p&gt;For the usage of EIP, please refer the chapter 15 of the tutorial &lt;a href=&quot;http://zstack.org/tutorials/ec2-ui.html&quot;&gt;Amazon EC2 classic EIP zone&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;smp&quot;&gt;2. Shared Mount Point Primary Storage&lt;/h2&gt;


&lt;p&gt;In order to support vast POSIX compatible distributed filesystems, we add a new type of primary storage called shared mount point storage in this version. The idea is that users can use any distributed filesystems(e.g. OCFS2, GlusterFS, MooseFS) as primary storage, as long as those filesystems are pre-mounted on the KVM hosts.&lt;/p&gt;

&lt;p&gt;Below is an example of adding a shared mount point primary storage, the URL is the absolute path of the folder where the distributed filesystem is
mounted.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;we suggest users changing /etc/rc.local or /etc/fstab to make the distributed filesystem automatically mount during Linux booting, otherwise you
will be unable to start a created VM or create a VM on your local storage.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;/images/1.2/smp.png&quot; class=&quot;center-img img-responsive&quot;&gt;&lt;/p&gt;

&lt;h2 id=&quot;db&quot;&gt;3. Database Periodical Backup&lt;/h2&gt;


&lt;p&gt;In this version, a new command &lt;code&gt;zstack-ctl dump_mysql&lt;/code&gt; is added for users to backup ZStack database.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    [root@172-20-12-46 ~]# zstack-ctl dump_mysql -h
    usage: zstackctl dump_mysql [-h] [--file-name FILE_NAME]
                          [--keep-amount KEEP_AMOUNT]

    optional arguments:
    -h, --help            show this help message and exit
    --file-name FILE_NAME
                        The filename you want to save the database, default is
                        &#39;zstack-backup-db&#39;
    --keep-amount KEEP_AMOUNT
                        The amount of backup files you want to keep, older
                        backup files will be deleted, default number is 60
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Once the all-in-one installation is done, a &lt;code&gt;crontab&lt;/code&gt; task is created as following to periodically backup your database:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;  30 0,12 * * * zstack-ctl dump_mysql --keep-amount 14
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;you can change the setting by &lt;code&gt;crontab -e&lt;/code&gt;.&lt;/p&gt;

&lt;h2 id=&quot;systemd&quot;&gt;4. Systemd Support&lt;/h2&gt;


&lt;p&gt;Systemd is supported in this version. You can use &lt;code&gt;systemctl&lt;/code&gt; to control ZStack management nodes&#39; lifecycle and make them start during Linux booting.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/1.2/systemd.png&quot; class=&quot;center-img img-responsive&quot;&gt;&lt;/p&gt;

&lt;h2 id=&quot;cachemode&quot;&gt;5. KVM Cache Mode&lt;/h2&gt;


&lt;p&gt;In this version, users can configure the &lt;code&gt;cache mode&lt;/code&gt; of volumes on the KVM hosts by a global configuration. There are three modes supported now:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;none&lt;/strong&gt;: With caching mode set to none, the host page cache is disabled, but the disk write cache is enabled for the guest. In this mode, the write performance in the guest is optimal because write operations bypass the host page cache and go directly to the disk write cache. If the disk write cache is battery-backed, or if the applications or storage stack in the guest transfer data properly (either through fsync operations or file system barriers), then data integrity can be ensured. However, because the host page cache is disabled, the read performance in the guest would not be as good as in the modes where the host page cache is enabled, such as writethrough mode.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;writeback&lt;/strong&gt;: With caching set to writeback mode, both the host page cache and the disk write cache are enabled for the guest. Because of this, the I/O performance for applications running in the guest is good, but the data is not protected in a power failure. As a result, this caching mode is recommended only for temporary data where potential data loss is not a concern.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;writethrough&lt;/strong&gt;: writethrough mode is the default caching mode. With caching set to writethrough mode, the host page cache is enabled, but the disk write cache is disabled for the guest. Consequently, this caching mode ensures data integrity even if the applications and storage stack in the guest do not transfer data to permanent storage properly (either through fsync operations or file system barriers). Because the host page cache is enabled in this mode, the read performance for applications running in the guest is generally better. However, the write performance might be reduced because the disk write cache is disabled.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;For details of KVM cache mode you can refer &lt;a href=&quot;https://www.ibm.com/support/knowledgecenter/linuxonibm/liaat/liaatbpkvmguestcache.htm&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The global configuration can be changed through UI or command line:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/1.2/cachemode.png&quot; class=&quot;center-img img-responsive&quot;&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt;UpdateGlobalConfig category=kvm name=vm.cacheMode value=writethrough
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;userdata&quot;&gt;6. AWS EC2 Way To Access Userdata&lt;/h2&gt;


&lt;p&gt;Beginning at the version 1.0, ZStack supports AWS EC2 userdata with cloud-init. However, the original way to access userdata is CloudStack like, which requires users to change the default configuration of cloud-init package and sometimes make people confused. In this version, ZStack starts using AWS EC2 way to distribute userdata, which means users can access userdata/metadata by a special IP address(169.254.169.254). It&#39;s also the default way that cloud-init fetches userdata, so users can directly use cloud-init built-in packages from CentOS and Ubuntu, without any modification.&lt;/p&gt;

&lt;h2 id=&quot;install&quot;&gt;7. Installation&lt;/h2&gt;


&lt;p&gt;You can install the 1.2 release by:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    wget http://download.zstack.org/releases/1.2/1.2.0/zstack-installer-1.2.0.bin
    bash zstack-installer-1.2.0.bin
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;upgrade&quot;&gt;8. Upgrade&lt;/h2&gt;


&lt;p&gt;You can upgrade your previous ZStack to 1.2 by:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    wget http://download.zstack.org/releases/1.2/1.2.0/zstack-installer-1.2.0.bin
    bash zstack-installer-1.2.0.bin -u
&lt;/code&gt;&lt;/pre&gt;
</description>
        <pubDate>Wed, 04 May 2016 00:00:00 +0800</pubDate>
        <link>http://zstack.org/blog/v1.2.html</link>
        <guid isPermaLink="true">http://zstack.org/blog/v1.2.html</guid>
        
        
        <category>blog</category>
        
      </item>
    
      <item>
        <title>ZStack v1.2 release</title>
        <description>&lt;p&gt;Hello everyone, I am Frank Zhang, the architect of ZStack. Today I am happy to
announce that ZStack v1.2 is released.&lt;/p&gt;

&lt;h1&gt;New Features And Enhancements&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#eip&quot;&gt;Distributed EIP&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#smp&quot;&gt;Shared Mount Point Primary Storage&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#db&quot;&gt;Database Periodical Backup&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#systemd&quot;&gt;Systemd Support&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#cachemode&quot;&gt;KVM Cache Mode&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#userdata&quot;&gt;AWS EC2 Like Userdata&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;h1&gt;Installation And Upgrade&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#install&quot;&gt;Installation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#upgrade&quot;&gt;Upgrade&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;h2 id=&quot;eip&quot;&gt; 1. Distributed EIP &lt;/h2&gt;


&lt;p&gt;Distributed EIP is added as a new service type of flat network provider in this version. Users can apply an EIP(normally a public IP) to a VM on a private network dynamically without using a virtual router VM, since the EIP is created on the host where the VM is running. As the EIPs are scattered on different hosts we call it distributed EIP. Below is an overall architecutre showing that the distributed EIP is implemented through the Linux network namspace.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/1.2/eipoverview.png&quot; class=&quot;center-img img-responsive&quot;&gt;&lt;/p&gt;

&lt;p&gt;To enable the distributed EIP, users need to select the EIP service of the flat network service provider at the last step of creating a L3 network.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/1.2/eip1.png&quot; class=&quot;center-img img-responsive&quot;&gt;
&lt;img src=&quot;/images/1.2/eip2.png&quot; class=&quot;center-img img-responsive&quot;&gt;&lt;/p&gt;

&lt;p&gt;For the usage of EIP, please refer the chapter 15 of the tutorial &lt;a href=&quot;http://zstack.org/tutorials/ec2-ui.html&quot;&gt;Amazon EC2 classic EIP zone&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;smp&quot;&gt;2. Shared Mount Point Primary Storage&lt;/h2&gt;


&lt;p&gt;In order to support vast POSIX compatible distributed filesystems, we add a new type of primary storage called shared mount point storage in this version. The idea is that users can use any distributed filesystems(e.g. OCFS2, GlusterFS, MooseFS) as primary storage, as long as those filesystems are pre-mounted on the KVM hosts.&lt;/p&gt;

&lt;p&gt;Below is an example of adding a shared mount point primary storage, the URL is the absolute path of the folder where the distributed filesystem is
mounted.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;we suggest users changing /etc/rc.local or /etc/fstab to make the distributed filesystem automatically mount during Linux booting, otherwise you
will be unable to start a created VM or create a VM on your local storage.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;/images/1.2/smp.png&quot; class=&quot;center-img img-responsive&quot;&gt;&lt;/p&gt;

&lt;h2 id=&quot;db&quot;&gt;3. Database Periodical Backup&lt;/h2&gt;


&lt;p&gt;In this version, a new command &lt;code&gt;zstack-ctl dump_mysql&lt;/code&gt; is added for users to backup ZStack database.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    [root@172-20-12-46 ~]# zstack-ctl dump_mysql -h
    usage: zstackctl dump_mysql [-h] [--file-name FILE_NAME]
                          [--keep-amount KEEP_AMOUNT]

    optional arguments:
    -h, --help            show this help message and exit
    --file-name FILE_NAME
                        The filename you want to save the database, default is
                        &#39;zstack-backup-db&#39;
    --keep-amount KEEP_AMOUNT
                        The amount of backup files you want to keep, older
                        backup files will be deleted, default number is 60
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Once the all-in-one installation is done, a &lt;code&gt;crontab&lt;/code&gt; task is created as following to periodically backup your database:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;  30 0,12 * * * zstack-ctl dump_mysql --keep-amount 14
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;you can change the setting by &lt;code&gt;crontab -e&lt;/code&gt;.&lt;/p&gt;

&lt;h2 id=&quot;systemd&quot;&gt;4. Systemd Support&lt;/h2&gt;


&lt;p&gt;Systemd is supported in this version. You can use &lt;code&gt;systemctl&lt;/code&gt; to control ZStack management nodes&#39; lifecycle and make them start during Linux booting.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/1.2/systemd.png&quot; class=&quot;center-img img-responsive&quot;&gt;&lt;/p&gt;

&lt;h2 id=&quot;cachemode&quot;&gt;5. KVM Cache Mode&lt;/h2&gt;


&lt;p&gt;In this version, users can configure the &lt;code&gt;cache mode&lt;/code&gt; of volumes on the KVM hosts by a global configuration. There are three modes supported now:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;none&lt;/strong&gt;: With caching mode set to none, the host page cache is disabled, but the disk write cache is enabled for the guest. In this mode, the write performance in the guest is optimal because write operations bypass the host page cache and go directly to the disk write cache. If the disk write cache is battery-backed, or if the applications or storage stack in the guest transfer data properly (either through fsync operations or file system barriers), then data integrity can be ensured. However, because the host page cache is disabled, the read performance in the guest would not be as good as in the modes where the host page cache is enabled, such as writethrough mode.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;writeback&lt;/strong&gt;: With caching set to writeback mode, both the host page cache and the disk write cache are enabled for the guest. Because of this, the I/O performance for applications running in the guest is good, but the data is not protected in a power failure. As a result, this caching mode is recommended only for temporary data where potential data loss is not a concern.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;writethrough&lt;/strong&gt;: writethrough mode is the default caching mode. With caching set to writethrough mode, the host page cache is enabled, but the disk write cache is disabled for the guest. Consequently, this caching mode ensures data integrity even if the applications and storage stack in the guest do not transfer data to permanent storage properly (either through fsync operations or file system barriers). Because the host page cache is enabled in this mode, the read performance for applications running in the guest is generally better. However, the write performance might be reduced because the disk write cache is disabled.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;For details of KVM cache mode you can refer &lt;a href=&quot;https://www.ibm.com/support/knowledgecenter/linuxonibm/liaat/liaatbpkvmguestcache.htm&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The global configuration can be changed through UI or command line:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/1.2/cachemode.png&quot; class=&quot;center-img img-responsive&quot;&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt;UpdateGlobalConfig category=kvm name=vm.cacheMode value=writethrough
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;userdata&quot;&gt;6. AWS EC2 Way To Access Userdata&lt;/h2&gt;


&lt;p&gt;Beginning at the version 1.0, ZStack supports AWS EC2 userdata with cloud-init. However, the original way to access userdata is CloudStack like, which requires users to change the default configuration of cloud-init package and sometimes make people confused. In this version, ZStack starts using AWS EC2 way to distribute userdata, which means users can access userdata/metadata by a special IP address(169.254.169.254). It&#39;s also the default way that cloud-init fetches userdata, so users can directly use cloud-init built-in packages from CentOS and Ubuntu, without any modification.&lt;/p&gt;

&lt;h2 id=&quot;install&quot;&gt;7. Installation&lt;/h2&gt;


&lt;p&gt;You can install the 1.2 release by:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    wget http://download.zstack.org/releases/1.2/1.2.0/zstack-installer-1.2.0.bin
    bash zstack-installer-1.2.0.bin
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;upgrade&quot;&gt;8. Upgrade&lt;/h2&gt;


&lt;p&gt;You can upgrade your previous ZStack to 1.2 by:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    wget http://download.zstack.org/releases/1.2/1.2.0/zstack-installer-1.2.0.bin
    bash zstack-installer-1.2.0.bin -u
&lt;/code&gt;&lt;/pre&gt;
</description>
        <pubDate>Wed, 04 May 2016 00:00:00 +0800</pubDate>
        <link>http://zstack.org/cn/blog/v1.2.html</link>
        <guid isPermaLink="true">http://zstack.org/cn/blog/v1.2.html</guid>
        
        
        <category>blog</category>
        
      </item>
    
      <item>
        <title>ZStack v1.2 发布</title>
        <description>&lt;h2&gt;ZStack 1.2 版本今天正式发布&lt;/h2&gt;

&lt;p&gt;ZStack 1.2 版本今天发布，欢迎大家下载试用。在该版中，我们修复了1.1版本中发现的bug，并增加了分布EIP、shared mountpoint主存储支持、数据库自动备份、Systemd支持等新功能。用户不再需要使用Virtual Router就可以使用EIP网络模式，也可以无缝的使用GlusterFS、MooseFS、OCFS2等分布式文件系统作为主存储。具体细节参考以下章节。&lt;/p&gt;

&lt;h2&gt;新增功能&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#eip&quot;&gt;分布式EIP&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#smp&quot;&gt;Shared Mountpoint主存储&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#database&quot;&gt;数据库定时备份&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#systemd&quot;&gt;Systemd支持&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#cachemode&quot;&gt;KVM缓存模式配置&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#userdata&quot;&gt;AWS EC2模式Userdata支持&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;h2&gt;安装升级&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#install&quot;&gt;安装&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#offlineinstall&quot;&gt;离线安装&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#upgrade&quot;&gt;升级&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;h3 id=&quot;eip&quot;&gt;1. 分布式EIP &lt;/h3&gt;


&lt;p&gt;在1.0版本中，我们增加了一个新的网络服务组件：FlatNetwork Provider，可以提供分布式DHCP支持。在1.2版本中，我们继续增强了该provider的功能，加入了分布式EIP支持。通过这种方式，用户无需再使用传统的virtual router方式就可以部署EIP网络模型，拥有独立的私有网络，并将公网IP地址映射到私有网络的中的云主机去。ZStack的分布式EIP通过Linux的network namespace实现，原理图如下：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/1.2/eipoverview.png&quot; class=&quot;center-img img-responsive&quot;&gt;&lt;/p&gt;

&lt;p&gt;要使用分布式EIP，用户只需在创建L3网络的时候，选择Flat Network Service Provider作为网络服务提供组件，并选择加载EIP服务即可。步骤如图：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/1.2/eip1.png&quot; class=&quot;center-img img-responsive&quot;&gt;
&lt;img src=&quot;/images/1.2/eip2.png&quot; class=&quot;center-img img-responsive&quot;&gt;&lt;/p&gt;

&lt;p&gt;要绑定EIP到私有网络的云主机，参考教程&lt;a href=&quot;http://zstack.org/cn/tutorials/ec2-ui.html&quot;&gt;经典Amazon EC2 EIP环境&lt;/a&gt;第15节即可。&lt;/p&gt;

&lt;h3 id=&quot;smp&quot;&gt;2. Shared Mountpoint主存储&lt;/h3&gt;


&lt;p&gt;在1.2版本中，我们新增了一种主存储(Primary Storage)类型：Shared Mountpoint Storage。通过该主存储，ZStack可以支持任何符合POSIX文件系统规范的分布式文件系统，例如大家熟悉的GlusterFS、MooseFS、OCFS2等。&lt;/p&gt;

&lt;p&gt;在使用前，用户需要先部署好你所使用的分布式文件系统，并将它mount到所有host相同的目录上，例如将GlusterFS mount到所有host的/glusterfs_dir目录中。在添加主存储时，选择类型“SharedMountPoint”并输入对应目录绝对路径即可，如图：&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;我们建议用户把mount分布式文件系统的命令放到每个host的/etc/rc.local或/etc/fstab当中，以避免host重启后，分布式文件系统没有挂载的情况。&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;/images/1.2/smp.png&quot; class=&quot;center-img img-responsive&quot;&gt;&lt;/p&gt;

&lt;h3 id=&quot;database&quot;&gt;3. 数据库定时备份&lt;/h3&gt;


&lt;p&gt;在1.2版本中，我们提供了一个新的命令&lt;code&gt;zstack-ctl dump_mysql&lt;/code&gt;为用户备份ZStack的数据库：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    [root@172-20-12-46 ~]# zstack-ctl dump_mysql -h
    usage: zstackctl dump_mysql [-h] [--file-name FILE_NAME]
                                [--keep-amount KEEP_AMOUNT]

    optional arguments:
        -h, --help            show this help message and exit
        --file-name FILE_NAME
                              The filename you want to save the database, default is
                              &#39;zstack-backup-db&#39;
        --keep-amount KEEP_AMOUNT
                              The amount of backup files you want to keep, older
                              backup files will be deleted, default number is 60
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在使用zstack all-in-one安装包安装后，我们会默认建立一个&lt;code&gt;crontab&lt;/code&gt;任务定时备份数据库，其设置为：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;30 0,12 * * * zstack-ctl dump_mysql --keep-amount 14
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;用户可以用&lt;code&gt;crontab -l&lt;/code&gt;的命令查看，或用&lt;code&gt;crontab -e&lt;/code&gt;修改。&lt;/p&gt;

&lt;h3 id=&quot;cachemode&quot;&gt;5. KVM cache mode选项&lt;/h3&gt;


&lt;p&gt;在1.2版本中，用户可以通过修改全局设置的来指定启动云主机时，KVM对云盘使用的缓存模式。支持三种模式：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;none:云主机不使用物理机的页面缓存，直接访问存储，不带cache。&lt;strong&gt;默认模式&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;writethrough:物理机的页面缓存工作在透写模式，数据完全写入云主机存储设备后，才返回成功。&lt;/li&gt;
&lt;li&gt;writeback:云主机使用了物理机的页面缓存机制，数据写入物理机页面缓存即报告给云主机返回成功。&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;KVM cache mode的具体解释可以参考&lt;a href=&quot;https://www.ibm.com/support/knowledgecenter/linuxonibm/liaat/liaatbpkvmguestcache.htm&quot;&gt;这篇文章&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;要修改该选项，可以使用UI：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/1.2/cachemode.png&quot; class=&quot;center-img img-responsive&quot;&gt;&lt;/p&gt;

&lt;p&gt;或命令行：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt;UpdateGlobalConfig category=kvm name=vm.cacheMode value=writethrough
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&quot;userdata&quot;&gt;6. AWS EC2模式Userdata支持&lt;/h3&gt;


&lt;p&gt;在1.0版本中，我们加入了对userdata的支持，使用的是CloudStack默认，用户需要修改cloud-init配置文件才能使用。在1.2版本中，我们将userdata的支持方式换成了AWS EC2模式，即云主机操作系统可以通过169.254.169.254这个IP地址获得userdata。该模式是cloud-init的默认模式，用户只需安装cloud-init包，无需修改任何配置就可以直接使用。此外，用户也可以从Ubuntu和Centos的官方网站上下载预装cloud-init的镜像直接使用。&lt;/p&gt;

&lt;h3 id=&quot;systemd&quot;&gt;7. Systemd支持&lt;/h3&gt;


&lt;p&gt;在1.2版本中，我们加入了对systemd的支持，用户可以通过&lt;code&gt;systemctl&lt;/code&gt;来控制zstack管理节点的生命周期。这同时修复了安装了zstack管理节点关机慢的问题。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/1.2/systemd.png&quot; class=&quot;center-img img-responsive&quot;&gt;&lt;/p&gt;

&lt;h3 id=&quot;install&quot;&gt;8. 安装&lt;/h3&gt;


&lt;p&gt;你可以通过下面方式安装：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    wget http://download.zstack.org/releases/1.2/1.2.0/zstack-installer-1.2.0.bin
    bash zstack-installer-1.2.0.bin -R aliyun
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;&lt;p&gt;这里&lt;code&gt;-R aliyun&lt;/code&gt;参数指定使用阿里云的源进行安装，你也可以使用&lt;code&gt;-R 163&lt;/code&gt;使用网易的源。我们推荐使用阿里云的源&lt;/p&gt;&lt;/blockquote&gt;

&lt;h3 id=&quot;offlineinstall&quot;&gt;9. 离线安装&lt;/h3&gt;


&lt;p&gt;针对内网用户,以及访问Internet速度较慢的用户.ZStack 1.2 提供了离线安装方式.
用户若需要离线安装ZStack,需要在目标管理节点和计算节点上安装CentOS 7.2 ZStack社区版.&lt;/p&gt;

&lt;p&gt;然后在下载了第8步中的 zstack-installer 之后,你可以通过下面方式快速完成离线安装：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    bash zstack-installer-1.2.0.bin -o
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;具体的离线安装教程和CentOS 7.2 ZStack社区版请阅读: &lt;a href=&quot;./offline-install-zstack-from-custom-iso.html&quot;&gt;ZStack离线安装教程&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;upgrade&quot;&gt;10. 升级 &lt;/h3&gt;


&lt;p&gt;一如既往的，我们支持一键无缝升级：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    wget http://download.zstack.org/releases/1.2/1.2.0/zstack-installer-1.2.0.bin
    bash zstack-installer-1.2.0.bin -u
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;多节点升级中的zstack.war请等待正式版发布。&lt;/p&gt;
</description>
        <pubDate>Fri, 29 Apr 2016 00:00:00 +0800</pubDate>
        <link>http://zstack.org/cn_blog/v1.2.html</link>
        <guid isPermaLink="true">http://zstack.org/cn_blog/v1.2.html</guid>
        
        
        <category>cn_blog</category>
        
      </item>
    
      <item>
        <title>ZStack v1.2 RC1 发布</title>
        <description>&lt;h2&gt;ZStack 1.2 RC1 版本今天发布&lt;/h2&gt;

&lt;p&gt;ZStack 1.2 RC1 版本今天发布，欢迎大家下载试用。在该版中，我们修复了1.1版本中发现的bug，并增加了分布EIP、shared mountpoint主存储支持、数据库自动备份、Systemd支持等新功能。用户不再需要使用Virtual Router就可以使用EIP网络模式，也可以无缝的使用GlusterFS、MooseFS、OCFS2等分布式文件系统作为主存储。具体细节参考以下章节。&lt;/p&gt;

&lt;h2&gt;新增功能&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#eip&quot;&gt;分布式EIP&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#smp&quot;&gt;Shared Mountpoint主存储&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#database&quot;&gt;数据库定时备份&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#systemd&quot;&gt;Systemed支持&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#cachemode&quot;&gt;KVM缓存模式配置&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#userdata&quot;&gt;AWS EC2模式Userdata支持&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;h2&gt;安装升级&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#install&quot;&gt;安装&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#offlineinstall&quot;&gt;离线安装&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#upgrade&quot;&gt;升级&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;h3 id=&quot;eip&quot;&gt;1. 分布式EIP &lt;/h3&gt;


&lt;p&gt;在1.0版本中，我们增加了一个新的网络服务组件：FlatNetwork Provider，可以提供分布式DHCP支持。在1.2版本中，我们继续增强了该provider的功能，加入了分布式EIP支持。通过这种方式，用户无需再使用传统的virtual router方式就可以部署EIP网络模型，拥有独立的私有网络，并将公网IP地址映射到私有网络的中的云主机去。ZStack的分布式EIP通过Linux的network namespace实现，原理图如下：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/1.2/eipoverview.png&quot; class=&quot;center-img img-responsive&quot;&gt;&lt;/p&gt;

&lt;p&gt;要使用分布式EIP，用户只需在创建L3网络的时候，选择Flat Network Service Provider作为网络服务提供组件，并选择加载EIP服务即可。步骤如图：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/1.2/eip1.png&quot; class=&quot;center-img img-responsive&quot;&gt;
&lt;img src=&quot;/images/1.2/eip2.png&quot; class=&quot;center-img img-responsive&quot;&gt;&lt;/p&gt;

&lt;p&gt;要绑定EIP到私有网络的云主机，参考教程&lt;a href=&quot;http://zstack.org/cn/tutorials/ec2-ui.html&quot;&gt;经典Amazon EC2 EIP环境&lt;/a&gt;第15节即可。&lt;/p&gt;

&lt;h3 id=&quot;smp&quot;&gt;2. Shared Mountpoint主存储&lt;/h3&gt;


&lt;p&gt;在1.2版本中，我们新增了一种主存储(Primary Storage)类型：Shared Mountpoint Storage。通过该主存储，ZStack可以支持任何符合POSIX文件系统规范的分布式文件系统，例如大家熟悉的GlusterFS、MooseFS、OCFS2等。&lt;/p&gt;

&lt;p&gt;在使用前，用户需要先部署好你所使用的分布式文件系统，并将它mount到所有host相同的目录上，例如将GlusterFS mount到所有host的/glusterfs_dir目录中。在添加主存储时，选择类型“SharedMountPoint”并输入对应目录绝对路径即可，如图：&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;我们建议用户把mount分布式文件系统的命令放到每个host的/etc/rc.local或/etc/fstab当中，以避免host重启后，分布式文件系统没有挂载的情况。&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;/images/1.2/smp.png&quot; class=&quot;center-img img-responsive&quot;&gt;&lt;/p&gt;

&lt;h3 id=&quot;database&quot;&gt;3. 数据库定时备份&lt;/h3&gt;


&lt;p&gt;在1.2版本中，我们提供了一个新的命令&lt;code&gt;zstack-ctl dump_mysql&lt;/code&gt;为用户备份ZStack的数据库：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    [root@172-20-12-46 ~]# zstack-ctl dump_mysql -h
    usage: zstackctl dump_mysql [-h] [--file-name FILE_NAME]
                                [--keep-amount KEEP_AMOUNT]

    optional arguments:
        -h, --help            show this help message and exit
        --file-name FILE_NAME
                              The filename you want to save the database, default is
                              &#39;zstack-backup-db&#39;
        --keep-amount KEEP_AMOUNT
                              The amount of backup files you want to keep, older
                              backup files will be deleted, default number is 60
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在使用zstack all-in-one安装包安装后，我们会默认建立一个&lt;code&gt;crontab&lt;/code&gt;任务定时备份数据库，其设置为：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;30 0,12 * * * zstack-ctl dump_mysql --keep-amount 14
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;用户可以用&lt;code&gt;crontab -l&lt;/code&gt;的命令查看，或用&lt;code&gt;crontab -e&lt;/code&gt;修改。&lt;/p&gt;

&lt;h3 id=&quot;cachemode&quot;&gt;5. KVM cache mode选项&lt;/h3&gt;


&lt;p&gt;在1.2版本中，用户可以通过修改全局设置的来指定启动云主机时，KVM对云盘使用的缓存模式。支持三种模式：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;none:云主机不使用物理机的页面缓存，直接访问存储，不带cache。&lt;strong&gt;默认模式&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;writethrough:物理机的页面缓存工作在透写模式，数据完全写入云主机存储设备后，才返回成功。&lt;/li&gt;
&lt;li&gt;writeback:云主机使用了物理机的页面缓存机制，数据写入物理机页面缓存即报告给云主机返回成功。&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;KVM cache mode的具体解释可以参考&lt;a href=&quot;https://www.ibm.com/support/knowledgecenter/linuxonibm/liaat/liaatbpkvmguestcache.htm&quot;&gt;这篇文章&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;要修改该选项，可以使用UI：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/1.2/cachemode.png&quot; class=&quot;center-img img-responsive&quot;&gt;&lt;/p&gt;

&lt;p&gt;或命令行：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt;UpdateGlobalConfig category=kvm name=vm.cacheMode value=writethrough
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&quot;userdata&quot;&gt;6. AWS EC2模式Userdata支持&lt;/h3&gt;


&lt;p&gt;在1.0版本中，我们加入了对userdata的支持，使用的是CloudStack默认，用户需要修改cloud-init配置文件才能使用。在1.2版本中，我们将userdata的支持方式换成了AWS EC2模式，即云主机操作系统可以通过169.254.169.254这个IP地址获得userdata。该模式是cloud-init的默认模式，用户只需安装cloud-init包，无需修改任何配置就可以直接使用。此外，用户也可以从Ubuntu和Centos的官方网站上下载预装cloud-init的镜像直接使用。&lt;/p&gt;

&lt;h3 id=&quot;systemd&quot;&gt;7. Systemd支持&lt;/h3&gt;


&lt;p&gt;在1.2版本中，我们加入了对systemd的支持，用户可以通过&lt;code&gt;systemctl&lt;/code&gt;来控制zstack管理节点的生命周期。这同时修复了安装了zstack管理节点关机慢的问题。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/1.2/systemd.png&quot; class=&quot;center-img img-responsive&quot;&gt;&lt;/p&gt;

&lt;h3 id=&quot;install&quot;&gt;8. 安装&lt;/h3&gt;


&lt;p&gt;你可以通过下面方式安装：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    wget http://download.zstack.org/releases/1.2/1.2.0/rc2/zstack-installer-1.2.0-rc2.bin
    bash zstack-installer-1.2.0-rc2.bin -R aliyun
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;&lt;p&gt;这里&lt;code&gt;-R aliyun&lt;/code&gt;参数指定使用阿里云的源进行安装，你也可以使用&lt;code&gt;-R 163&lt;/code&gt;使用网易的源。我们推荐使用阿里云的源&lt;/p&gt;&lt;/blockquote&gt;

&lt;h3 id=&quot;offlineinstall&quot;&gt;9. 离线安装&lt;/h3&gt;


&lt;p&gt;针对内网用户,以及访问Internet速度较慢的用户.ZStack 1.2 提供了离线安装方式.
用户若需要离线安装ZStack,需要在目标管理节点和计算节点上安装CentOS 7.2 ZStack社区版.&lt;/p&gt;

&lt;p&gt;然后在下载了第8步中的 zstack-installer 之后,你可以通过下面方式快速完成离线安装：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    bash zstack-installer-1.2.0-rc2.bin -o
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;具体的离线安装教程和CentOS 7.2 ZStack社区版请阅读: &lt;a href=&quot;./offline-install-zstack-from-custom-iso.html&quot;&gt;ZStack离线安装教程&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;upgrade&quot;&gt;10. 升级 &lt;/h3&gt;


&lt;p&gt;一如既往的，我们支持一键无缝升级：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    wget http://download.zstack.org/releases/1.2/1.2.0/rc2/zstack-installer-1.2.0-rc2.bin
    bash zstack-installer-1.2.0-rc2.bin -u
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;多节点升级中的zstack.war请等待正式版发布。&lt;/p&gt;
</description>
        <pubDate>Fri, 22 Apr 2016 00:00:00 +0800</pubDate>
        <link>http://zstack.org/cn_blog/v1.2-rc1.html</link>
        <guid isPermaLink="true">http://zstack.org/cn_blog/v1.2-rc1.html</guid>
        
        
        <category>cn_blog</category>
        
      </item>
    
      <item>
        <title>ZStack v1.1.2 发布</title>
        <description>&lt;h2&gt;ZStack 1.1.2 版本今天发布&lt;/h2&gt;

&lt;p&gt;ZStack v1.1.2 修复了部分 zstack-ctl 的功能,以便搭建ZStack HA的集群.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#zstackctl&quot;&gt;使用zstack-ctl修改管理节点IP地址&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#install&quot;&gt;一键安装&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#offlineinstall&quot;&gt;离线安装&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#upgrade&quot;&gt;无缝升级&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;h2&gt;功能提升&lt;/h2&gt;

&lt;h3 id=&quot;zstackctl&quot;&gt;1. 使用zstack-ctl修改管理节点IP地址&lt;/h3&gt;


&lt;p&gt;在之前的版本中,如果管理节点IP变更,我们需要用户手动修改 zstack.properties的文件.
从1.1 版本开始,我们提供了全新的&lt;code&gt;zstack-ctl change_ip&lt;/code&gt;来帮助用户修改管理节点,
数据库,消息总线的IP地址. 例如:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[root@172-20-11-73 ~]# zstack-ctl change_ip --ip 172.20.11.73
Update cloudbus server ip 172.20.11.73 in /usr/local/zstack/apache-tomcat/webapps/zstack/WEB-INF/classes/zstack.properties 
Update mysql new url jdbc:mysql://172.20.11.73:3306 in /usr/local/zstack/apache-tomcat/webapps/zstack/WEB-INF/classes/zstack.properties 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;如果数据库,消息总线使用了不同的IP地址,我们也可以使用该命令进行修改.具体的参数细节,请添加-h 参数获取:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[root@172-20-11-73 ~]# zstack-ctl change_ip -h
usage: zstackctl change_ip [-h] --ip IP [--kairosdb_ip KAIROSDB_IP]
                           [--cassandra_rpc_address CASSANDRA_RPC_ADDRESS]
                           [--cassandra_listen_address CASSANDRA_LISTEN_ADDRESS]
                           [--cloudbus_server_ip CLOUDBUS_SERVER_IP]
                           [--mysql_ip MYSQL_IP]

optional arguments:
  -h, --help            show this help message and exit
  --ip IP               The new IP address of management node.This operation
                        will update the new ip address to zstack, kairosdb and
                        cassandra config file
  --kairosdb_ip KAIROSDB_IP
                        The new IP address of kairosdb, default will use value
                        from --ip
  --cassandra_rpc_address CASSANDRA_RPC_ADDRESS
                        The new IP address of cassandra_rpc_address, default
                        will use value from --ip
  --cassandra_listen_address CASSANDRA_LISTEN_ADDRESS
                        The new IP address of cassandra_listen_address,
                        default will use value from --ip
  --cloudbus_server_ip CLOUDBUS_SERVER_IP
                        The new IP address of CloudBus.serverIp.0, default
                        will use value from --ip
  --mysql_ip MYSQL_IP   The new IP address of DB.url, default will use value
                        from --ip
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&quot;install&quot;&gt; 2. 安装 &lt;/h3&gt;


&lt;p&gt;你可以通过下面方式安装：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    wget http://download.zstack.org/releases/1.1/1.1.2/zstack-installer-1.1.2.bin -O zstack-installer-1.1.2.bin
    bash zstack-installer-1.1.2.bin -R aliyun
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;&lt;p&gt;这里&lt;code&gt;-R aliyun&lt;/code&gt;参数指定使用阿里云的源进行安装，你也可以使用&lt;code&gt;-R 163&lt;/code&gt;使用网易的源。我们推荐使用阿里云的源&lt;/p&gt;&lt;/blockquote&gt;

&lt;h3 id=&quot;offlineinstall&quot;&gt; 3. 离线安装 ZStack &lt;/h3&gt;


&lt;p&gt;针对内网用户,以及访问Internet速度较慢的用户.ZStack 1.1 提供了离线安装方式.
用户若需要离线安装ZStack,需要在目标管理节点和计算节点上安装CentOS 7.2 ZStack社区版.&lt;/p&gt;

&lt;p&gt;然后在下载了第8步中的 zstack-installer 之后,你可以通过下面方式快速完成离线安装：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    bash zstack-installer-1.1.2.bin -o
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;具体的离线安装教程和CentOS 7.2 ZStack社区版请阅读: &lt;a href=&quot;./offline-install-zstack-from-custom-iso.html&quot;&gt;ZStack离线安装教程&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;upgrade&quot;&gt; 4. 升级 &lt;/h3&gt;


&lt;p&gt;一如既往的，我们支持一键无缝升级：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    wget http://download.zstack.org/releases/1.1/1.1.2/zstack-installer-1.1.2.bin -O zstack-installer-1.1.2.bin
    bash zstack-installer-1.1.2.bin -u
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;多节点升级中的zstack.war 可以从如下链接获取: http://download.zstack.org/releases/1.1/1.1.2/zstack.war&lt;/p&gt;
</description>
        <pubDate>Sat, 09 Apr 2016 00:00:00 +0800</pubDate>
        <link>http://zstack.org/cn_blog/v1.1.2.html</link>
        <guid isPermaLink="true">http://zstack.org/cn_blog/v1.1.2.html</guid>
        
        
        <category>cn_blog</category>
        
      </item>
    
      <item>
        <title>ZStack v1.1.1 发布</title>
        <description>&lt;h2&gt;ZStack 1.1.1 版本今天发布&lt;/h2&gt;

&lt;p&gt;ZStack v1.1.1 修复了 v1.1.0里两个缺陷: 默认超时过短和添加Ceph存储出错. 建议用户升级.&lt;/p&gt;

&lt;h2&gt;修复缺陷&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#timeout&quot;&gt;默认超时过短&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#ceph&quot;&gt;添加Ceph存储出错&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;h2&gt;功能提升&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#zstackctl&quot;&gt;使用zstack-ctl修改管理节点IP地址&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;h3 id=&quot;timeout&quot;&gt;1. 默认超时过短 &lt;/h3&gt;


&lt;p&gt;1.1.0 版本中默认超时存在一个缺陷,导致API的默认超时仅为300秒. 1.1.1版本已经把耗时API超时时间加长到了默认3个小时,例如下载Image的API,创建Image的API.&lt;/p&gt;

&lt;h3 id=&quot;ceph&quot;&gt;2. 添加Ceph存储出错 &lt;/h3&gt;


&lt;p&gt;1.1.0 版本中的资源添加优化程序存在一个缺陷,导致ceph存储添加可能出现错误. 1.1.1版本已经修复了该错误.&lt;/p&gt;

&lt;h3 id=&quot;zstackctl&quot;&gt;3. 使用zstack-ctl修改管理节点IP地址&lt;/h3&gt;


&lt;p&gt;在之前的版本中,如果管理节点IP变更,我们需要用户手动修改 zstack.properties的文件.
从1.1 版本开始,我们提供了全新的&lt;code&gt;zstack-ctl change_ip&lt;/code&gt;来帮助用户修改管理节点,
数据库,消息总线的IP地址. 例如:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[root@172-20-11-73 ~]# zstack-ctl change_ip --ip 172.20.11.73
Update cloudbus server ip 172.20.11.73 in /usr/local/zstack/apache-tomcat/webapps/zstack/WEB-INF/classes/zstack.properties 
Update mysql new url jdbc:mysql://172.20.11.73:3306 in /usr/local/zstack/apache-tomcat/webapps/zstack/WEB-INF/classes/zstack.properties 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;如果数据库,消息总线使用了不同的IP地址,我们也可以使用该命令进行修改.具体的参数细节,请添加-h 参数获取:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[root@172-20-11-73 ~]# zstack-ctl change_ip -h
usage: zstackctl change_ip [-h] --ip IP [--kairosdb_ip KAIROSDB_IP]
                           [--cassandra_rpc_address CASSANDRA_RPC_ADDRESS]
                           [--cassandra_listen_address CASSANDRA_LISTEN_ADDRESS]
                           [--cloudbus_server_ip CLOUDBUS_SERVER_IP]
                           [--mysql_ip MYSQL_IP]

optional arguments:
  -h, --help            show this help message and exit
  --ip IP               The new IP address of management node.This operation
                        will update the new ip address to zstack, kairosdb and
                        cassandra config file
  --kairosdb_ip KAIROSDB_IP
                        The new IP address of kairosdb, default will use value
                        from --ip
  --cassandra_rpc_address CASSANDRA_RPC_ADDRESS
                        The new IP address of cassandra_rpc_address, default
                        will use value from --ip
  --cassandra_listen_address CASSANDRA_LISTEN_ADDRESS
                        The new IP address of cassandra_listen_address,
                        default will use value from --ip
  --cloudbus_server_ip CLOUDBUS_SERVER_IP
                        The new IP address of CloudBus.serverIp.0, default
                        will use value from --ip
  --mysql_ip MYSQL_IP   The new IP address of DB.url, default will use value
                        from --ip
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&quot;install&quot;&gt; 4. 安装 &lt;/h3&gt;


&lt;p&gt;你可以通过下面方式安装：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    wget http://download.zstack.org/releases/1.1/1.1.1/zstack-installer-1.1.1.bin -O zstack-installer-1.1.1.bin
    bash zstack-installer-1.1.1.bin -R aliyun
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;&lt;p&gt;这里&lt;code&gt;-R aliyun&lt;/code&gt;参数指定使用阿里云的源进行安装，你也可以使用&lt;code&gt;-R 163&lt;/code&gt;使用网易的源。我们推荐使用阿里云的源&lt;/p&gt;&lt;/blockquote&gt;

&lt;h3 id=&quot;install&quot;&gt; 5. 离线安装 ZStack &lt;/h3&gt;


&lt;p&gt;针对内网用户,以及访问Internet速度较慢的用户.ZStack 1.1 提供了离线安装方式.
用户若需要离线安装ZStack,需要在目标管理节点和计算节点上安装CentOS 7.2 ZStack社区版.&lt;/p&gt;

&lt;p&gt;然后在下载了第8步中的 zstack-installer 之后,你可以通过下面方式快速完成离线安装：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    bash zstack-installer-1.1.1.bin -o
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;具体的离线安装教程和CentOS 7.2 ZStack社区版请阅读: &lt;a href=&quot;./offline-install-zstack-from-custom-iso.html&quot;&gt;ZStack离线安装教程&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;upgrade&quot;&gt; 6. 升级 &lt;/h3&gt;


&lt;p&gt;一如既往的，我们支持一键无缝升级：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    wget http://download.zstack.org/releases/1.1/1.1.1/zstack-installer-1.1.1.bin -O zstack-installer-1.1.1.bin
    bash zstack-installer-1.1.1.bin -u
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;多节点升级中的zstack.war 可以从如下链接获取: http://download.zstack.org/releases/1.1/1.1.1/zstack.war&lt;/p&gt;
</description>
        <pubDate>Fri, 01 Apr 2016 00:00:00 +0800</pubDate>
        <link>http://zstack.org/cn_blog/v1.1.1.html</link>
        <guid isPermaLink="true">http://zstack.org/cn_blog/v1.1.1.html</guid>
        
        
        <category>cn_blog</category>
        
      </item>
    
      <item>
        <title>ZStack v1.1 release</title>
        <description>&lt;p&gt;Hello everyone, I am Frank Zhang, the architect of ZStack. Today I am happy to
announce that ZStack v1.1 is released.&lt;/p&gt;

&lt;h1&gt;New Features And Enhancements&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#ansible&quot;&gt;Ansible Optimization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#consoleproxy&quot;&gt;Console Proxy APIs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#apitimeout&quot;&gt;API Timeout Management&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#gc&quot;&gt;Garbage Collector&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#image&quot;&gt;15 Tiny Tryout Image&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#vr&quot;&gt;Virtual Router Image Upgrade&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;h1&gt;Installation And Upgrade&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#install&quot;&gt;Installation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#upgrade&quot;&gt;Upgrade&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#upgradevr&quot;&gt;Upgrade Virtual Router Provider To Flat Network Provider&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;h2 id=&quot;ansible&quot;&gt; 1. Ansible Optimization &lt;/h2&gt;


&lt;p&gt;In this version, we create customized deployers for all ZStack agents(i.e. kvmagent, backup storage agent) directly using Ansible SDK, instead of regular Ansible playbook YAML files. As the result, the speed of agent deployment gets significantly improved, because the deployer that is a Python application will try best to avoid unnecessary time-costing steps such as accessing YUM repo; the logging also gets better, each task will post messages to a logging URL before and after execution, and the error message will clearly state the error instead of flooding out all tasks status, which regular Ansible playbook YAML files normally do.&lt;/p&gt;

&lt;h2 id=&quot;consoleproxy&quot;&gt;2. Console Proxy APIs &lt;/h2&gt;


&lt;p&gt;Two new APIs are added for console proxy, &lt;code&gt;ReconnectConsoleProxyAgent&lt;/code&gt; and &lt;code&gt;QueryConsoleProxyAgent&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Users can use &lt;code&gt;ReconnectConsoleProxyAgent&lt;/code&gt; to redeploy console proxy agents:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;        &amp;gt;&amp;gt;&amp;gt;ReconnectConsoleProxyAgent 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;or use &lt;code&gt;QueryConsoleProxyAgent&lt;/code&gt; to query agents&#39; status:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;       &amp;gt;&amp;gt;&amp;gt;QueryConsoleProxyAgent 
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;apitimeout&quot;&gt;3. API Timeout Management&lt;/h2&gt;


&lt;p&gt;As ZStack consists of a lot of microservices which communicate with each other through async-messages, it&#39;s very hard to control API timeout because the API has no idea about internal messages entailed by itself. In this version, we add a central API timeout management framework that can connect an API to all entailed internal messages and HTTP requests, and that can propagate the API&#39;s timeout to the descendants. All APIs have default configurations, users can change a configuration by editing the &lt;code&gt;zstack.properties&lt;/code&gt; file, for example:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    ApiTimeout.org.zstack.header.image.APIAddImageMsg= org.zstack.header.storage.backup.DownloadImageMsg, org.zstack.storage.backup.sftp.SftpBackupStorageCommands$DownloadCmd, org.zstack.storage.ceph.backup.CephBackupStorageBase$DownloadCmd; 6h
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This example changes the timeout of API &lt;code&gt;org.zstack.header.image.APIAddImageMsg&lt;/code&gt; to six hours. However, this way is discouraged. In 1.2 version, we will allow users to configure APIs&#39; timeout through a new API.&lt;/p&gt;

&lt;h2 id=&quot;gc&quot;&gt;4. Garbage Collector&lt;/h2&gt;


&lt;p&gt;In this version, the VM related garbage collectors are enabled. Users can destroy a VM anytime no matter the connection status of the host. For example, you can delete a VM even the network connection to the host where the VM is running is lost. The garbage collector will save user operations which cannot be completed in current situation and re-execute them once the host&#39;s network connection recovers. The garbage collector can be triggered by time-based poll and events, for example, a host reconnect event and host delete event can both trigger a VM deleting garbage collector.&lt;/p&gt;

&lt;h2 id=&quot;image&quot;&gt;5. 15M Tiny Tryout Image&lt;/h2&gt;


&lt;p&gt;A new 15 tiny image is ready for quickly try out creating VMs. The image supports runtime attaching/detaching volumes and networks. The ACPID daemon is also included so you can gracefully shutdown a VM. You can download the image from:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    http://download.zstack.org/templates/zstack-image-1.2.qcow2
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;vr&quot;&gt;6. New Virtual Router Image&lt;/h2&gt;


&lt;p&gt;The virtual router image is upgraded to 1.1 version, you can download it from:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    http://download.zstack.org/templates/zstack-virtualrouter-1.1.0.qcow2
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;&lt;p&gt;NOTE: Users still using the old 0.9 version are not necessary to upgrade. However, we suggest all new users using the new version.&lt;/p&gt;&lt;/blockquote&gt;

&lt;h2 id=&quot;install&quot;&gt;7. Installation&lt;/h2&gt;


&lt;p&gt;You can install the 1.1 release by:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    wget http://download.zstack.org/releases/1.1/1.1.0/0331/zstack-installer-1.1.0-0331.bin -O zstack-installer-1.1.0.bin
    bash zstack-installer-1.1.0.bin
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;upgrade&quot;&gt;8. Upgrade&lt;/h2&gt;


&lt;p&gt;To upgrade your ZStack to 1.1, do:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    wget http://download.zstack.org/releases/1.1/1.1.0/0331/zstack-installer-1.1.0-0331.bin -O zstack-installer-1.1.0.bin
    bash zstack-installer-1.1.0.bin -u
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;upgradevr&quot;&gt;9. Upgrade Virtual Router Provider To Flat Network Provider&lt;/h2&gt;


&lt;p&gt;If you are currently using a flat network with a previous ZStack version, you can upgrade the L3 network using the flat network provider so
you won&#39;t need the virtual router VM anymore. Assume the UUID of your L3 network is 1a82c2691978476fa6cefa36bb9d4bfd, please follow
the below steps:&lt;/p&gt;

&lt;h4&gt;1. Obtain the UUID of the virtual rotuer provider&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;    &amp;gt;&amp;gt;&amp;gt;QueryNetworkServiceL3NetworkRef l3NetworkUuid=1a82c2691978476fa6cefa36bb9d4bfd
    {
        &quot;inventories&quot;: [
            {
                &quot;l3NetworkUuid&quot;: &quot;1a82c2691978476fa6cefa36bb9d4bfd&quot;,
                &quot;networkServiceProviderUuid&quot;: &quot;5d21ea0f39c04d6fb68cfaf5a37db4ad&quot;,
                &quot;networkServiceType&quot;: &quot;DNS&quot;
            },
            {
                &quot;l3NetworkUuid&quot;: &quot;1a82c2691978476fa6cefa36bb9d4bfd&quot;,
                &quot;networkServiceProviderUuid&quot;: &quot;5d21ea0f39c04d6fb68cfaf5a37db4ad&quot;,
                &quot;networkServiceType&quot;: &quot;DHCP&quot;
            }
        ],
        &quot;success&quot;: true
    }
&lt;/code&gt;&lt;/pre&gt;

&lt;h4&gt;2. Detach the virtual router provider from the L3 network&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;        &amp;gt;&amp;gt;&amp;gt;DetachNetworkServiceFromL3Network  l3NetworkUuid=1a82c2691978476fa6cefa36bb9d4bfd networkServices=&#39;{&quot;5d21ea0f39c04d6fb68cfaf5a37db4ad&quot;:[&quot;DHCP&quot;,&quot;DNS&quot;]}&#39;
         {
             &quot;inventory&quot;: {
                 &quot;createDate&quot;: &quot;Jan 30, 2016 3:01:03 PM&quot;,
                 &quot;dns&quot;: [
                     &quot;8.8.8.8&quot;
                 ],
                 &quot;ipRanges&quot;: [
                     {
                         &quot;createDate&quot;: &quot;Jan 30, 2016 3:01:04 PM&quot;,
                         &quot;endIp&quot;: &quot;192.168.201.199&quot;,
                         &quot;gateway&quot;: &quot;192.168.200.1&quot;,
                         &quot;l3NetworkUuid&quot;: &quot;1a82c2691978476fa6cefa36bb9d4bfd&quot;,
                         &quot;lastOpDate&quot;: &quot;Jan 30, 2016 3:01:04 PM&quot;,
                         &quot;name&quot;: &quot;ipr-dk7p&quot;,
                         &quot;netmask&quot;: &quot;255.255.252.0&quot;,
                         &quot;startIp&quot;: &quot;192.168.201.180&quot;,
                         &quot;uuid&quot;: &quot;ec5fd87dd80243fdabeeace847c04427&quot;
                     }
                 ],
                 &quot;l2NetworkUuid&quot;: &quot;9ec8cad681d1424fa7eda2447edae142&quot;,
                 &quot;lastOpDate&quot;: &quot;Jan 30, 2016 3:01:03 PM&quot;,
                 &quot;name&quot;: &quot;l3-etpz&quot;,
                 &quot;networkServices&quot;: [],
                 &quot;state&quot;: &quot;Enabled&quot;,
                 &quot;system&quot;: false,
                 &quot;type&quot;: &quot;L3BasicNetwork&quot;,
                 &quot;uuid&quot;: &quot;1a82c2691978476fa6cefa36bb9d4bfd&quot;,
                 &quot;zoneUuid&quot;: &quot;4a3a78b1b9f049948b79cf9e667f0af2&quot;
             },
             &quot;success&quot;: true
         }
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;&lt;p&gt;the parameter &lt;code&gt;networkServices&lt;/code&gt; is a map where the key is a &lt;code&gt;networkServiceProviderUuid&lt;/code&gt; and the value is a list of &lt;code&gt;networkServiceType&lt;/code&gt;, which you obtain in the step 1&lt;/p&gt;&lt;/blockquote&gt;

&lt;h4&gt;3. Get the flat network provider UUID&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;        &amp;gt;&amp;gt;&amp;gt;QueryNetworkServiceProvider type=Flat
        {
            &quot;inventories&quot;: [
                {
                    &quot;attachedL2NetworkUuids&quot;: [
                        &quot;9ec8cad681d1424fa7eda2447edae142&quot;
                    ],
                    &quot;createDate&quot;: &quot;Jan 30, 2016 11:56:32 AM&quot;,
                    &quot;description&quot;: &quot;Flat Network Service Provider&quot;,
                    &quot;lastOpDate&quot;: &quot;Jan 30, 2016 11:56:32 AM&quot;,
                    &quot;name&quot;: &quot;Flat Network Service Provider&quot;,
                    &quot;networkServiceTypes&quot;: [
                        &quot;DHCP&quot;,
                        &quot;Userdata&quot;
                    ],
                    &quot;type&quot;: &quot;Flat&quot;,
                    &quot;uuid&quot;: &quot;17864f985e584a9ba4cd81de215212ce&quot;
                }
            ],
            &quot;success&quot;: true
        }
&lt;/code&gt;&lt;/pre&gt;

&lt;h4&gt;4. Get L2 UUID for the L3 network&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;        &amp;gt;&amp;gt;&amp;gt;QueryL3Network fields=l2NetworkUuid, uuid=1a82c2691978476fa6cefa36bb9d4bfd
        {
            &quot;inventories&quot;: [
                {
                    &quot;l2NetworkUuid&quot;: &quot;9ec8cad681d1424fa7eda2447edae142&quot;
                }
            ],
            &quot;success&quot;: true
        }
&lt;/code&gt;&lt;/pre&gt;

&lt;h4&gt;5. Attach the flat network provider to the L2 network&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;       &amp;gt;&amp;gt;&amp;gt;AttachNetworkServiceProviderToL2Network l2NetworkUuid=9ec8cad681d1424fa7eda2447edae142 networkServiceProviderUuid=17864f985e584a9ba4cd81de215212ce
       {
           &quot;inventory&quot;: {
               &quot;attachedL2NetworkUuids&quot;: [
                   &quot;9ec8cad681d1424fa7eda2447edae142&quot;
               ],
               &quot;createDate&quot;: &quot;Jan 30, 2016 11:56:32 AM&quot;,
               &quot;description&quot;: &quot;Flat Network Service Provider&quot;,
               &quot;lastOpDate&quot;: &quot;Jan 30, 2016 11:56:32 AM&quot;,
               &quot;name&quot;: &quot;Flat Network Service Provider&quot;,
               &quot;networkServiceTypes&quot;: [
                   &quot;DHCP&quot;,
                   &quot;Userdata&quot;
               ],
               &quot;type&quot;: &quot;Flat&quot;,
               &quot;uuid&quot;: &quot;17864f985e584a9ba4cd81de215212ce&quot;
           },
           &quot;success&quot;: true
       }
&lt;/code&gt;&lt;/pre&gt;

&lt;h4&gt;6. Attach the flat network provider to the L3 network&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;     &amp;gt;&amp;gt;&amp;gt;AttachNetworkServiceToL3Network l3NetworkUuid=1a82c2691978476fa6cefa36bb9d4bfd networkServices=&#39;{&quot;17864f985e584a9ba4cd81de215212ce&quot;:[&quot;DHCP&quot;,&quot;Userdata&quot;]}&#39;
      {
          &quot;inventory&quot;: {
              &quot;createDate&quot;: &quot;Jan 30, 2016 3:01:03 PM&quot;,
              &quot;dns&quot;: [
                  &quot;8.8.8.8&quot;
              ],
              &quot;ipRanges&quot;: [
                  {
                      &quot;createDate&quot;: &quot;Jan 30, 2016 3:01:04 PM&quot;,
                      &quot;endIp&quot;: &quot;192.168.201.199&quot;,
                      &quot;gateway&quot;: &quot;192.168.200.1&quot;,
                      &quot;l3NetworkUuid&quot;: &quot;1a82c2691978476fa6cefa36bb9d4bfd&quot;,
                      &quot;lastOpDate&quot;: &quot;Jan 30, 2016 3:01:04 PM&quot;,
                      &quot;name&quot;: &quot;ipr-dk7p&quot;,
                      &quot;netmask&quot;: &quot;255.255.252.0&quot;,
                      &quot;startIp&quot;: &quot;192.168.201.180&quot;,
                      &quot;uuid&quot;: &quot;ec5fd87dd80243fdabeeace847c04427&quot;
                  }
              ],
              &quot;l2NetworkUuid&quot;: &quot;9ec8cad681d1424fa7eda2447edae142&quot;,
              &quot;lastOpDate&quot;: &quot;Jan 30, 2016 3:01:03 PM&quot;,
              &quot;name&quot;: &quot;l3-etpz&quot;,
              &quot;networkServices&quot;: [
                  {
                      &quot;l3NetworkUuid&quot;: &quot;1a82c2691978476fa6cefa36bb9d4bfd&quot;,
                      &quot;networkServiceProviderUuid&quot;: &quot;17864f985e584a9ba4cd81de215212ce&quot;,
                      &quot;networkServiceType&quot;: &quot;DHCP&quot;
                  },
                  {
                      &quot;l3NetworkUuid&quot;: &quot;1a82c2691978476fa6cefa36bb9d4bfd&quot;,
                      &quot;networkServiceProviderUuid&quot;: &quot;17864f985e584a9ba4cd81de215212ce&quot;,
                      &quot;networkServiceType&quot;: &quot;Userdata&quot;
                  }
              ],
              &quot;state&quot;: &quot;Enabled&quot;,
              &quot;system&quot;: false,
              &quot;type&quot;: &quot;L3BasicNetwork&quot;,
              &quot;uuid&quot;: &quot;1a82c2691978476fa6cefa36bb9d4bfd&quot;,
              &quot;zoneUuid&quot;: &quot;4a3a78b1b9f049948b79cf9e667f0af2&quot;
          },
          &quot;success&quot;: true
      }
&lt;/code&gt;&lt;/pre&gt;

&lt;h4&gt;7. Delete the virtual router VM&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;        &amp;gt;&amp;gt;QueryVirtualRouterVm
         {
             &quot;inventories&quot;: [
                 {
                     &quot;allVolumes&quot;: [
                         {
                             &quot;createDate&quot;: &quot;Jan 30, 2016 3:06:50 PM&quot;,
                             &quot;description&quot;: &quot;Root volume for VM[uuid:c5a966cb87d644649952daf683f89e26]&quot;,
                             &quot;deviceId&quot;: 0,
                             &quot;format&quot;: &quot;qcow2&quot;,
                             &quot;installPath&quot;: &quot;/zstack_ps/rootVolumes/acct-36c27e8ff05c4780bf6d2fa65700f22e/vol-8eeaa9cb4c1045a2825f8815fed69d72/8eeaa9cb4c1045a2825f8815fed69d72.qcow2&quot;,
                             &quot;lastOpDate&quot;: &quot;Jan 30, 2016 3:06:59 PM&quot;,
                             &quot;name&quot;: &quot;ROOT-for-virtualRouter.l3.1a82c2691978476fa6cefa36bb9d4bfd&quot;,
                             &quot;primaryStorageUuid&quot;: &quot;4bff4e2d266f480ead596752d14ff3b5&quot;,
                             &quot;rootImageUuid&quot;: &quot;7bed05aa8ace4e5e8d6c55b284b66fb5&quot;,
                             &quot;size&quot;: 467206656,
                             &quot;state&quot;: &quot;Enabled&quot;,
                             &quot;status&quot;: &quot;Ready&quot;,
                             &quot;type&quot;: &quot;Root&quot;,
                             &quot;uuid&quot;: &quot;8eeaa9cb4c1045a2825f8815fed69d72&quot;,
                             &quot;vmInstanceUuid&quot;: &quot;c5a966cb87d644649952daf683f89e26&quot;
                         }
                     ],
                     &quot;allocatorStrategy&quot;: &quot;LeastVmPreferredHostAllocatorStrategy&quot;,
                     &quot;applianceVmType&quot;: &quot;VirtualRouter&quot;,
                     &quot;clusterUuid&quot;: &quot;10409d3e33b249c19746022930a541c7&quot;,
                     &quot;cpuNum&quot;: 1,
                     &quot;cpuSpeed&quot;: 2,
                     &quot;createDate&quot;: &quot;Jan 30, 2016 3:06:50 PM&quot;,
                     &quot;defaultRouteL3NetworkUuid&quot;: &quot;1a82c2691978476fa6cefa36bb9d4bfd&quot;,
                     &quot;hostUuid&quot;: &quot;415fa093b34e4a3d873368104b127115&quot;,
                     &quot;hypervisorType&quot;: &quot;KVM&quot;,
                     &quot;imageUuid&quot;: &quot;7bed05aa8ace4e5e8d6c55b284b66fb5&quot;,
                     &quot;instanceOfferingUuid&quot;: &quot;9cec7bd6324445a184351ffb7d32f970&quot;,
                     &quot;lastHostUuid&quot;: &quot;415fa093b34e4a3d873368104b127115&quot;,
                     &quot;lastOpDate&quot;: &quot;Jan 30, 2016 3:07:20 PM&quot;,
                     &quot;managementNetworkUuid&quot;: &quot;1a82c2691978476fa6cefa36bb9d4bfd&quot;,
                     &quot;memorySize&quot;: 536870912,
                     &quot;name&quot;: &quot;virtualRouter.l3.1a82c2691978476fa6cefa36bb9d4bfd&quot;,
                     &quot;platform&quot;: &quot;Linux&quot;,
                     &quot;publicNetworkUuid&quot;: &quot;1a82c2691978476fa6cefa36bb9d4bfd&quot;,
                     &quot;rootVolumeUuid&quot;: &quot;8eeaa9cb4c1045a2825f8815fed69d72&quot;,
                     &quot;state&quot;: &quot;Running&quot;,
                     &quot;status&quot;: &quot;Connected&quot;,
                     &quot;type&quot;: &quot;ApplianceVm&quot;,
                     &quot;uuid&quot;: &quot;c5a966cb87d644649952daf683f89e26&quot;,
                     &quot;vmNics&quot;: [
                         {
                             &quot;createDate&quot;: &quot;Jan 30, 2016 3:06:50 PM&quot;,
                             &quot;deviceId&quot;: 0,
                             &quot;gateway&quot;: &quot;192.168.200.1&quot;,
                             &quot;ip&quot;: &quot;192.168.201.195&quot;,
                             &quot;l3NetworkUuid&quot;: &quot;1a82c2691978476fa6cefa36bb9d4bfd&quot;,
                             &quot;lastOpDate&quot;: &quot;Jan 30, 2016 3:06:50 PM&quot;,
                             &quot;mac&quot;: &quot;fa:4c:01:68:77:00&quot;,
                             &quot;metaData&quot;: &quot;7&quot;,
                             &quot;netmask&quot;: &quot;255.255.252.0&quot;,
                             &quot;uuid&quot;: &quot;c44e856aa88a42bc85ec30ce8c334c6c&quot;,
                             &quot;vmInstanceUuid&quot;: &quot;c5a966cb87d644649952daf683f89e26&quot;
                         }
                     ],
                     &quot;zoneUuid&quot;: &quot;4a3a78b1b9f049948b79cf9e667f0af2&quot;
                 }
             ],
             &quot;success&quot;: true
         }

         &amp;gt;&amp;gt;&amp;gt;DestroyVmInstance uuid=c5a966cb87d644649952daf683f89e26
         {
             &quot;success&quot;: true
         }
&lt;/code&gt;&lt;/pre&gt;

&lt;h4&gt;8. Reconnect all hosts&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;         &amp;gt;&amp;gt;&amp;gt;QueryHost
         {
             &quot;inventories&quot;: [
                 {
                     &quot;availableCpuCapacity&quot;: 7180,
                     &quot;availableMemoryCapacity&quot;: 1997570048,
                     &quot;clusterUuid&quot;: &quot;4282fb61aa55458ea160de138e130298&quot;,
                     &quot;createDate&quot;: &quot;Jan 30, 2016 2:51:13 PM&quot;,
                     &quot;hypervisorType&quot;: &quot;KVM&quot;,
                     &quot;lastOpDate&quot;: &quot;Jan 30, 2016 3:03:20 PM&quot;,
                     &quot;managementIp&quot;: &quot;192.168.200.187&quot;,
                     &quot;name&quot;: &quot;host1&quot;,
                     &quot;state&quot;: &quot;Enabled&quot;,
                     &quot;status&quot;: &quot;Connected&quot;,
                     &quot;totalCpuCapacity&quot;: 7182,
                     &quot;totalMemoryCapacity&quot;: 2098233344,
                     &quot;username&quot;: &quot;root&quot;,
                     &quot;uuid&quot;: &quot;402f8304a50c410486e023512492316b&quot;,
                     &quot;zoneUuid&quot;: &quot;4a3a78b1b9f049948b79cf9e667f0af2&quot;
                 },
                 {
                     &quot;availableCpuCapacity&quot;: 14363,
                     &quot;availableMemoryCapacity&quot;: 8321593344,
                     &quot;clusterUuid&quot;: &quot;10409d3e33b249c19746022930a541c7&quot;,
                     &quot;createDate&quot;: &quot;Jan 30, 2016 3:03:14 PM&quot;,
                     &quot;hypervisorType&quot;: &quot;KVM&quot;,
                     &quot;lastOpDate&quot;: &quot;Jan 30, 2016 3:03:52 PM&quot;,
                     &quot;managementIp&quot;: &quot;192.168.200.150&quot;,
                     &quot;name&quot;: &quot;host2&quot;,
                     &quot;state&quot;: &quot;Enabled&quot;,
                     &quot;status&quot;: &quot;Connected&quot;,
                     &quot;totalCpuCapacity&quot;: 14364,
                     &quot;totalMemoryCapacity&quot;: 8371924992,
                     &quot;username&quot;: &quot;root&quot;,
                     &quot;uuid&quot;: &quot;415fa093b34e4a3d873368104b127115&quot;,
                     &quot;zoneUuid&quot;: &quot;4a3a78b1b9f049948b79cf9e667f0af2&quot;
                 }
             ],
             &quot;success&quot;: true
         }

         &amp;gt;&amp;gt;&amp;gt;ReconnectHost uuid=402f8304a50c410486e023512492316b
         {
             &quot;success&quot;: true
         }

         &amp;gt;&amp;gt;&amp;gt;ReconnectHost uuid=415fa093b34e4a3d873368104b127115
         {
             &quot;success&quot;: true
         }
&lt;/code&gt;&lt;/pre&gt;
</description>
        <pubDate>Wed, 30 Mar 2016 00:00:00 +0800</pubDate>
        <link>http://zstack.org/blog/v1.1.html</link>
        <guid isPermaLink="true">http://zstack.org/blog/v1.1.html</guid>
        
        
        <category>blog</category>
        
      </item>
    
      <item>
        <title>ZStack v1.1 release</title>
        <description>&lt;p&gt;Hello everyone, I am Frank Zhang, the architect of ZStack. Today I am happy to
announce that ZStack v1.1 is released.&lt;/p&gt;

&lt;h1&gt;New Features And Enhancements&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#ansible&quot;&gt;Ansible Optimization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#consoleproxy&quot;&gt;Console Proxy APIs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#apitimeout&quot;&gt;API Timeout Management&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#gc&quot;&gt;Garbage Collector&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#image&quot;&gt;15 Tiny Tryout Image&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#vr&quot;&gt;Virtual Router Image Upgrade&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;h1&gt;Installation And Upgrade&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#install&quot;&gt;Installation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#upgrade&quot;&gt;Upgrade&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#upgradevr&quot;&gt;Upgrade Virtual Router Provider To Flat Network Provider&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;h2 id=&quot;ansible&quot;&gt; 1. Ansible Optimization &lt;/h2&gt;


&lt;p&gt;In this version, we create customized deployers for all ZStack agents(i.e. kvmagent, backup storage agent) directly using Ansible SDK, instead of regular Ansible playbook YAML files. As the result, the speed of agent deployment gets significantly improved, because the deployer that is a Python application will try best to avoid unnecessary time-costing steps such as accessing YUM repo; the logging also gets better, each task will post messages to a logging URL before and after execution, and the error message will clearly state the error instead of flooding out all tasks status, which regular Ansible playbook YAML files normally do.&lt;/p&gt;

&lt;h2 id=&quot;consoleproxy&quot;&gt;2. Console Proxy APIs &lt;/h2&gt;


&lt;p&gt;Two new APIs are added for console proxy, &lt;code&gt;ReconnectConsoleProxyAgent&lt;/code&gt; and &lt;code&gt;QueryConsoleProxyAgent&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Users can use &lt;code&gt;ReconnectConsoleProxyAgent&lt;/code&gt; to redeploy console proxy agents:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;        &amp;gt;&amp;gt;&amp;gt;ReconnectConsoleProxyAgent 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;or use &lt;code&gt;QueryConsoleProxyAgent&lt;/code&gt; to query agents&#39; status:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;       &amp;gt;&amp;gt;&amp;gt;QueryConsoleProxyAgent 
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;apitimeout&quot;&gt;3. API Timeout Management&lt;/h2&gt;


&lt;p&gt;As ZStack consists of a lot of microservices which communicate with each other through async-messages, it&#39;s very hard to control API timeout because the API has no idea about internal messages entailed by itself. In this version, we add a central API timeout management framework that can connect an API to all entailed internal messages and HTTP requests, and that can propagate the API&#39;s timeout to the descendants. All APIs have default configurations, users can change a configuration by editing the &lt;code&gt;zstack.properties&lt;/code&gt; file, for example:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    ApiTimeout.org.zstack.header.image.APIAddImageMsg= org.zstack.header.storage.backup.DownloadImageMsg, org.zstack.storage.backup.sftp.SftpBackupStorageCommands$DownloadCmd, org.zstack.storage.ceph.backup.CephBackupStorageBase$DownloadCmd; 6h
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This example changes the timeout of API &lt;code&gt;org.zstack.header.image.APIAddImageMsg&lt;/code&gt; to six hours. However, this way is discouraged. In 1.2 version, we will allow users to configure APIs&#39; timeout through a new API.&lt;/p&gt;

&lt;h2 id=&quot;gc&quot;&gt;4. Garbage Collector&lt;/h2&gt;


&lt;p&gt;In this version, the VM related garbage collectors are enabled. Users can destroy a VM anytime no matter the connection status of the host. For example, you can delete a VM even the network connection to the host where the VM is running is lost. The garbage collector will save user operations which cannot be completed in current situation and re-execute them once the host&#39;s network connection recovers. The garbage collector can be triggered by time-based poll and events, for example, a host reconnect event and host delete event can both trigger a VM deleting garbage collector.&lt;/p&gt;

&lt;h2 id=&quot;image&quot;&gt;5. 15M Tiny Tryout Image&lt;/h2&gt;


&lt;p&gt;A new 15 tiny image is ready for quickly try out creating VMs. The image supports runtime attaching/detaching volumes and networks. The ACPID daemon is also included so you can gracefully shutdown a VM. You can download the image from:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    http://download.zstack.org/templates/zstack-image-1.2.qcow2
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;vr&quot;&gt;6. New Virtual Router Image&lt;/h2&gt;


&lt;p&gt;The virtual router image is upgraded to 1.1 version, you can download it from:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    http://download.zstack.org/templates/zstack-virtualrouter-1.1.0.qcow2
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;&lt;p&gt;NOTE: Users still using the old 0.9 version are not necessary to upgrade. However, we suggest all new users using the new version.&lt;/p&gt;&lt;/blockquote&gt;

&lt;h2 id=&quot;install&quot;&gt;7. Installation&lt;/h2&gt;


&lt;p&gt;You can install the 1.1 release by:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    wget http://download.zstack.org/releases/1.1/1.1.0/0331/zstack-installer-1.1.0-0331.bin -O zstack-installer-1.1.0.bin
    bash zstack-installer-1.1.0.bin
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;upgrade&quot;&gt;8. Upgrade&lt;/h2&gt;


&lt;p&gt;To upgrade your ZStack to 1.1, do:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    wget http://download.zstack.org/releases/1.1/1.1.0/0331/zstack-installer-1.1.0-0331.bin -O zstack-installer-1.1.0.bin
    bash zstack-installer-1.1.0.bin -u
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;upgradevr&quot;&gt;9. Upgrade Virtual Router Provider To Flat Network Provider&lt;/h2&gt;


&lt;p&gt;If you are currently using a flat network with a previous ZStack version, you can upgrade the L3 network using the flat network provider so
you won&#39;t need the virtual router VM anymore. Assume the UUID of your L3 network is 1a82c2691978476fa6cefa36bb9d4bfd, please follow
the below steps:&lt;/p&gt;

&lt;h4&gt;1. Obtain the UUID of the virtual rotuer provider&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;    &amp;gt;&amp;gt;&amp;gt;QueryNetworkServiceL3NetworkRef l3NetworkUuid=1a82c2691978476fa6cefa36bb9d4bfd
    {
        &quot;inventories&quot;: [
            {
                &quot;l3NetworkUuid&quot;: &quot;1a82c2691978476fa6cefa36bb9d4bfd&quot;,
                &quot;networkServiceProviderUuid&quot;: &quot;5d21ea0f39c04d6fb68cfaf5a37db4ad&quot;,
                &quot;networkServiceType&quot;: &quot;DNS&quot;
            },
            {
                &quot;l3NetworkUuid&quot;: &quot;1a82c2691978476fa6cefa36bb9d4bfd&quot;,
                &quot;networkServiceProviderUuid&quot;: &quot;5d21ea0f39c04d6fb68cfaf5a37db4ad&quot;,
                &quot;networkServiceType&quot;: &quot;DHCP&quot;
            }
        ],
        &quot;success&quot;: true
    }
&lt;/code&gt;&lt;/pre&gt;

&lt;h4&gt;2. Detach the virtual router provider from the L3 network&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;        &amp;gt;&amp;gt;&amp;gt;DetachNetworkServiceFromL3Network  l3NetworkUuid=1a82c2691978476fa6cefa36bb9d4bfd networkServices=&#39;{&quot;5d21ea0f39c04d6fb68cfaf5a37db4ad&quot;:[&quot;DHCP&quot;,&quot;DNS&quot;]}&#39;
         {
             &quot;inventory&quot;: {
                 &quot;createDate&quot;: &quot;Jan 30, 2016 3:01:03 PM&quot;,
                 &quot;dns&quot;: [
                     &quot;8.8.8.8&quot;
                 ],
                 &quot;ipRanges&quot;: [
                     {
                         &quot;createDate&quot;: &quot;Jan 30, 2016 3:01:04 PM&quot;,
                         &quot;endIp&quot;: &quot;192.168.201.199&quot;,
                         &quot;gateway&quot;: &quot;192.168.200.1&quot;,
                         &quot;l3NetworkUuid&quot;: &quot;1a82c2691978476fa6cefa36bb9d4bfd&quot;,
                         &quot;lastOpDate&quot;: &quot;Jan 30, 2016 3:01:04 PM&quot;,
                         &quot;name&quot;: &quot;ipr-dk7p&quot;,
                         &quot;netmask&quot;: &quot;255.255.252.0&quot;,
                         &quot;startIp&quot;: &quot;192.168.201.180&quot;,
                         &quot;uuid&quot;: &quot;ec5fd87dd80243fdabeeace847c04427&quot;
                     }
                 ],
                 &quot;l2NetworkUuid&quot;: &quot;9ec8cad681d1424fa7eda2447edae142&quot;,
                 &quot;lastOpDate&quot;: &quot;Jan 30, 2016 3:01:03 PM&quot;,
                 &quot;name&quot;: &quot;l3-etpz&quot;,
                 &quot;networkServices&quot;: [],
                 &quot;state&quot;: &quot;Enabled&quot;,
                 &quot;system&quot;: false,
                 &quot;type&quot;: &quot;L3BasicNetwork&quot;,
                 &quot;uuid&quot;: &quot;1a82c2691978476fa6cefa36bb9d4bfd&quot;,
                 &quot;zoneUuid&quot;: &quot;4a3a78b1b9f049948b79cf9e667f0af2&quot;
             },
             &quot;success&quot;: true
         }
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;&lt;p&gt;the parameter &lt;code&gt;networkServices&lt;/code&gt; is a map where the key is a &lt;code&gt;networkServiceProviderUuid&lt;/code&gt; and the value is a list of &lt;code&gt;networkServiceType&lt;/code&gt;, which you obtain in the step 1&lt;/p&gt;&lt;/blockquote&gt;

&lt;h4&gt;3. Get the flat network provider UUID&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;        &amp;gt;&amp;gt;&amp;gt;QueryNetworkServiceProvider type=Flat
        {
            &quot;inventories&quot;: [
                {
                    &quot;attachedL2NetworkUuids&quot;: [
                        &quot;9ec8cad681d1424fa7eda2447edae142&quot;
                    ],
                    &quot;createDate&quot;: &quot;Jan 30, 2016 11:56:32 AM&quot;,
                    &quot;description&quot;: &quot;Flat Network Service Provider&quot;,
                    &quot;lastOpDate&quot;: &quot;Jan 30, 2016 11:56:32 AM&quot;,
                    &quot;name&quot;: &quot;Flat Network Service Provider&quot;,
                    &quot;networkServiceTypes&quot;: [
                        &quot;DHCP&quot;,
                        &quot;Userdata&quot;
                    ],
                    &quot;type&quot;: &quot;Flat&quot;,
                    &quot;uuid&quot;: &quot;17864f985e584a9ba4cd81de215212ce&quot;
                }
            ],
            &quot;success&quot;: true
        }
&lt;/code&gt;&lt;/pre&gt;

&lt;h4&gt;4. Get L2 UUID for the L3 network&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;        &amp;gt;&amp;gt;&amp;gt;QueryL3Network fields=l2NetworkUuid, uuid=1a82c2691978476fa6cefa36bb9d4bfd
        {
            &quot;inventories&quot;: [
                {
                    &quot;l2NetworkUuid&quot;: &quot;9ec8cad681d1424fa7eda2447edae142&quot;
                }
            ],
            &quot;success&quot;: true
        }
&lt;/code&gt;&lt;/pre&gt;

&lt;h4&gt;5. Attach the flat network provider to the L2 network&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;       &amp;gt;&amp;gt;&amp;gt;AttachNetworkServiceProviderToL2Network l2NetworkUuid=9ec8cad681d1424fa7eda2447edae142 networkServiceProviderUuid=17864f985e584a9ba4cd81de215212ce
       {
           &quot;inventory&quot;: {
               &quot;attachedL2NetworkUuids&quot;: [
                   &quot;9ec8cad681d1424fa7eda2447edae142&quot;
               ],
               &quot;createDate&quot;: &quot;Jan 30, 2016 11:56:32 AM&quot;,
               &quot;description&quot;: &quot;Flat Network Service Provider&quot;,
               &quot;lastOpDate&quot;: &quot;Jan 30, 2016 11:56:32 AM&quot;,
               &quot;name&quot;: &quot;Flat Network Service Provider&quot;,
               &quot;networkServiceTypes&quot;: [
                   &quot;DHCP&quot;,
                   &quot;Userdata&quot;
               ],
               &quot;type&quot;: &quot;Flat&quot;,
               &quot;uuid&quot;: &quot;17864f985e584a9ba4cd81de215212ce&quot;
           },
           &quot;success&quot;: true
       }
&lt;/code&gt;&lt;/pre&gt;

&lt;h4&gt;6. Attach the flat network provider to the L3 network&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;     &amp;gt;&amp;gt;&amp;gt;AttachNetworkServiceToL3Network l3NetworkUuid=1a82c2691978476fa6cefa36bb9d4bfd networkServices=&#39;{&quot;17864f985e584a9ba4cd81de215212ce&quot;:[&quot;DHCP&quot;,&quot;Userdata&quot;]}&#39;
      {
          &quot;inventory&quot;: {
              &quot;createDate&quot;: &quot;Jan 30, 2016 3:01:03 PM&quot;,
              &quot;dns&quot;: [
                  &quot;8.8.8.8&quot;
              ],
              &quot;ipRanges&quot;: [
                  {
                      &quot;createDate&quot;: &quot;Jan 30, 2016 3:01:04 PM&quot;,
                      &quot;endIp&quot;: &quot;192.168.201.199&quot;,
                      &quot;gateway&quot;: &quot;192.168.200.1&quot;,
                      &quot;l3NetworkUuid&quot;: &quot;1a82c2691978476fa6cefa36bb9d4bfd&quot;,
                      &quot;lastOpDate&quot;: &quot;Jan 30, 2016 3:01:04 PM&quot;,
                      &quot;name&quot;: &quot;ipr-dk7p&quot;,
                      &quot;netmask&quot;: &quot;255.255.252.0&quot;,
                      &quot;startIp&quot;: &quot;192.168.201.180&quot;,
                      &quot;uuid&quot;: &quot;ec5fd87dd80243fdabeeace847c04427&quot;
                  }
              ],
              &quot;l2NetworkUuid&quot;: &quot;9ec8cad681d1424fa7eda2447edae142&quot;,
              &quot;lastOpDate&quot;: &quot;Jan 30, 2016 3:01:03 PM&quot;,
              &quot;name&quot;: &quot;l3-etpz&quot;,
              &quot;networkServices&quot;: [
                  {
                      &quot;l3NetworkUuid&quot;: &quot;1a82c2691978476fa6cefa36bb9d4bfd&quot;,
                      &quot;networkServiceProviderUuid&quot;: &quot;17864f985e584a9ba4cd81de215212ce&quot;,
                      &quot;networkServiceType&quot;: &quot;DHCP&quot;
                  },
                  {
                      &quot;l3NetworkUuid&quot;: &quot;1a82c2691978476fa6cefa36bb9d4bfd&quot;,
                      &quot;networkServiceProviderUuid&quot;: &quot;17864f985e584a9ba4cd81de215212ce&quot;,
                      &quot;networkServiceType&quot;: &quot;Userdata&quot;
                  }
              ],
              &quot;state&quot;: &quot;Enabled&quot;,
              &quot;system&quot;: false,
              &quot;type&quot;: &quot;L3BasicNetwork&quot;,
              &quot;uuid&quot;: &quot;1a82c2691978476fa6cefa36bb9d4bfd&quot;,
              &quot;zoneUuid&quot;: &quot;4a3a78b1b9f049948b79cf9e667f0af2&quot;
          },
          &quot;success&quot;: true
      }
&lt;/code&gt;&lt;/pre&gt;

&lt;h4&gt;7. Delete the virtual router VM&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;        &amp;gt;&amp;gt;QueryVirtualRouterVm
         {
             &quot;inventories&quot;: [
                 {
                     &quot;allVolumes&quot;: [
                         {
                             &quot;createDate&quot;: &quot;Jan 30, 2016 3:06:50 PM&quot;,
                             &quot;description&quot;: &quot;Root volume for VM[uuid:c5a966cb87d644649952daf683f89e26]&quot;,
                             &quot;deviceId&quot;: 0,
                             &quot;format&quot;: &quot;qcow2&quot;,
                             &quot;installPath&quot;: &quot;/zstack_ps/rootVolumes/acct-36c27e8ff05c4780bf6d2fa65700f22e/vol-8eeaa9cb4c1045a2825f8815fed69d72/8eeaa9cb4c1045a2825f8815fed69d72.qcow2&quot;,
                             &quot;lastOpDate&quot;: &quot;Jan 30, 2016 3:06:59 PM&quot;,
                             &quot;name&quot;: &quot;ROOT-for-virtualRouter.l3.1a82c2691978476fa6cefa36bb9d4bfd&quot;,
                             &quot;primaryStorageUuid&quot;: &quot;4bff4e2d266f480ead596752d14ff3b5&quot;,
                             &quot;rootImageUuid&quot;: &quot;7bed05aa8ace4e5e8d6c55b284b66fb5&quot;,
                             &quot;size&quot;: 467206656,
                             &quot;state&quot;: &quot;Enabled&quot;,
                             &quot;status&quot;: &quot;Ready&quot;,
                             &quot;type&quot;: &quot;Root&quot;,
                             &quot;uuid&quot;: &quot;8eeaa9cb4c1045a2825f8815fed69d72&quot;,
                             &quot;vmInstanceUuid&quot;: &quot;c5a966cb87d644649952daf683f89e26&quot;
                         }
                     ],
                     &quot;allocatorStrategy&quot;: &quot;LeastVmPreferredHostAllocatorStrategy&quot;,
                     &quot;applianceVmType&quot;: &quot;VirtualRouter&quot;,
                     &quot;clusterUuid&quot;: &quot;10409d3e33b249c19746022930a541c7&quot;,
                     &quot;cpuNum&quot;: 1,
                     &quot;cpuSpeed&quot;: 2,
                     &quot;createDate&quot;: &quot;Jan 30, 2016 3:06:50 PM&quot;,
                     &quot;defaultRouteL3NetworkUuid&quot;: &quot;1a82c2691978476fa6cefa36bb9d4bfd&quot;,
                     &quot;hostUuid&quot;: &quot;415fa093b34e4a3d873368104b127115&quot;,
                     &quot;hypervisorType&quot;: &quot;KVM&quot;,
                     &quot;imageUuid&quot;: &quot;7bed05aa8ace4e5e8d6c55b284b66fb5&quot;,
                     &quot;instanceOfferingUuid&quot;: &quot;9cec7bd6324445a184351ffb7d32f970&quot;,
                     &quot;lastHostUuid&quot;: &quot;415fa093b34e4a3d873368104b127115&quot;,
                     &quot;lastOpDate&quot;: &quot;Jan 30, 2016 3:07:20 PM&quot;,
                     &quot;managementNetworkUuid&quot;: &quot;1a82c2691978476fa6cefa36bb9d4bfd&quot;,
                     &quot;memorySize&quot;: 536870912,
                     &quot;name&quot;: &quot;virtualRouter.l3.1a82c2691978476fa6cefa36bb9d4bfd&quot;,
                     &quot;platform&quot;: &quot;Linux&quot;,
                     &quot;publicNetworkUuid&quot;: &quot;1a82c2691978476fa6cefa36bb9d4bfd&quot;,
                     &quot;rootVolumeUuid&quot;: &quot;8eeaa9cb4c1045a2825f8815fed69d72&quot;,
                     &quot;state&quot;: &quot;Running&quot;,
                     &quot;status&quot;: &quot;Connected&quot;,
                     &quot;type&quot;: &quot;ApplianceVm&quot;,
                     &quot;uuid&quot;: &quot;c5a966cb87d644649952daf683f89e26&quot;,
                     &quot;vmNics&quot;: [
                         {
                             &quot;createDate&quot;: &quot;Jan 30, 2016 3:06:50 PM&quot;,
                             &quot;deviceId&quot;: 0,
                             &quot;gateway&quot;: &quot;192.168.200.1&quot;,
                             &quot;ip&quot;: &quot;192.168.201.195&quot;,
                             &quot;l3NetworkUuid&quot;: &quot;1a82c2691978476fa6cefa36bb9d4bfd&quot;,
                             &quot;lastOpDate&quot;: &quot;Jan 30, 2016 3:06:50 PM&quot;,
                             &quot;mac&quot;: &quot;fa:4c:01:68:77:00&quot;,
                             &quot;metaData&quot;: &quot;7&quot;,
                             &quot;netmask&quot;: &quot;255.255.252.0&quot;,
                             &quot;uuid&quot;: &quot;c44e856aa88a42bc85ec30ce8c334c6c&quot;,
                             &quot;vmInstanceUuid&quot;: &quot;c5a966cb87d644649952daf683f89e26&quot;
                         }
                     ],
                     &quot;zoneUuid&quot;: &quot;4a3a78b1b9f049948b79cf9e667f0af2&quot;
                 }
             ],
             &quot;success&quot;: true
         }

         &amp;gt;&amp;gt;&amp;gt;DestroyVmInstance uuid=c5a966cb87d644649952daf683f89e26
         {
             &quot;success&quot;: true
         }
&lt;/code&gt;&lt;/pre&gt;

&lt;h4&gt;8. Reconnect all hosts&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;         &amp;gt;&amp;gt;&amp;gt;QueryHost
         {
             &quot;inventories&quot;: [
                 {
                     &quot;availableCpuCapacity&quot;: 7180,
                     &quot;availableMemoryCapacity&quot;: 1997570048,
                     &quot;clusterUuid&quot;: &quot;4282fb61aa55458ea160de138e130298&quot;,
                     &quot;createDate&quot;: &quot;Jan 30, 2016 2:51:13 PM&quot;,
                     &quot;hypervisorType&quot;: &quot;KVM&quot;,
                     &quot;lastOpDate&quot;: &quot;Jan 30, 2016 3:03:20 PM&quot;,
                     &quot;managementIp&quot;: &quot;192.168.200.187&quot;,
                     &quot;name&quot;: &quot;host1&quot;,
                     &quot;state&quot;: &quot;Enabled&quot;,
                     &quot;status&quot;: &quot;Connected&quot;,
                     &quot;totalCpuCapacity&quot;: 7182,
                     &quot;totalMemoryCapacity&quot;: 2098233344,
                     &quot;username&quot;: &quot;root&quot;,
                     &quot;uuid&quot;: &quot;402f8304a50c410486e023512492316b&quot;,
                     &quot;zoneUuid&quot;: &quot;4a3a78b1b9f049948b79cf9e667f0af2&quot;
                 },
                 {
                     &quot;availableCpuCapacity&quot;: 14363,
                     &quot;availableMemoryCapacity&quot;: 8321593344,
                     &quot;clusterUuid&quot;: &quot;10409d3e33b249c19746022930a541c7&quot;,
                     &quot;createDate&quot;: &quot;Jan 30, 2016 3:03:14 PM&quot;,
                     &quot;hypervisorType&quot;: &quot;KVM&quot;,
                     &quot;lastOpDate&quot;: &quot;Jan 30, 2016 3:03:52 PM&quot;,
                     &quot;managementIp&quot;: &quot;192.168.200.150&quot;,
                     &quot;name&quot;: &quot;host2&quot;,
                     &quot;state&quot;: &quot;Enabled&quot;,
                     &quot;status&quot;: &quot;Connected&quot;,
                     &quot;totalCpuCapacity&quot;: 14364,
                     &quot;totalMemoryCapacity&quot;: 8371924992,
                     &quot;username&quot;: &quot;root&quot;,
                     &quot;uuid&quot;: &quot;415fa093b34e4a3d873368104b127115&quot;,
                     &quot;zoneUuid&quot;: &quot;4a3a78b1b9f049948b79cf9e667f0af2&quot;
                 }
             ],
             &quot;success&quot;: true
         }

         &amp;gt;&amp;gt;&amp;gt;ReconnectHost uuid=402f8304a50c410486e023512492316b
         {
             &quot;success&quot;: true
         }

         &amp;gt;&amp;gt;&amp;gt;ReconnectHost uuid=415fa093b34e4a3d873368104b127115
         {
             &quot;success&quot;: true
         }
&lt;/code&gt;&lt;/pre&gt;
</description>
        <pubDate>Wed, 30 Mar 2016 00:00:00 +0800</pubDate>
        <link>http://zstack.org/cn/blog/v1.1.html</link>
        <guid isPermaLink="true">http://zstack.org/cn/blog/v1.1.html</guid>
        
        
        <category>blog</category>
        
      </item>
    
      <item>
        <title>ZStack离线安装教程</title>
        <description>&lt;h2&gt;ZStack离线安装教程&lt;/h2&gt;

&lt;p&gt;针对无法访问互联网以及访问互联网速度较慢的用户，ZStack 提供了一个离线安装的方法。
用户使用离线安装方法，首先需要在管理节点,镜像服务器和计算节点上安装CentOS 7.2的ZStack社区版，
然后在安装ZStack的时候使用-o参数即可快速完成环境的搭建。&lt;/p&gt;

&lt;p&gt;本文将会详细介绍如何把定制版ISO的刻录成U盘，如何使用U盘引导安装CentOS 7.2操作系统，
以及如何离线安装ZStack系统的方法。&lt;/p&gt;

&lt;h4&gt;CentOS 7.2 ZStack社区版ISO特性：&lt;/h4&gt;

&lt;ol&gt;
&lt;li&gt;基于CentOS-7-x86_64-1511.ISO深度定制；&lt;/li&gt;
&lt;li&gt;包含ZStack需要的所有安装包，安装ZStack时，无须连接外网，也无须配置yum源，就可以实现ZStack的完全离线安装；&lt;/li&gt;
&lt;li&gt;保留了CentOS7.2的官方yum源，支持官方yum更新；&lt;/li&gt;
&lt;li&gt;默认设置了root密码为password，支持安装OS后修改密码；&lt;/li&gt;
&lt;li&gt;网卡名称默认为ethX格式，例如eth0或eth1；&lt;/li&gt;
&lt;li&gt;默认选项：时区--亚洲东八区，语言--English，键盘--English(United States)。&lt;/li&gt;
&lt;/ol&gt;


&lt;h3&gt;CentOS 7.2 ZStack 社区定制版系统安装教程：&lt;/h3&gt;

&lt;h4&gt;1. 下载ZStack社区定制版CentOS7.2 ISO&lt;/h4&gt;

&lt;p&gt;文件名称：ZStack-Community-x86_64-DVD-1.3.0.iso (1.7G)&lt;/p&gt;

&lt;p&gt;MD5校验码：80a87506325702d7f3d453a54041ddcb&lt;/p&gt;

&lt;p&gt;下载地址1：
http://download.zstack.org/ISO/ZStack-Community-x86_64-DVD-1.3.0.iso&lt;/p&gt;

&lt;p&gt;下载地址2：
http://pan.baidu.com/s/1hsqCEfa&lt;/p&gt;

&lt;h4&gt;2. 制作U盘安装盘&lt;/h4&gt;

&lt;h5&gt;2.1   使用UltraISO打开ISO&lt;/h5&gt;

&lt;p&gt;使用UltraISO，点击“文件”按钮，选择打开已下载好的CentOS7.2 ISO文件，如图1所示。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/blogs/offline_install/use-UltraISO-open-custom-centos7.2-iso.png&quot; &gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;图1 选择UltraISO打开定制版CentOS7.2 ISO&lt;/em&gt;&lt;/p&gt;

&lt;h5&gt;2.2   写入硬盘镜像&lt;/h5&gt;

&lt;p&gt;点击“启动”按钮，选择“写入硬盘镜像”，如图2所示。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/blogs/offline_install/click-write-to-diskimage.png&quot; &gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;图2 点击写入硬盘镜像&lt;/em&gt;&lt;/p&gt;

&lt;h5&gt;2.3   将ISO写入硬盘镜像&lt;/h5&gt;

&lt;p&gt;在硬盘驱动器列表选择相应的U盘进行刻录，如果系统只插了一个U盘，则默认以此U盘进行刻录和写入，在刻录前，注意备份U盘之前的内容。
其他选项，按照默认设置，无须额外配置。点击“写入”按钮，如图3所示。在新界面中点击“是”按钮进行确认，UltraISO将会把此ISO刻录到U盘。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/blogs/offline_install/choose-u-disk-to-write.png&quot; &gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;图3 选择U盘，点击写入按钮&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/blogs/offline_install/choose-u-disk-to-write.png&quot; &gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;图4 确认写入&lt;/em&gt;&lt;/p&gt;

&lt;h5&gt;2.4   刻录检查&lt;/h5&gt;

&lt;p&gt;刻录成功的界面如图5所示，表示ZStack的定制版CentOS 7.2 可引导U盘已刻录成功。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/blogs/offline_install/burn-check.png&quot; &gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;图5 刻录检查&lt;/em&gt;&lt;/p&gt;

&lt;h4&gt;3. 使用U盘引导CentOS7.2&lt;/h4&gt;

&lt;p&gt;此ISO支持Legacy模式引导，也支持UEFI模式引导。可根据需求，自定义选择安装。下面以Legacy模式引导安装举例。
在BIOS启动选项列表，选择此U盘为第一启动设备，启动后，引导安装界面如图6所示：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/blogs/offline_install/boot-from-U-disk.png&quot; &gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;图6 可引导U盘启动界面&lt;/em&gt;&lt;/p&gt;

&lt;h4&gt;4. 硬盘分区&lt;/h4&gt;

&lt;p&gt;安装过程中，只需进行分区，即可一键安装CentOS7.2操作系统，如图7所示的分区为根分区48G，swap分区为2G。也可根据存储及需求，提前设置好大容量分区。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/blogs/offline_install/partition.png&quot; &gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;图7 安装分区界面&lt;/em&gt;&lt;/p&gt;

&lt;h4&gt;5. 安装系统&lt;/h4&gt;

&lt;p&gt;分区完毕后，点击“Begin Installation”按钮，开始安装。如图8所示。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/blogs/offline_install/click-begin-installation.png&quot; &gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;图8 点击Begin Installation按钮&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;所有的安装包安装完毕后，点击“reboot”按钮，如图9所示，即可启动进入CentOS7.2系统。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../images/blogs/offline_install/prepare-reboot.png&quot; &gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;图9 点击reboot按钮&lt;/em&gt;&lt;/p&gt;

&lt;h3&gt;离线安装ZStack：&lt;/h3&gt;

&lt;p&gt;安装系统后，可通过以下方法离线安装ZStack。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;下载ZStack离线安装包(e.g. wget http://download.zstack.org/releases/1.2/1.2.0/zstack-installer-1.2.0.bin -O zstack-installer.bin)到任意目录(假定文件名为zstack-installer.bin)；&lt;/li&gt;
&lt;li&gt;在此目录下执行“bash zstack-installer.bin -o”即可完成相应安装。如图10所示。&lt;/li&gt;
&lt;li&gt;安装过程如果提示错误，可参考相应错误提示进行处理。如果无法正常安装可发送相应错误日志到官方讨论群寻求帮助。&lt;/li&gt;
&lt;li&gt;安装完毕可参考相应的提示，访问对应的URL打开ZStack Web UI。
&lt;img src=&quot;../images/blogs/offline_install/offline-install-zstack.png&quot; &gt;&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;&lt;em&gt;图10 离线安装ZStack&lt;/em&gt;&lt;/p&gt;

&lt;h2&gt;配置用户内网独立yum源：&lt;/h2&gt;

&lt;p&gt;如果用户自己在内部配置了统一的yum源,也可以不使用ZStack CentOS 7.2 社区版的ISO来安装系统。
但是需要手动在每一台机器上(需要安装ZStack管理节点,镜像服务器以及计算节点的机器),编写如下的yum配置,把内部yum源配置到名为zstack-local的repository里:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#echo /etc/yum.repos.d/zstack-local.repo
[zstack-local]
name=ZStack Local Yum Repo
baseurl=http://内部YUM源URL
enabled=0
gpgcheck=0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;需要注意的是该内部源内需要包含系统需要以来的各种标准库,包括epel里的库.&lt;/p&gt;

&lt;p&gt;配置之后,就可以使用-o参数来安装ZStack.添加各种ZStack资源的时候,也会使用每台服务器上的该配置文件.&lt;/p&gt;
</description>
        <pubDate>Tue, 29 Mar 2016 00:00:00 +0800</pubDate>
        <link>http://zstack.org/cn_blog/offline-install-zstack-from-custom-iso.html</link>
        <guid isPermaLink="true">http://zstack.org/cn_blog/offline-install-zstack-from-custom-iso.html</guid>
        
        
        <category>cn_blog</category>
        
      </item>
    
      <item>
        <title>ZStack v1.1 RC1 发布</title>
        <description>&lt;h2&gt;ZStack 1.1 RC1 版本今天发布&lt;/h2&gt;

&lt;p&gt;ZStack 1.1 RC1 版本今天发布，欢迎大家下载试用。在该版本中，我们主要针对1.0 版本做了性能和稳定性相关的工作。
某些性能指标提升超过10倍,例如consoleproxy在管理节点重启后会立刻安装完毕.
在ZStack 1.1 正式版发布的时候我们还会提供一个离线版的CentOS7.2的安装ISO和ZStack 1.1的离线安装方法。&lt;/p&gt;

&lt;h2&gt;新增功能&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#ansible&quot;&gt;Ansible 优化&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#consoleproxy&quot;&gt;ConsoleProxy 重连API&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#timeout&quot;&gt;API超时管理框架&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#reclaim&quot;&gt;垃圾自动回收&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#zstackimage&quot;&gt;15M超小试用镜像--支持动态添加删除云盘和网络&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#virtualrouter&quot;&gt;更新虚拟路由（VirtualRouter）镜像&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#migration&quot;&gt;修改CentOS7.2 无法热迁移VM的Bug&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;h2&gt;安装升级&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#install&quot;&gt;安装&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#upgrade&quot;&gt;升级&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#upgradenetwork&quot;&gt;Virtual Router Provider升级到Flat Network Porvider&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;h3 id=&quot;ansible&quot;&gt;1. Ansible优化 &lt;/h3&gt;


&lt;p&gt;在1.1版本中，我们不再使用Ansible Playbook的方式去部署agent，而是直接使用了Ansible的原生SDK，为每个agent都定制了单独的部署程序，使得部署的稳定性和效率得到了极大的提高。&lt;/p&gt;

&lt;p&gt;新的Ansible部署工具会自动检查系统依赖包的安装情况，只在有依赖包缺失的情况下才访问yum或apt源，避免了重启ZStack和升级ZStack过程中，由于访问外网抖动导致的物理机重连失败的问题，提高了系统的稳定性。新的部署工具也会检查Python依赖，解决了升级过程中consoleproxy依赖的websockify重复编译问题，升级consoleproxy的部署时间从原来的5分钟缩减到了4秒。&lt;/p&gt;

&lt;h3 id=&quot;consoleproxy&quot;&gt;2. ConsoleProxy重连API &lt;/h3&gt;


&lt;p&gt;在1.1版本中，我们加入了console proxy的重连和查询API，用户不再需要通过重启ZStack来重新部署console proxy。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    &amp;gt;&amp;gt;&amp;gt;QueryConsoleProxyAgent 
    {
        &quot;inventories&quot;: [
            {
                &quot;createDate&quot;: &quot;Mar 26, 2016 12:53:17 PM&quot;,
                &quot;description&quot;: &quot;Console proxy agent running on the management node[uuid:ae80b109e9ca4f4c81191cd2ffe43000]&quot;,
                &quot;lastOpDate&quot;: &quot;Mar 26, 2016 12:53:22 PM&quot;,
                &quot;managementIp&quot;: &quot;172.20.12.46&quot;,
                &quot;state&quot;: &quot;Enabled&quot;,
                &quot;status&quot;: &quot;Connected&quot;,
                &quot;type&quot;: &quot;ManagementServerConsoleProxy&quot;,
                &quot;uuid&quot;: &quot;ae80b109e9ca4f4c81191cd2ffe43000&quot;
            }
        ],
        &quot;success&quot;: true
    }

    &amp;gt;&amp;gt;&amp;gt;ReconnectConsoleProxyAgent 
    {
        &quot;inventory&quot;: {
            &quot;ae80b109e9ca4f4c81191cd2ffe43000&quot;: true
        },
        &quot;success&quot;: true
    }
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&quot;timeout&quot;&gt;3. API超时管理框架&lt;/h3&gt;


&lt;p&gt;ZStack所有功能由大量相互独立的微服务实现，服务之间使用异步消息通信，通常一个API会涉及到多个消息以及跟Agent端的HTTP调用，超时管理成为一个难题。在1.1版本中，我们加入了统一的API超时管理框架，用户无需关心底层细节。在当前版本中，用户如果需要改变默认的API超时，暂时还需要通过zstack.properties文件来改变，例如需要改变AddImage的API超时为6个小时，需要在zstack.properties添加如下配置：&lt;/p&gt;

&lt;p&gt;ApiTimeout.org.zstack.header.image.APIAddImageMsg= org.zstack.header.storage.backup.DownloadImageMsg, org.zstack.storage.backup.sftp.SftpBackupStorageCommands$DownloadCmd, org.zstack.storage.ceph.backup.CephBackupStorageBase$DownloadCmd; 6h&lt;/p&gt;

&lt;p&gt;NOTE：目前我们为所有耗时的API都设置了默认3小时的超时时间，用户在如无特殊需要，不建议通过配置的方式进行修改。我们在1.2版本会新加超时管理API，用户可以直接通过API来设定相应操作的超时时间。&lt;/p&gt;

&lt;h3 id=&quot;reclaim&quot;&gt;4. 垃圾回收机制&lt;/h3&gt;


&lt;p&gt;在1.1版本中，我们全面开启了跟虚拟机相关的垃圾回收器，可以自动回收由于网络故障、物理机故障导致的遗留资源，而不阻碍用户操作。&lt;/p&gt;

&lt;p&gt; 场景：&lt;/p&gt;

&lt;p&gt;物理机网络失联导致用户无法删除该物理机上运行的虚拟机。在早前的ZStack版本中，用户需要等待物理机网络恢复后再执行删除操作。有了垃圾回收器后，用户可以直接删除虚拟机，后台会记录该删除操作。垃圾回收器会在物理机网络恢复后自动触发，执行未完成的操作。&lt;/p&gt;

&lt;p&gt;目前已经启动的垃圾回收器包括云主机、云盘、快照，更多的垃圾回收器会在未来版本中逐一开放。&lt;/p&gt;

&lt;p&gt;ZStack的垃圾回收器非常智能，支持时间轮询和事件触发，其中事件触发支持多种关联事件。例如在前面的例子中，如果管理员在物理机网络恢复前又删除了该物理机，垃圾回收器也会被触发，清除之前提交的删除该物理机上虚拟机的任务。&lt;/p&gt;

&lt;h3 id=&quot;virtualrouter&quot;&gt;5. 新虚拟路由（Virtual Router）镜像&lt;/h3&gt;


&lt;p&gt;VirtualRouter image 更新到了 zstack-virtualrouter-1.1.0.qcow2 .我们除了更新了VirtualRouter 对应的services外，还提高了VirtualRouter的安全访问方式：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;修改了virtual router 默认的密码，原先的默认密码是 password。以后用户无法用密码登录Virtual Router&lt;/li&gt;
&lt;li&gt;使用了用户特别的 SSH public key。 这个public key是用户在安装ZStack的时候自动产生的，可以保证每个用户都是用不同的SSH key。 用户可以使用私有的 SSH private key从Virtual Router的管理网络登录。 该SSH private key 默认存放在管理节点： /usr/local/zstack/apache-tomcat/webapps/zstackWEB-INF/classes/ansible/rsaKeys/id_rsa&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;用户可以下载并替换原有VirtualRouter Image: http://download.zstack.org/templates/zstack-virtualrouter-1.1.0.qcow2&lt;/p&gt;

&lt;p&gt;替换原有VirtualRouter的方法是：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;从UI上下载最新的VirtualRouter image，例如命名为 zstack-vr-1.1-image&lt;/li&gt;
&lt;li&gt;从镜像服务器删除老的VirtualRouter Image&lt;/li&gt;
&lt;li&gt;删除老的VirtualRouter Offering&lt;/li&gt;
&lt;li&gt;创建新的VirtualRouter Offering，并且选择新下载的zstack-vr-1.1-image做为VirtualRouter Offering的镜像。其他网络配置不变。&lt;/li&gt;
&lt;li&gt;从UI面板的Virtual Router菜单中删除现有的VirtualRouter VM&lt;/li&gt;
&lt;li&gt;选择使用VR的L3网络重新创建一个普通VM，ZStack就会使用新的Virtual Router镜像创建一个新的虚拟路由。&lt;/li&gt;
&lt;/ol&gt;


&lt;h3 id=&quot;zstackimage&quot;&gt;6. 15M超小试用镜像--支持动态添加删除云盘和网络 &lt;/h3&gt;


&lt;p&gt;在1.1我们为ZStack专门构建了一个只有15M的测试镜像，支持网络、SSHD，用户可以用它来做一些基本测试。相比于之前的1.0的测试镜像，该镜像支持了动态添加删除云盘和网络。下载链接：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;     http://download.zstack.org/templates/zstack-image-1.2.qcow2
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;感谢Robert Yang(@linuxer)提供该镜像!&lt;/p&gt;

&lt;h3 id=&quot;migration&quot;&gt; 7. 修复CentOS7.2 物理机无法热迁移VM的bug&lt;/h3&gt;


&lt;p&gt;CentOS7.2 修改了热迁移VM的libvirt的相关代码，导致如果用户没有显示的设置物理机Hostname的情况下，云主机无法热迁移。ZStack以及给RedHat报告了问题。
不过在ZStack 1.1中，我们做了特别的改动来避免CentOS7.2 的这个bug。&lt;/p&gt;

&lt;h3 id=&quot;install&quot;&gt; 8. 安装 &lt;/h3&gt;


&lt;p&gt;你可以通过下面方式安装：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    wget http://download.zstack.org/releases/1.1/1.1.0/rc1/zstack-installer-1.1.0-rc1.bin -O zstack-installer-1.1.0-rc1.bin
    bash zstack-installer-1.1.0-rc1.bin -R aliyun
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;&lt;p&gt;这里&lt;code&gt;-R aliyun&lt;/code&gt;参数指定使用阿里云的源进行安装，你也可以使用&lt;code&gt;-R 163&lt;/code&gt;使用网易的源。我们推荐使用阿里云的源&lt;/p&gt;&lt;/blockquote&gt;

&lt;h3 id=&quot;upgrade&quot;&gt; 9. 升级 &lt;/h3&gt;


&lt;p&gt;一如既往的，我们支持一键无缝升级：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    wget http://download.zstack.org/releases/1.1/1.1.0/rc1/zstack-installer-1.1.0-rc1.bin -O zstack-installer-1.1.0-rc1.bin
    bash zstack-installer-1.1.0-rc1.bin -u
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&quot;upgradenetwork&quot;&gt; 10. 用Flat Network Provider替换Virtual Router Provider &lt;/h3&gt;


&lt;p&gt;如果你的网络模式是扁平网络，并且使用的是Virtual Rotuer Provider作为网络提供商，你可以使用1.0的Flat Network Provider替换它，这样你就不再需要virtual router VM来充当DHCP服务器了。假定你要替换网络提供商的L3网络的UUID是1a82c2691978476fa6cefa36bb9d4bfd，参考以下步骤：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;获得当前L3网络的网络提供商UUID&lt;/p&gt;

&lt;pre&gt;&lt;code&gt; &amp;gt;&amp;gt;&amp;gt;QueryNetworkServiceL3NetworkRef l3NetworkUuid=1a82c2691978476fa6cefa36bb9d4bfd
 {
     &quot;inventories&quot;: [
         {
             &quot;l3NetworkUuid&quot;: &quot;1a82c2691978476fa6cefa36bb9d4bfd&quot;,
             &quot;networkServiceProviderUuid&quot;: &quot;5d21ea0f39c04d6fb68cfaf5a37db4ad&quot;,
             &quot;networkServiceType&quot;: &quot;DNS&quot;
         },
         {
             &quot;l3NetworkUuid&quot;: &quot;1a82c2691978476fa6cefa36bb9d4bfd&quot;,
             &quot;networkServiceProviderUuid&quot;: &quot;5d21ea0f39c04d6fb68cfaf5a37db4ad&quot;,
             &quot;networkServiceType&quot;: &quot;DHCP&quot;
         }
     ],
     &quot;success&quot;: true
 }
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;从L3网络上卸载Virtual Router Provider&lt;/p&gt;

&lt;pre&gt;&lt;code&gt; &amp;gt;&amp;gt;&amp;gt;DetachNetworkServiceFromL3Network  l3NetworkUuid=1a82c2691978476fa6cefa36bb9d4bfd networkServices=&#39;{&quot;5d21ea0f39c04d6fb68cfaf5a37db4ad&quot;:[&quot;DHCP&quot;,&quot;DNS&quot;]}&#39;
 {
     &quot;inventory&quot;: {
         &quot;createDate&quot;: &quot;Jan 30, 2016 3:01:03 PM&quot;,
         &quot;dns&quot;: [
             &quot;8.8.8.8&quot;
         ],
         &quot;ipRanges&quot;: [
             {
                 &quot;createDate&quot;: &quot;Jan 30, 2016 3:01:04 PM&quot;,
                 &quot;endIp&quot;: &quot;192.168.201.199&quot;,
                 &quot;gateway&quot;: &quot;192.168.200.1&quot;,
                 &quot;l3NetworkUuid&quot;: &quot;1a82c2691978476fa6cefa36bb9d4bfd&quot;,
                 &quot;lastOpDate&quot;: &quot;Jan 30, 2016 3:01:04 PM&quot;,
                 &quot;name&quot;: &quot;ipr-dk7p&quot;,
                 &quot;netmask&quot;: &quot;255.255.252.0&quot;,
                 &quot;startIp&quot;: &quot;192.168.201.180&quot;,
                 &quot;uuid&quot;: &quot;ec5fd87dd80243fdabeeace847c04427&quot;
             }
         ],
         &quot;l2NetworkUuid&quot;: &quot;9ec8cad681d1424fa7eda2447edae142&quot;,
         &quot;lastOpDate&quot;: &quot;Jan 30, 2016 3:01:03 PM&quot;,
         &quot;name&quot;: &quot;l3-etpz&quot;,
         &quot;networkServices&quot;: [],
         &quot;state&quot;: &quot;Enabled&quot;,
         &quot;system&quot;: false,
         &quot;type&quot;: &quot;L3BasicNetwork&quot;,
         &quot;uuid&quot;: &quot;1a82c2691978476fa6cefa36bb9d4bfd&quot;,
         &quot;zoneUuid&quot;: &quot;4a3a78b1b9f049948b79cf9e667f0af2&quot;
     },
     &quot;success&quot;: true
 }
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ol&gt;


&lt;blockquote&gt;&lt;p&gt;注意这里的参数networkServices是一个map， key是第一步里返回的networkServiceProviderUuid，value是第一步里返回的networkServiceType&lt;/p&gt;&lt;/blockquote&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;获得Flat Network Provider的UUID&lt;/p&gt;

&lt;pre&gt;&lt;code&gt; &amp;gt;&amp;gt;&amp;gt;QueryNetworkServiceProvider type=Flat
 {
     &quot;inventories&quot;: [
         {
             &quot;attachedL2NetworkUuids&quot;: [
                 &quot;9ec8cad681d1424fa7eda2447edae142&quot;
             ],
             &quot;createDate&quot;: &quot;Jan 30, 2016 11:56:32 AM&quot;,
             &quot;description&quot;: &quot;Flat Network Service Provider&quot;,
             &quot;lastOpDate&quot;: &quot;Jan 30, 2016 11:56:32 AM&quot;,
             &quot;name&quot;: &quot;Flat Network Service Provider&quot;,
             &quot;networkServiceTypes&quot;: [
                 &quot;DHCP&quot;,
                 &quot;Userdata&quot;
             ],
             &quot;type&quot;: &quot;Flat&quot;,
             &quot;uuid&quot;: &quot;17864f985e584a9ba4cd81de215212ce&quot;
         }
     ],
     &quot;success&quot;: true
 }
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;获得承载L3网络的L2网络的UUID&lt;/p&gt;

&lt;pre&gt;&lt;code&gt; &amp;gt;&amp;gt;&amp;gt;QueryL3Network fields=l2NetworkUuid, uuid=1a82c2691978476fa6cefa36bb9d4bfd
 {
     &quot;inventories&quot;: [
         {
             &quot;l2NetworkUuid&quot;: &quot;9ec8cad681d1424fa7eda2447edae142&quot;
         }
     ],
     &quot;success&quot;: true
 }
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;加载Flat Network Provider到L2网络&lt;/p&gt;

&lt;pre&gt;&lt;code&gt; &amp;gt;&amp;gt;&amp;gt;AttachNetworkServiceProviderToL2Network l2NetworkUuid=9ec8cad681d1424fa7eda2447edae142 networkServiceProviderUuid=17864f985e584a9ba4cd81de215212ce
 {
     &quot;inventory&quot;: {
         &quot;attachedL2NetworkUuids&quot;: [
             &quot;9ec8cad681d1424fa7eda2447edae142&quot;
         ],
         &quot;createDate&quot;: &quot;Jan 30, 2016 11:56:32 AM&quot;,
         &quot;description&quot;: &quot;Flat Network Service Provider&quot;,
         &quot;lastOpDate&quot;: &quot;Jan 30, 2016 11:56:32 AM&quot;,
         &quot;name&quot;: &quot;Flat Network Service Provider&quot;,
         &quot;networkServiceTypes&quot;: [
             &quot;DHCP&quot;,
             &quot;Userdata&quot;
         ],
         &quot;type&quot;: &quot;Flat&quot;,
         &quot;uuid&quot;: &quot;17864f985e584a9ba4cd81de215212ce&quot;
     },
     &quot;success&quot;: true
 }
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;加载Flat Network Provider的服务到三层网络&lt;/p&gt;

&lt;pre&gt;&lt;code&gt; &amp;gt;&amp;gt;&amp;gt;AttachNetworkServiceToL3Network l3NetworkUuid=1a82c2691978476fa6cefa36bb9d4bfd networkServices=&#39;{&quot;17864f985e584a9ba4cd81de215212ce&quot;:[&quot;DHCP&quot;,&quot;Userdata&quot;]}&#39;
 {
     &quot;inventory&quot;: {
         &quot;createDate&quot;: &quot;Jan 30, 2016 3:01:03 PM&quot;,
         &quot;dns&quot;: [
             &quot;8.8.8.8&quot;
         ],
         &quot;ipRanges&quot;: [
             {
                 &quot;createDate&quot;: &quot;Jan 30, 2016 3:01:04 PM&quot;,
                 &quot;endIp&quot;: &quot;192.168.201.199&quot;,
                 &quot;gateway&quot;: &quot;192.168.200.1&quot;,
                 &quot;l3NetworkUuid&quot;: &quot;1a82c2691978476fa6cefa36bb9d4bfd&quot;,
                 &quot;lastOpDate&quot;: &quot;Jan 30, 2016 3:01:04 PM&quot;,
                 &quot;name&quot;: &quot;ipr-dk7p&quot;,
                 &quot;netmask&quot;: &quot;255.255.252.0&quot;,
                 &quot;startIp&quot;: &quot;192.168.201.180&quot;,
                 &quot;uuid&quot;: &quot;ec5fd87dd80243fdabeeace847c04427&quot;
             }
         ],
         &quot;l2NetworkUuid&quot;: &quot;9ec8cad681d1424fa7eda2447edae142&quot;,
         &quot;lastOpDate&quot;: &quot;Jan 30, 2016 3:01:03 PM&quot;,
         &quot;name&quot;: &quot;l3-etpz&quot;,
         &quot;networkServices&quot;: [
             {
                 &quot;l3NetworkUuid&quot;: &quot;1a82c2691978476fa6cefa36bb9d4bfd&quot;,
                 &quot;networkServiceProviderUuid&quot;: &quot;17864f985e584a9ba4cd81de215212ce&quot;,
                 &quot;networkServiceType&quot;: &quot;DHCP&quot;
             },
             {
                 &quot;l3NetworkUuid&quot;: &quot;1a82c2691978476fa6cefa36bb9d4bfd&quot;,
                 &quot;networkServiceProviderUuid&quot;: &quot;17864f985e584a9ba4cd81de215212ce&quot;,
                 &quot;networkServiceType&quot;: &quot;Userdata&quot;
             }
         ],
         &quot;state&quot;: &quot;Enabled&quot;,
         &quot;system&quot;: false,
         &quot;type&quot;: &quot;L3BasicNetwork&quot;,
         &quot;uuid&quot;: &quot;1a82c2691978476fa6cefa36bb9d4bfd&quot;,
         &quot;zoneUuid&quot;: &quot;4a3a78b1b9f049948b79cf9e667f0af2&quot;
     },
     &quot;success&quot;: true
 }
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;删除virtualrouter ,删除virtual router offering&lt;/p&gt;

&lt;pre&gt;&lt;code&gt; &amp;gt;&amp;gt;&amp;gt;QueryVirtualRouterVm
 {
     &quot;inventories&quot;: [
         {
             &quot;allVolumes&quot;: [
                 {
                     &quot;createDate&quot;: &quot;Jan 30, 2016 3:06:50 PM&quot;,
                     &quot;description&quot;: &quot;Root volume for VM[uuid:c5a966cb87d644649952daf683f89e26]&quot;,
                     &quot;deviceId&quot;: 0,
                     &quot;format&quot;: &quot;qcow2&quot;,
                     &quot;installPath&quot;: &quot;/zstack_ps/rootVolumes/acct-36c27e8ff05c4780bf6d2fa65700f22e/vol-8eeaa9cb4c1045a2825f8815fed69d72/8eeaa9cb4c1045a2825f8815fed69d72.qcow2&quot;,
                     &quot;lastOpDate&quot;: &quot;Jan 30, 2016 3:06:59 PM&quot;,
                     &quot;name&quot;: &quot;ROOT-for-virtualRouter.l3.1a82c2691978476fa6cefa36bb9d4bfd&quot;,
                     &quot;primaryStorageUuid&quot;: &quot;4bff4e2d266f480ead596752d14ff3b5&quot;,
                     &quot;rootImageUuid&quot;: &quot;7bed05aa8ace4e5e8d6c55b284b66fb5&quot;,
                     &quot;size&quot;: 467206656,
                     &quot;state&quot;: &quot;Enabled&quot;,
                     &quot;status&quot;: &quot;Ready&quot;,
                     &quot;type&quot;: &quot;Root&quot;,
                     &quot;uuid&quot;: &quot;8eeaa9cb4c1045a2825f8815fed69d72&quot;,
                     &quot;vmInstanceUuid&quot;: &quot;c5a966cb87d644649952daf683f89e26&quot;
                 }
             ],
             &quot;allocatorStrategy&quot;: &quot;LeastVmPreferredHostAllocatorStrategy&quot;,
             &quot;applianceVmType&quot;: &quot;VirtualRouter&quot;,
             &quot;clusterUuid&quot;: &quot;10409d3e33b249c19746022930a541c7&quot;,
             &quot;cpuNum&quot;: 1,
             &quot;cpuSpeed&quot;: 2,
             &quot;createDate&quot;: &quot;Jan 30, 2016 3:06:50 PM&quot;,
             &quot;defaultRouteL3NetworkUuid&quot;: &quot;1a82c2691978476fa6cefa36bb9d4bfd&quot;,
             &quot;hostUuid&quot;: &quot;415fa093b34e4a3d873368104b127115&quot;,
             &quot;hypervisorType&quot;: &quot;KVM&quot;,
             &quot;imageUuid&quot;: &quot;7bed05aa8ace4e5e8d6c55b284b66fb5&quot;,
             &quot;instanceOfferingUuid&quot;: &quot;9cec7bd6324445a184351ffb7d32f970&quot;,
             &quot;lastHostUuid&quot;: &quot;415fa093b34e4a3d873368104b127115&quot;,
             &quot;lastOpDate&quot;: &quot;Jan 30, 2016 3:07:20 PM&quot;,
             &quot;managementNetworkUuid&quot;: &quot;1a82c2691978476fa6cefa36bb9d4bfd&quot;,
             &quot;memorySize&quot;: 536870912,
             &quot;name&quot;: &quot;virtualRouter.l3.1a82c2691978476fa6cefa36bb9d4bfd&quot;,
             &quot;platform&quot;: &quot;Linux&quot;,
             &quot;publicNetworkUuid&quot;: &quot;1a82c2691978476fa6cefa36bb9d4bfd&quot;,
             &quot;rootVolumeUuid&quot;: &quot;8eeaa9cb4c1045a2825f8815fed69d72&quot;,
             &quot;state&quot;: &quot;Running&quot;,
             &quot;status&quot;: &quot;Connected&quot;,
             &quot;type&quot;: &quot;ApplianceVm&quot;,
             &quot;uuid&quot;: &quot;c5a966cb87d644649952daf683f89e26&quot;,
             &quot;vmNics&quot;: [
                 {
                     &quot;createDate&quot;: &quot;Jan 30, 2016 3:06:50 PM&quot;,
                     &quot;deviceId&quot;: 0,
                     &quot;gateway&quot;: &quot;192.168.200.1&quot;,
                     &quot;ip&quot;: &quot;192.168.201.195&quot;,
                     &quot;l3NetworkUuid&quot;: &quot;1a82c2691978476fa6cefa36bb9d4bfd&quot;,
                     &quot;lastOpDate&quot;: &quot;Jan 30, 2016 3:06:50 PM&quot;,
                     &quot;mac&quot;: &quot;fa:4c:01:68:77:00&quot;,
                     &quot;metaData&quot;: &quot;7&quot;,
                     &quot;netmask&quot;: &quot;255.255.252.0&quot;,
                     &quot;uuid&quot;: &quot;c44e856aa88a42bc85ec30ce8c334c6c&quot;,
                     &quot;vmInstanceUuid&quot;: &quot;c5a966cb87d644649952daf683f89e26&quot;
                 }
             ],
             &quot;zoneUuid&quot;: &quot;4a3a78b1b9f049948b79cf9e667f0af2&quot;
         }
     ],
     &quot;success&quot;: true
 }

 &amp;gt;&amp;gt;&amp;gt;DestroyVmInstance uuid=c5a966cb87d644649952daf683f89e26
 {
     &quot;success&quot;: true
 }
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;重连所有有VM运行的host&lt;/p&gt;

&lt;pre&gt;&lt;code&gt; &amp;gt;&amp;gt;&amp;gt;QueryHost
 {
     &quot;inventories&quot;: [
         {
             &quot;availableCpuCapacity&quot;: 7180,
             &quot;availableMemoryCapacity&quot;: 1997570048,
             &quot;clusterUuid&quot;: &quot;4282fb61aa55458ea160de138e130298&quot;,
             &quot;createDate&quot;: &quot;Jan 30, 2016 2:51:13 PM&quot;,
             &quot;hypervisorType&quot;: &quot;KVM&quot;,
             &quot;lastOpDate&quot;: &quot;Jan 30, 2016 3:03:20 PM&quot;,
             &quot;managementIp&quot;: &quot;192.168.200.187&quot;,
             &quot;name&quot;: &quot;host1&quot;,
             &quot;state&quot;: &quot;Enabled&quot;,
             &quot;status&quot;: &quot;Connected&quot;,
             &quot;totalCpuCapacity&quot;: 7182,
             &quot;totalMemoryCapacity&quot;: 2098233344,
             &quot;username&quot;: &quot;root&quot;,
             &quot;uuid&quot;: &quot;402f8304a50c410486e023512492316b&quot;,
             &quot;zoneUuid&quot;: &quot;4a3a78b1b9f049948b79cf9e667f0af2&quot;
         },
         {
             &quot;availableCpuCapacity&quot;: 14363,
             &quot;availableMemoryCapacity&quot;: 8321593344,
             &quot;clusterUuid&quot;: &quot;10409d3e33b249c19746022930a541c7&quot;,
             &quot;createDate&quot;: &quot;Jan 30, 2016 3:03:14 PM&quot;,
             &quot;hypervisorType&quot;: &quot;KVM&quot;,
             &quot;lastOpDate&quot;: &quot;Jan 30, 2016 3:03:52 PM&quot;,
             &quot;managementIp&quot;: &quot;192.168.200.150&quot;,
             &quot;name&quot;: &quot;host2&quot;,
             &quot;state&quot;: &quot;Enabled&quot;,
             &quot;status&quot;: &quot;Connected&quot;,
             &quot;totalCpuCapacity&quot;: 14364,
             &quot;totalMemoryCapacity&quot;: 8371924992,
             &quot;username&quot;: &quot;root&quot;,
             &quot;uuid&quot;: &quot;415fa093b34e4a3d873368104b127115&quot;,
             &quot;zoneUuid&quot;: &quot;4a3a78b1b9f049948b79cf9e667f0af2&quot;
         }
     ],
     &quot;success&quot;: true
 }

 &amp;gt;&amp;gt;&amp;gt;ReconnectHost uuid=402f8304a50c410486e023512492316b
 {
     &quot;success&quot;: true
 }

 &amp;gt;&amp;gt;&amp;gt;ReconnectHost uuid=415fa093b34e4a3d873368104b127115
 {
     &quot;success&quot;: true
 }
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ol&gt;

</description>
        <pubDate>Sat, 26 Mar 2016 00:00:00 +0800</pubDate>
        <link>http://zstack.org/cn_blog/v1.1-rc1.html</link>
        <guid isPermaLink="true">http://zstack.org/cn_blog/v1.1-rc1.html</guid>
        
        
        <category>cn_blog</category>
        
      </item>
    
  </channel>
</rss>
