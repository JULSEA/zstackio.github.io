<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>ZStack</title>
    <description>ZStack is open source IaaS software managing resources of compute, storage, networking throughout a datacenter all by APIs.</description>
    <link>http://zstack.org/</link>
    <atom:link href="http://zstack.org/feed.xml" rel="self" type="application/rss+xml" />
    <pubDate>Wed, 01 Jun 2016 14:02:23 +0800</pubDate>
    <lastBuildDate>Wed, 01 Jun 2016 14:02:23 +0800</lastBuildDate>
    <generator>Jekyll v2.5.3</generator>
    
      <item>
        <title>ZStack v1.3.1 发布</title>
        <description>&lt;h2&gt;ZStack 1.3.1 版本今天发布&lt;/h2&gt;

&lt;p&gt;ZStack 1.3版本的第一个更新版本今天发布，请之前全新安装ZStack 1.3版本和Virtual Router(虚拟路由)的用户需要尽快升级。
在该版中，我们修复了1.3版本中 Qemu 2.3 版本的一个缺陷。该缺陷会导致新创建的Virtual Router无法正确的获取IP地址。&lt;/p&gt;

&lt;h2&gt;修复的缺陷&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;虚拟路由器无法获取IP地址&lt;/li&gt;
&lt;/ul&gt;


&lt;h2&gt;安装升级&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#install&quot;&gt;安装&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#offlineinstall&quot;&gt;离线安装&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#upgrade&quot;&gt;升级&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;h3 id=&quot;install&quot;&gt;1. 安装&lt;/h3&gt;


&lt;p&gt;你可以通过下面方式安装：&lt;/p&gt;

&lt;p&gt;   wget http://download.zstack.org/releases/1.3/1.3.1/zstack-installer-1.3.1.bin
   bash zstack-installer-1.3.1.bin -R aliyun&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;这里&lt;code&gt;-R aliyun&lt;/code&gt;参数指定使用阿里云的源进行安装，你也可以使用&lt;code&gt;-R 163&lt;/code&gt;使用网易的源。我们推荐使用阿里云的源&lt;/p&gt;&lt;/blockquote&gt;

&lt;h3 id=&quot;offlineinstall&quot;&gt;2. 离线安装&lt;/h3&gt;


&lt;p&gt;针对内网用户,以及访问Internet速度较慢的用户.ZStack 1.3 提供了离线安装方式.
用户若需要离线安装ZStack,需要在目标管理节点和计算节点上安装CentOS 7.2 ZStack社区版.&lt;/p&gt;

&lt;p&gt;然后在下载了第8步中的 zstack-installer 之后,你可以通过下面方式快速完成离线安装：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;bash zstack-installer-1.3.1.bin -o
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;具体的离线安装教程和CentOS 7.2 ZStack社区版请阅读: &lt;a href=&quot;./offline-install-zstack-from-custom-iso.html&quot;&gt;ZStack离线安装教程&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;upgrade&quot;&gt;3. 升级 &lt;/h3&gt;


&lt;p&gt;一如既往的，我们支持一键无缝升级：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;wget http://download.zstack.org/releases/1.3/1.3.1/zstack-installer-1.3.1.bin
bash zstack-installer-1.3.1.bin -u
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;多节点升级中的zstack.war文件可以从下面的链接下载：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;wget http://download.zstack.org/releases/1.3/1.3.1/zstack.war
&lt;/code&gt;&lt;/pre&gt;
</description>
        <pubDate>Wed, 01 Jun 2016 00:00:00 +0800</pubDate>
        <link>http://zstack.org/cn_blog/v1.3.1.html</link>
        <guid isPermaLink="true">http://zstack.org/cn_blog/v1.3.1.html</guid>
        
        
        <category>cn_blog</category>
        
      </item>
    
      <item>
        <title>ZStack v1.3 发布</title>
        <description>&lt;h2&gt;ZStack 1.3 版本今天正式发布&lt;/h2&gt;

&lt;p&gt;ZStack 1.3版本今天发布，欢迎大家下载试用。在该版中，我们修复了1.2版本中发现的bug，新增了如下功能；image/volume的virtual size/actual size支持，CPU超分设置，启动VM的时候指定集群（cluster）或物理机，加载L3网络到虚拟机时指定IP等功能。此外，该版本包含了华云网际贡献的fusionstor插件，用户可以使用华云网际的商业存储fusionstor作为备份存储和主存储。具体细节参考以下章节。&lt;/p&gt;

&lt;h2&gt;新增功能&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#actualsize&quot;&gt;Image/Volume的actual size/virtual size支持&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#cpu&quot;&gt;CPU超分&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#startvm&quot;&gt;启动VM指定集群或物理机&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#staticip&quot;&gt;加载L3网络指定静态IP&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#log&quot;&gt;日志收集工具&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#qemu&quot;&gt;社区版ISO安装升级到QEMU2.3版本&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#fusionstor&quot;&gt;华云网际fusionstor支持&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;h2&gt;安装升级&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#install&quot;&gt;安装&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#offlineinstall&quot;&gt;离线安装&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#upgrade&quot;&gt;升级&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;h3 id=&quot;actualsize&quot;&gt;1. Image/Volume实际容量 &lt;/h3&gt;


&lt;p&gt;在使用thin-provisioning（又称thin-clone）技术的时候，一个qcow2文件有两个容量：表示物理大小的真实容量(actual size)和表示用户申请空间大小的容量（virtual size）。在之前的zstack版本中 ，对于image，用户只能看到actual size，对于volume，只能看到virtual size。从1.3版本开始，image和volume都同时支持actual size和virtual size，这样用户既能知道该image/volume目前的物理大小，也可以知道表示其容量上限的virtual size。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/1.3/1.png&quot; class=&quot;center-img img-responsive&quot;&gt;&lt;/p&gt;

&lt;p&gt;对于volume，由于其actual size会随用户对磁盘的使用不断增长，我们新加了一个API方便用户能实时获取volume当前的actual size:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    &amp;gt;&amp;gt;&amp;gt;SyncVolumeSize uuid=e9fc82e23cd14d8aa33d1304cb1f5f87
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&quot;cpu&quot;&gt;2. CPU超分设定&lt;/h3&gt;


&lt;p&gt;在之前的zstack版本中，我们引入了一个对应VM CPU权重的概念cpu speed，给用户造成了很大困惑。在1.3版本中，我们已将其去掉。用户创建VM时只需要执行VCPU的数量即可。用户可以通过设置一个 全局配置来执行物理机CPU的超分比例:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    &amp;gt;&amp;gt;&amp;gt;UpdateGlobalConfig category=host name=cpu.overProvisioning.ratio value=20
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;&lt;p&gt;默认CPU超分比例是10，即一个Linux操作系统可见的物理CPU可以分配10 VCPU供VM使用。例如一个4 CPU物理机，则可以虚出40个VCPU。&lt;/p&gt;&lt;/blockquote&gt;

&lt;h3 id=&quot;startvm&quot;&gt;3. 启动VM时指定cluster或host&lt;/h3&gt;


&lt;p&gt;在该版本中，用户可以在启动一个停止的VM时，指定该VM从启动的cluster或host：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    &amp;gt;&amp;gt;&amp;gt;StartVmInstance uuid=554d67a78c40475cbe4e8e0cdf6adc44 hostUuid=c2025197915944acaf0435c0c1a44f96
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;或&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    &amp;gt;&amp;gt;&amp;gt;StartVmInstance uuid=554d67a78c40475cbe4e8e0cdf6adc44 clusterUuid==c2025197915944acaf0435c0c1a44f96
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;&lt;p&gt;该功能只对使用共享主存储（例如NFS）的VM有效，对于使用本地存储的VM，由于VM的根磁盘在物理机的硬盘上，无法跨物理机启动&lt;/p&gt;&lt;/blockquote&gt;

&lt;h3 id=&quot;staticip&quot;&gt;4. 加载L3网络指定静态IP&lt;/h3&gt;


&lt;p&gt;在该版本中，用户可以在给一个VM加载L3网络的时候指定静态IP：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    &amp;gt;&amp;gt;&amp;gt;AttachL3NetworkToVm l3NetworkUuid=23e15a6acc80431fa0f1763ab45ae144 vmInstanceUuid=b7ba300853974189b7adc90f2c25e00b staticIp=192.168.1.10
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&quot;sshport&quot;&gt;5. 添加host、backup storage时指定ssh端口以及使用非root用户&lt;/h3&gt;


&lt;p&gt;从该版本开始，在添加host、sftp backup storage、ceph primary storage、ceph backup storage时，可以指定ssh端口，以及使用非root的用户名:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/1.3/2.png&quot; class=&quot;center-img img-responsive&quot;&gt;
&lt;img src=&quot;/images/1.3/3.png&quot; class=&quot;center-img img-responsive&quot;&gt;&lt;/p&gt;

&lt;h3 id=&quot;log&quot;&gt;6. 日志收集工具&lt;/h3&gt;


&lt;p&gt;为了方便用户在调试zstack的时候收集日志，在1.3版本中我们新加了一个zstack-ctl collect_log命令用于自动收集并打包相关日志：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/1.3/4.png&quot; class=&quot;center-img img-responsive&quot;&gt;&lt;/p&gt;

&lt;p&gt;在1.2版本中，用户可以通过修改全局设置的来指定启动云主机时，KVM对云盘使用的缓存模式。支持三种模式：&lt;/p&gt;

&lt;h3 id=&quot;qemu&quot;&gt;7. 社区版ISO安装升级到QEMU2.3版本&lt;/h3&gt;


&lt;p&gt;在最新的ZStack 1.3社区版ISO中，我们已经将QEMU升级到了2.3版本，该版本支持VM的在线快照功能，用户无需停止VM即可以生成快照。该ISO的下载链接在：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    http://download.zstack.org/ISO/ZStack-Community-x86_64-DVD-1.3.0.iso
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;百度云盘:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    http://pan.baidu.com/s/1hsqCEfa
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&quot;fusionstor&quot;&gt;8. 华云网际fusionstor插件&lt;/h3&gt;


&lt;p&gt;在1.3版本中，华云网际公司贡献了其商业存储fusionstor的插件，用户可以直接在ZStack UI上添加fusionstor作为主存储和备份存储&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/1.3/5.png&quot; class=&quot;center-img img-responsive&quot;&gt;
&lt;img src=&quot;/images/1.3/6.png&quot; class=&quot;center-img img-responsive&quot;&gt;&lt;/p&gt;

&lt;h3 id=&quot;install&quot;&gt;9. 安装&lt;/h3&gt;


&lt;p&gt;你可以通过下面方式安装：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    wget http://download.zstack.org/releases/1.3/1.3.0/zstack-installer-1.3.0.bin
    bash zstack-installer-1.3.0.bin -R aliyun
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;&lt;p&gt;这里&lt;code&gt;-R aliyun&lt;/code&gt;参数指定使用阿里云的源进行安装，你也可以使用&lt;code&gt;-R 163&lt;/code&gt;使用网易的源。我们推荐使用阿里云的源&lt;/p&gt;&lt;/blockquote&gt;

&lt;h3 id=&quot;offlineinstall&quot;&gt;10. 离线安装&lt;/h3&gt;


&lt;p&gt;针对内网用户,以及访问Internet速度较慢的用户.ZStack 1.3 提供了离线安装方式.
用户若需要离线安装ZStack,需要在目标管理节点和计算节点上安装CentOS 7.2 ZStack社区版.&lt;/p&gt;

&lt;p&gt;然后在下载了第8步中的 zstack-installer 之后,你可以通过下面方式快速完成离线安装：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    bash zstack-installer-1.3.0.bin -o
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;具体的离线安装教程和CentOS 7.2 ZStack社区版请阅读: &lt;a href=&quot;./offline-install-zstack-from-custom-iso.html&quot;&gt;ZStack离线安装教程&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;upgrade&quot;&gt;11. 升级 &lt;/h3&gt;


&lt;p&gt;一如既往的，我们支持一键无缝升级：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    wget http://download.zstack.org/releases/1.3/1.3.0/zstack-installer-1.3.0.bin
    bash zstack-installer-1.3.0.bin -u
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;多节点升级中的zstack.war文件可以从下面的链接下载：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;            wget http://download.zstack.org/releases/1.3/1.3.0/zstack.war
&lt;/code&gt;&lt;/pre&gt;
</description>
        <pubDate>Mon, 30 May 2016 00:00:00 +0800</pubDate>
        <link>http://zstack.org/cn_blog/v1.3.html</link>
        <guid isPermaLink="true">http://zstack.org/cn_blog/v1.3.html</guid>
        
        
        <category>cn_blog</category>
        
      </item>
    
      <item>
        <title>ZStack v1.2 release</title>
        <description>&lt;p&gt;Hello everyone, I am Frank Zhang, the architect of ZStack. Today I am happy to
announce that ZStack v1.2 is released.&lt;/p&gt;

&lt;h1&gt;New Features And Enhancements&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#eip&quot;&gt;Distributed EIP&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#smp&quot;&gt;Shared Mount Point Primary Storage&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#db&quot;&gt;Database Periodical Backup&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#systemd&quot;&gt;Systemd Support&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#cachemode&quot;&gt;KVM Cache Mode&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#userdata&quot;&gt;AWS EC2 Like Userdata&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;h1&gt;Installation And Upgrade&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#install&quot;&gt;Installation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#upgrade&quot;&gt;Upgrade&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;h2 id=&quot;eip&quot;&gt; 1. Distributed EIP &lt;/h2&gt;


&lt;p&gt;Distributed EIP is added as a new service type of flat network provider in this version. Users can apply an EIP(normally a public IP) to a VM on a private network dynamically without using a virtual router VM, since the EIP is created on the host where the VM is running. As the EIPs are scattered on different hosts we call it distributed EIP. Below is an overall architecutre showing that the distributed EIP is implemented through the Linux network namspace.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/1.2/eipoverview.png&quot; class=&quot;center-img img-responsive&quot;&gt;&lt;/p&gt;

&lt;p&gt;To enable the distributed EIP, users need to select the EIP service of the flat network service provider at the last step of creating a L3 network.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/1.2/eip1.png&quot; class=&quot;center-img img-responsive&quot;&gt;
&lt;img src=&quot;/images/1.2/eip2.png&quot; class=&quot;center-img img-responsive&quot;&gt;&lt;/p&gt;

&lt;p&gt;For the usage of EIP, please refer the chapter 15 of the tutorial &lt;a href=&quot;http://zstack.org/tutorials/ec2-ui.html&quot;&gt;Amazon EC2 classic EIP zone&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;smp&quot;&gt;2. Shared Mount Point Primary Storage&lt;/h2&gt;


&lt;p&gt;In order to support vast POSIX compatible distributed filesystems, we add a new type of primary storage called shared mount point storage in this version. The idea is that users can use any distributed filesystems(e.g. OCFS2, GlusterFS, MooseFS) as primary storage, as long as those filesystems are pre-mounted on the KVM hosts.&lt;/p&gt;

&lt;p&gt;Below is an example of adding a shared mount point primary storage, the URL is the absolute path of the folder where the distributed filesystem is
mounted.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;we suggest users changing /etc/rc.local or /etc/fstab to make the distributed filesystem automatically mount during Linux booting, otherwise you
will be unable to start a created VM or create a VM on your local storage.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;/images/1.2/smp.png&quot; class=&quot;center-img img-responsive&quot;&gt;&lt;/p&gt;

&lt;h2 id=&quot;db&quot;&gt;3. Database Periodical Backup&lt;/h2&gt;


&lt;p&gt;In this version, a new command &lt;code&gt;zstack-ctl dump_mysql&lt;/code&gt; is added for users to backup ZStack database.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    [root@172-20-12-46 ~]# zstack-ctl dump_mysql -h
    usage: zstackctl dump_mysql [-h] [--file-name FILE_NAME]
                          [--keep-amount KEEP_AMOUNT]

    optional arguments:
    -h, --help            show this help message and exit
    --file-name FILE_NAME
                        The filename you want to save the database, default is
                        &#39;zstack-backup-db&#39;
    --keep-amount KEEP_AMOUNT
                        The amount of backup files you want to keep, older
                        backup files will be deleted, default number is 60
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Once the all-in-one installation is done, a &lt;code&gt;crontab&lt;/code&gt; task is created as following to periodically backup your database:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;  30 0,12 * * * zstack-ctl dump_mysql --keep-amount 14
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;you can change the setting by &lt;code&gt;crontab -e&lt;/code&gt;.&lt;/p&gt;

&lt;h2 id=&quot;systemd&quot;&gt;4. Systemd Support&lt;/h2&gt;


&lt;p&gt;Systemd is supported in this version. You can use &lt;code&gt;systemctl&lt;/code&gt; to control ZStack management nodes&#39; lifecycle and make them start during Linux booting.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/1.2/systemd.png&quot; class=&quot;center-img img-responsive&quot;&gt;&lt;/p&gt;

&lt;h2 id=&quot;cachemode&quot;&gt;5. KVM Cache Mode&lt;/h2&gt;


&lt;p&gt;In this version, users can configure the &lt;code&gt;cache mode&lt;/code&gt; of volumes on the KVM hosts by a global configuration. There are three modes supported now:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;none&lt;/strong&gt;: With caching mode set to none, the host page cache is disabled, but the disk write cache is enabled for the guest. In this mode, the write performance in the guest is optimal because write operations bypass the host page cache and go directly to the disk write cache. If the disk write cache is battery-backed, or if the applications or storage stack in the guest transfer data properly (either through fsync operations or file system barriers), then data integrity can be ensured. However, because the host page cache is disabled, the read performance in the guest would not be as good as in the modes where the host page cache is enabled, such as writethrough mode.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;writeback&lt;/strong&gt;: With caching set to writeback mode, both the host page cache and the disk write cache are enabled for the guest. Because of this, the I/O performance for applications running in the guest is good, but the data is not protected in a power failure. As a result, this caching mode is recommended only for temporary data where potential data loss is not a concern.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;writethrough&lt;/strong&gt;: writethrough mode is the default caching mode. With caching set to writethrough mode, the host page cache is enabled, but the disk write cache is disabled for the guest. Consequently, this caching mode ensures data integrity even if the applications and storage stack in the guest do not transfer data to permanent storage properly (either through fsync operations or file system barriers). Because the host page cache is enabled in this mode, the read performance for applications running in the guest is generally better. However, the write performance might be reduced because the disk write cache is disabled.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;For details of KVM cache mode you can refer &lt;a href=&quot;https://www.ibm.com/support/knowledgecenter/linuxonibm/liaat/liaatbpkvmguestcache.htm&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The global configuration can be changed through UI or command line:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/1.2/cachemode.png&quot; class=&quot;center-img img-responsive&quot;&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt;UpdateGlobalConfig category=kvm name=vm.cacheMode value=writethrough
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;userdata&quot;&gt;6. AWS EC2 Way To Access Userdata&lt;/h2&gt;


&lt;p&gt;Beginning at the version 1.0, ZStack supports AWS EC2 userdata with cloud-init. However, the original way to access userdata is CloudStack like, which requires users to change the default configuration of cloud-init package and sometimes make people confused. In this version, ZStack starts using AWS EC2 way to distribute userdata, which means users can access userdata/metadata by a special IP address(169.254.169.254). It&#39;s also the default way that cloud-init fetches userdata, so users can directly use cloud-init built-in packages from CentOS and Ubuntu, without any modification.&lt;/p&gt;

&lt;h2 id=&quot;install&quot;&gt;7. Installation&lt;/h2&gt;


&lt;p&gt;You can install the 1.2 release by:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    wget http://download.zstack.org/releases/1.2/1.2.0/zstack-installer-1.2.0.bin
    bash zstack-installer-1.2.0.bin
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;upgrade&quot;&gt;8. Upgrade&lt;/h2&gt;


&lt;p&gt;You can upgrade your previous ZStack to 1.2 by:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    wget http://download.zstack.org/releases/1.2/1.2.0/zstack-installer-1.2.0.bin
    bash zstack-installer-1.2.0.bin -u
&lt;/code&gt;&lt;/pre&gt;
</description>
        <pubDate>Wed, 04 May 2016 00:00:00 +0800</pubDate>
        <link>http://zstack.org/blog/v1.2.html</link>
        <guid isPermaLink="true">http://zstack.org/blog/v1.2.html</guid>
        
        
        <category>blog</category>
        
      </item>
    
      <item>
        <title>ZStack v1.2 release</title>
        <description>&lt;p&gt;Hello everyone, I am Frank Zhang, the architect of ZStack. Today I am happy to
announce that ZStack v1.2 is released.&lt;/p&gt;

&lt;h1&gt;New Features And Enhancements&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#eip&quot;&gt;Distributed EIP&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#smp&quot;&gt;Shared Mount Point Primary Storage&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#db&quot;&gt;Database Periodical Backup&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#systemd&quot;&gt;Systemd Support&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#cachemode&quot;&gt;KVM Cache Mode&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#userdata&quot;&gt;AWS EC2 Like Userdata&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;h1&gt;Installation And Upgrade&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#install&quot;&gt;Installation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#upgrade&quot;&gt;Upgrade&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;h2 id=&quot;eip&quot;&gt; 1. Distributed EIP &lt;/h2&gt;


&lt;p&gt;Distributed EIP is added as a new service type of flat network provider in this version. Users can apply an EIP(normally a public IP) to a VM on a private network dynamically without using a virtual router VM, since the EIP is created on the host where the VM is running. As the EIPs are scattered on different hosts we call it distributed EIP. Below is an overall architecutre showing that the distributed EIP is implemented through the Linux network namspace.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/1.2/eipoverview.png&quot; class=&quot;center-img img-responsive&quot;&gt;&lt;/p&gt;

&lt;p&gt;To enable the distributed EIP, users need to select the EIP service of the flat network service provider at the last step of creating a L3 network.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/1.2/eip1.png&quot; class=&quot;center-img img-responsive&quot;&gt;
&lt;img src=&quot;/images/1.2/eip2.png&quot; class=&quot;center-img img-responsive&quot;&gt;&lt;/p&gt;

&lt;p&gt;For the usage of EIP, please refer the chapter 15 of the tutorial &lt;a href=&quot;http://zstack.org/tutorials/ec2-ui.html&quot;&gt;Amazon EC2 classic EIP zone&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;smp&quot;&gt;2. Shared Mount Point Primary Storage&lt;/h2&gt;


&lt;p&gt;In order to support vast POSIX compatible distributed filesystems, we add a new type of primary storage called shared mount point storage in this version. The idea is that users can use any distributed filesystems(e.g. OCFS2, GlusterFS, MooseFS) as primary storage, as long as those filesystems are pre-mounted on the KVM hosts.&lt;/p&gt;

&lt;p&gt;Below is an example of adding a shared mount point primary storage, the URL is the absolute path of the folder where the distributed filesystem is
mounted.&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;we suggest users changing /etc/rc.local or /etc/fstab to make the distributed filesystem automatically mount during Linux booting, otherwise you
will be unable to start a created VM or create a VM on your local storage.&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;/images/1.2/smp.png&quot; class=&quot;center-img img-responsive&quot;&gt;&lt;/p&gt;

&lt;h2 id=&quot;db&quot;&gt;3. Database Periodical Backup&lt;/h2&gt;


&lt;p&gt;In this version, a new command &lt;code&gt;zstack-ctl dump_mysql&lt;/code&gt; is added for users to backup ZStack database.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    [root@172-20-12-46 ~]# zstack-ctl dump_mysql -h
    usage: zstackctl dump_mysql [-h] [--file-name FILE_NAME]
                          [--keep-amount KEEP_AMOUNT]

    optional arguments:
    -h, --help            show this help message and exit
    --file-name FILE_NAME
                        The filename you want to save the database, default is
                        &#39;zstack-backup-db&#39;
    --keep-amount KEEP_AMOUNT
                        The amount of backup files you want to keep, older
                        backup files will be deleted, default number is 60
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Once the all-in-one installation is done, a &lt;code&gt;crontab&lt;/code&gt; task is created as following to periodically backup your database:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;  30 0,12 * * * zstack-ctl dump_mysql --keep-amount 14
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;you can change the setting by &lt;code&gt;crontab -e&lt;/code&gt;.&lt;/p&gt;

&lt;h2 id=&quot;systemd&quot;&gt;4. Systemd Support&lt;/h2&gt;


&lt;p&gt;Systemd is supported in this version. You can use &lt;code&gt;systemctl&lt;/code&gt; to control ZStack management nodes&#39; lifecycle and make them start during Linux booting.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/1.2/systemd.png&quot; class=&quot;center-img img-responsive&quot;&gt;&lt;/p&gt;

&lt;h2 id=&quot;cachemode&quot;&gt;5. KVM Cache Mode&lt;/h2&gt;


&lt;p&gt;In this version, users can configure the &lt;code&gt;cache mode&lt;/code&gt; of volumes on the KVM hosts by a global configuration. There are three modes supported now:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;none&lt;/strong&gt;: With caching mode set to none, the host page cache is disabled, but the disk write cache is enabled for the guest. In this mode, the write performance in the guest is optimal because write operations bypass the host page cache and go directly to the disk write cache. If the disk write cache is battery-backed, or if the applications or storage stack in the guest transfer data properly (either through fsync operations or file system barriers), then data integrity can be ensured. However, because the host page cache is disabled, the read performance in the guest would not be as good as in the modes where the host page cache is enabled, such as writethrough mode.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;writeback&lt;/strong&gt;: With caching set to writeback mode, both the host page cache and the disk write cache are enabled for the guest. Because of this, the I/O performance for applications running in the guest is good, but the data is not protected in a power failure. As a result, this caching mode is recommended only for temporary data where potential data loss is not a concern.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;writethrough&lt;/strong&gt;: writethrough mode is the default caching mode. With caching set to writethrough mode, the host page cache is enabled, but the disk write cache is disabled for the guest. Consequently, this caching mode ensures data integrity even if the applications and storage stack in the guest do not transfer data to permanent storage properly (either through fsync operations or file system barriers). Because the host page cache is enabled in this mode, the read performance for applications running in the guest is generally better. However, the write performance might be reduced because the disk write cache is disabled.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;For details of KVM cache mode you can refer &lt;a href=&quot;https://www.ibm.com/support/knowledgecenter/linuxonibm/liaat/liaatbpkvmguestcache.htm&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The global configuration can be changed through UI or command line:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/1.2/cachemode.png&quot; class=&quot;center-img img-responsive&quot;&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt;UpdateGlobalConfig category=kvm name=vm.cacheMode value=writethrough
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;userdata&quot;&gt;6. AWS EC2 Way To Access Userdata&lt;/h2&gt;


&lt;p&gt;Beginning at the version 1.0, ZStack supports AWS EC2 userdata with cloud-init. However, the original way to access userdata is CloudStack like, which requires users to change the default configuration of cloud-init package and sometimes make people confused. In this version, ZStack starts using AWS EC2 way to distribute userdata, which means users can access userdata/metadata by a special IP address(169.254.169.254). It&#39;s also the default way that cloud-init fetches userdata, so users can directly use cloud-init built-in packages from CentOS and Ubuntu, without any modification.&lt;/p&gt;

&lt;h2 id=&quot;install&quot;&gt;7. Installation&lt;/h2&gt;


&lt;p&gt;You can install the 1.2 release by:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    wget http://download.zstack.org/releases/1.2/1.2.0/zstack-installer-1.2.0.bin
    bash zstack-installer-1.2.0.bin
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;upgrade&quot;&gt;8. Upgrade&lt;/h2&gt;


&lt;p&gt;You can upgrade your previous ZStack to 1.2 by:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    wget http://download.zstack.org/releases/1.2/1.2.0/zstack-installer-1.2.0.bin
    bash zstack-installer-1.2.0.bin -u
&lt;/code&gt;&lt;/pre&gt;
</description>
        <pubDate>Wed, 04 May 2016 00:00:00 +0800</pubDate>
        <link>http://zstack.org/cn/blog/v1.2.html</link>
        <guid isPermaLink="true">http://zstack.org/cn/blog/v1.2.html</guid>
        
        
        <category>blog</category>
        
      </item>
    
      <item>
        <title>ZStack v1.2 发布</title>
        <description>&lt;h2&gt;ZStack 1.2 版本今天正式发布&lt;/h2&gt;

&lt;p&gt;ZStack 1.2 版本今天发布，欢迎大家下载试用。在该版中，我们修复了1.1版本中发现的bug，并增加了分布EIP、shared mountpoint主存储支持、数据库自动备份、Systemd支持等新功能。用户不再需要使用Virtual Router就可以使用EIP网络模式，也可以无缝的使用GlusterFS、MooseFS、OCFS2等分布式文件系统作为主存储。具体细节参考以下章节。&lt;/p&gt;

&lt;h2&gt;新增功能&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#eip&quot;&gt;分布式EIP&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#smp&quot;&gt;Shared Mountpoint主存储&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#database&quot;&gt;数据库定时备份&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#systemd&quot;&gt;Systemd支持&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#cachemode&quot;&gt;KVM缓存模式配置&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#userdata&quot;&gt;AWS EC2模式Userdata支持&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;h2&gt;安装升级&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#install&quot;&gt;安装&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#offlineinstall&quot;&gt;离线安装&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#upgrade&quot;&gt;升级&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;h3 id=&quot;eip&quot;&gt;1. 分布式EIP &lt;/h3&gt;


&lt;p&gt;在1.0版本中，我们增加了一个新的网络服务组件：FlatNetwork Provider，可以提供分布式DHCP支持。在1.2版本中，我们继续增强了该provider的功能，加入了分布式EIP支持。通过这种方式，用户无需再使用传统的virtual router方式就可以部署EIP网络模型，拥有独立的私有网络，并将公网IP地址映射到私有网络的中的云主机去。ZStack的分布式EIP通过Linux的network namespace实现，原理图如下：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/1.2/eipoverview.png&quot; class=&quot;center-img img-responsive&quot;&gt;&lt;/p&gt;

&lt;p&gt;要使用分布式EIP，用户只需在创建L3网络的时候，选择Flat Network Service Provider作为网络服务提供组件，并选择加载EIP服务即可。步骤如图：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/1.2/eip1.png&quot; class=&quot;center-img img-responsive&quot;&gt;
&lt;img src=&quot;/images/1.2/eip2.png&quot; class=&quot;center-img img-responsive&quot;&gt;&lt;/p&gt;

&lt;p&gt;要绑定EIP到私有网络的云主机，参考教程&lt;a href=&quot;http://zstack.org/cn/tutorials/ec2-ui.html&quot;&gt;经典Amazon EC2 EIP环境&lt;/a&gt;第15节即可。&lt;/p&gt;

&lt;h3 id=&quot;smp&quot;&gt;2. Shared Mountpoint主存储&lt;/h3&gt;


&lt;p&gt;在1.2版本中，我们新增了一种主存储(Primary Storage)类型：Shared Mountpoint Storage。通过该主存储，ZStack可以支持任何符合POSIX文件系统规范的分布式文件系统，例如大家熟悉的GlusterFS、MooseFS、OCFS2等。&lt;/p&gt;

&lt;p&gt;在使用前，用户需要先部署好你所使用的分布式文件系统，并将它mount到所有host相同的目录上，例如将GlusterFS mount到所有host的/glusterfs_dir目录中。在添加主存储时，选择类型“SharedMountPoint”并输入对应目录绝对路径即可，如图：&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;我们建议用户把mount分布式文件系统的命令放到每个host的/etc/rc.local或/etc/fstab当中，以避免host重启后，分布式文件系统没有挂载的情况。&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;/images/1.2/smp.png&quot; class=&quot;center-img img-responsive&quot;&gt;&lt;/p&gt;

&lt;h3 id=&quot;database&quot;&gt;3. 数据库定时备份&lt;/h3&gt;


&lt;p&gt;在1.2版本中，我们提供了一个新的命令&lt;code&gt;zstack-ctl dump_mysql&lt;/code&gt;为用户备份ZStack的数据库：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    [root@172-20-12-46 ~]# zstack-ctl dump_mysql -h
    usage: zstackctl dump_mysql [-h] [--file-name FILE_NAME]
                                [--keep-amount KEEP_AMOUNT]

    optional arguments:
        -h, --help            show this help message and exit
        --file-name FILE_NAME
                              The filename you want to save the database, default is
                              &#39;zstack-backup-db&#39;
        --keep-amount KEEP_AMOUNT
                              The amount of backup files you want to keep, older
                              backup files will be deleted, default number is 60
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在使用zstack all-in-one安装包安装后，我们会默认建立一个&lt;code&gt;crontab&lt;/code&gt;任务定时备份数据库，其设置为：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;30 0,12 * * * zstack-ctl dump_mysql --keep-amount 14
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;用户可以用&lt;code&gt;crontab -l&lt;/code&gt;的命令查看，或用&lt;code&gt;crontab -e&lt;/code&gt;修改。&lt;/p&gt;

&lt;h3 id=&quot;cachemode&quot;&gt;5. KVM cache mode选项&lt;/h3&gt;


&lt;p&gt;在1.2版本中，用户可以通过修改全局设置的来指定启动云主机时，KVM对云盘使用的缓存模式。支持三种模式：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;none:云主机不使用物理机的页面缓存，直接访问存储，不带cache。&lt;strong&gt;默认模式&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;writethrough:物理机的页面缓存工作在透写模式，数据完全写入云主机存储设备后，才返回成功。&lt;/li&gt;
&lt;li&gt;writeback:云主机使用了物理机的页面缓存机制，数据写入物理机页面缓存即报告给云主机返回成功。&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;KVM cache mode的具体解释可以参考&lt;a href=&quot;https://www.ibm.com/support/knowledgecenter/linuxonibm/liaat/liaatbpkvmguestcache.htm&quot;&gt;这篇文章&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;要修改该选项，可以使用UI：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/1.2/cachemode.png&quot; class=&quot;center-img img-responsive&quot;&gt;&lt;/p&gt;

&lt;p&gt;或命令行：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt;UpdateGlobalConfig category=kvm name=vm.cacheMode value=writethrough
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&quot;userdata&quot;&gt;6. AWS EC2模式Userdata支持&lt;/h3&gt;


&lt;p&gt;在1.0版本中，我们加入了对userdata的支持，使用的是CloudStack默认，用户需要修改cloud-init配置文件才能使用。在1.2版本中，我们将userdata的支持方式换成了AWS EC2模式，即云主机操作系统可以通过169.254.169.254这个IP地址获得userdata。该模式是cloud-init的默认模式，用户只需安装cloud-init包，无需修改任何配置就可以直接使用。此外，用户也可以从Ubuntu和Centos的官方网站上下载预装cloud-init的镜像直接使用。&lt;/p&gt;

&lt;h3 id=&quot;systemd&quot;&gt;7. Systemd支持&lt;/h3&gt;


&lt;p&gt;在1.2版本中，我们加入了对systemd的支持，用户可以通过&lt;code&gt;systemctl&lt;/code&gt;来控制zstack管理节点的生命周期。这同时修复了安装了zstack管理节点关机慢的问题。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/1.2/systemd.png&quot; class=&quot;center-img img-responsive&quot;&gt;&lt;/p&gt;

&lt;h3 id=&quot;install&quot;&gt;8. 安装&lt;/h3&gt;


&lt;p&gt;你可以通过下面方式安装：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    wget http://download.zstack.org/releases/1.2/1.2.0/zstack-installer-1.2.0.bin
    bash zstack-installer-1.2.0.bin -R aliyun
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;&lt;p&gt;这里&lt;code&gt;-R aliyun&lt;/code&gt;参数指定使用阿里云的源进行安装，你也可以使用&lt;code&gt;-R 163&lt;/code&gt;使用网易的源。我们推荐使用阿里云的源&lt;/p&gt;&lt;/blockquote&gt;

&lt;h3 id=&quot;offlineinstall&quot;&gt;9. 离线安装&lt;/h3&gt;


&lt;p&gt;针对内网用户,以及访问Internet速度较慢的用户.ZStack 1.2 提供了离线安装方式.
用户若需要离线安装ZStack,需要在目标管理节点和计算节点上安装CentOS 7.2 ZStack社区版.&lt;/p&gt;

&lt;p&gt;然后在下载了第8步中的 zstack-installer 之后,你可以通过下面方式快速完成离线安装：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    bash zstack-installer-1.2.0.bin -o
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;具体的离线安装教程和CentOS 7.2 ZStack社区版请阅读: &lt;a href=&quot;./offline-install-zstack-from-custom-iso.html&quot;&gt;ZStack离线安装教程&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;upgrade&quot;&gt;10. 升级 &lt;/h3&gt;


&lt;p&gt;一如既往的，我们支持一键无缝升级：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    wget http://download.zstack.org/releases/1.2/1.2.0/zstack-installer-1.2.0.bin
    bash zstack-installer-1.2.0.bin -u
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;多节点升级中的zstack.war请等待正式版发布。&lt;/p&gt;
</description>
        <pubDate>Fri, 29 Apr 2016 00:00:00 +0800</pubDate>
        <link>http://zstack.org/cn_blog/v1.2.html</link>
        <guid isPermaLink="true">http://zstack.org/cn_blog/v1.2.html</guid>
        
        
        <category>cn_blog</category>
        
      </item>
    
      <item>
        <title>ZStack v1.2 RC1 发布</title>
        <description>&lt;h2&gt;ZStack 1.2 RC1 版本今天发布&lt;/h2&gt;

&lt;p&gt;ZStack 1.2 RC1 版本今天发布，欢迎大家下载试用。在该版中，我们修复了1.1版本中发现的bug，并增加了分布EIP、shared mountpoint主存储支持、数据库自动备份、Systemd支持等新功能。用户不再需要使用Virtual Router就可以使用EIP网络模式，也可以无缝的使用GlusterFS、MooseFS、OCFS2等分布式文件系统作为主存储。具体细节参考以下章节。&lt;/p&gt;

&lt;h2&gt;新增功能&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#eip&quot;&gt;分布式EIP&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#smp&quot;&gt;Shared Mountpoint主存储&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#database&quot;&gt;数据库定时备份&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#systemd&quot;&gt;Systemed支持&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#cachemode&quot;&gt;KVM缓存模式配置&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#userdata&quot;&gt;AWS EC2模式Userdata支持&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;h2&gt;安装升级&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#install&quot;&gt;安装&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#offlineinstall&quot;&gt;离线安装&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#upgrade&quot;&gt;升级&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;h3 id=&quot;eip&quot;&gt;1. 分布式EIP &lt;/h3&gt;


&lt;p&gt;在1.0版本中，我们增加了一个新的网络服务组件：FlatNetwork Provider，可以提供分布式DHCP支持。在1.2版本中，我们继续增强了该provider的功能，加入了分布式EIP支持。通过这种方式，用户无需再使用传统的virtual router方式就可以部署EIP网络模型，拥有独立的私有网络，并将公网IP地址映射到私有网络的中的云主机去。ZStack的分布式EIP通过Linux的network namespace实现，原理图如下：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/1.2/eipoverview.png&quot; class=&quot;center-img img-responsive&quot;&gt;&lt;/p&gt;

&lt;p&gt;要使用分布式EIP，用户只需在创建L3网络的时候，选择Flat Network Service Provider作为网络服务提供组件，并选择加载EIP服务即可。步骤如图：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/1.2/eip1.png&quot; class=&quot;center-img img-responsive&quot;&gt;
&lt;img src=&quot;/images/1.2/eip2.png&quot; class=&quot;center-img img-responsive&quot;&gt;&lt;/p&gt;

&lt;p&gt;要绑定EIP到私有网络的云主机，参考教程&lt;a href=&quot;http://zstack.org/cn/tutorials/ec2-ui.html&quot;&gt;经典Amazon EC2 EIP环境&lt;/a&gt;第15节即可。&lt;/p&gt;

&lt;h3 id=&quot;smp&quot;&gt;2. Shared Mountpoint主存储&lt;/h3&gt;


&lt;p&gt;在1.2版本中，我们新增了一种主存储(Primary Storage)类型：Shared Mountpoint Storage。通过该主存储，ZStack可以支持任何符合POSIX文件系统规范的分布式文件系统，例如大家熟悉的GlusterFS、MooseFS、OCFS2等。&lt;/p&gt;

&lt;p&gt;在使用前，用户需要先部署好你所使用的分布式文件系统，并将它mount到所有host相同的目录上，例如将GlusterFS mount到所有host的/glusterfs_dir目录中。在添加主存储时，选择类型“SharedMountPoint”并输入对应目录绝对路径即可，如图：&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;我们建议用户把mount分布式文件系统的命令放到每个host的/etc/rc.local或/etc/fstab当中，以避免host重启后，分布式文件系统没有挂载的情况。&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;/images/1.2/smp.png&quot; class=&quot;center-img img-responsive&quot;&gt;&lt;/p&gt;

&lt;h3 id=&quot;database&quot;&gt;3. 数据库定时备份&lt;/h3&gt;


&lt;p&gt;在1.2版本中，我们提供了一个新的命令&lt;code&gt;zstack-ctl dump_mysql&lt;/code&gt;为用户备份ZStack的数据库：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    [root@172-20-12-46 ~]# zstack-ctl dump_mysql -h
    usage: zstackctl dump_mysql [-h] [--file-name FILE_NAME]
                                [--keep-amount KEEP_AMOUNT]

    optional arguments:
        -h, --help            show this help message and exit
        --file-name FILE_NAME
                              The filename you want to save the database, default is
                              &#39;zstack-backup-db&#39;
        --keep-amount KEEP_AMOUNT
                              The amount of backup files you want to keep, older
                              backup files will be deleted, default number is 60
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在使用zstack all-in-one安装包安装后，我们会默认建立一个&lt;code&gt;crontab&lt;/code&gt;任务定时备份数据库，其设置为：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;30 0,12 * * * zstack-ctl dump_mysql --keep-amount 14
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;用户可以用&lt;code&gt;crontab -l&lt;/code&gt;的命令查看，或用&lt;code&gt;crontab -e&lt;/code&gt;修改。&lt;/p&gt;

&lt;h3 id=&quot;cachemode&quot;&gt;5. KVM cache mode选项&lt;/h3&gt;


&lt;p&gt;在1.2版本中，用户可以通过修改全局设置的来指定启动云主机时，KVM对云盘使用的缓存模式。支持三种模式：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;none:云主机不使用物理机的页面缓存，直接访问存储，不带cache。&lt;strong&gt;默认模式&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;writethrough:物理机的页面缓存工作在透写模式，数据完全写入云主机存储设备后，才返回成功。&lt;/li&gt;
&lt;li&gt;writeback:云主机使用了物理机的页面缓存机制，数据写入物理机页面缓存即报告给云主机返回成功。&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;KVM cache mode的具体解释可以参考&lt;a href=&quot;https://www.ibm.com/support/knowledgecenter/linuxonibm/liaat/liaatbpkvmguestcache.htm&quot;&gt;这篇文章&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;要修改该选项，可以使用UI：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/1.2/cachemode.png&quot; class=&quot;center-img img-responsive&quot;&gt;&lt;/p&gt;

&lt;p&gt;或命令行：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt;UpdateGlobalConfig category=kvm name=vm.cacheMode value=writethrough
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&quot;userdata&quot;&gt;6. AWS EC2模式Userdata支持&lt;/h3&gt;


&lt;p&gt;在1.0版本中，我们加入了对userdata的支持，使用的是CloudStack默认，用户需要修改cloud-init配置文件才能使用。在1.2版本中，我们将userdata的支持方式换成了AWS EC2模式，即云主机操作系统可以通过169.254.169.254这个IP地址获得userdata。该模式是cloud-init的默认模式，用户只需安装cloud-init包，无需修改任何配置就可以直接使用。此外，用户也可以从Ubuntu和Centos的官方网站上下载预装cloud-init的镜像直接使用。&lt;/p&gt;

&lt;h3 id=&quot;systemd&quot;&gt;7. Systemd支持&lt;/h3&gt;


&lt;p&gt;在1.2版本中，我们加入了对systemd的支持，用户可以通过&lt;code&gt;systemctl&lt;/code&gt;来控制zstack管理节点的生命周期。这同时修复了安装了zstack管理节点关机慢的问题。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/1.2/systemd.png&quot; class=&quot;center-img img-responsive&quot;&gt;&lt;/p&gt;

&lt;h3 id=&quot;install&quot;&gt;8. 安装&lt;/h3&gt;


&lt;p&gt;你可以通过下面方式安装：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    wget http://download.zstack.org/releases/1.2/1.2.0/rc2/zstack-installer-1.2.0-rc2.bin
    bash zstack-installer-1.2.0-rc2.bin -R aliyun
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;&lt;p&gt;这里&lt;code&gt;-R aliyun&lt;/code&gt;参数指定使用阿里云的源进行安装，你也可以使用&lt;code&gt;-R 163&lt;/code&gt;使用网易的源。我们推荐使用阿里云的源&lt;/p&gt;&lt;/blockquote&gt;

&lt;h3 id=&quot;offlineinstall&quot;&gt;9. 离线安装&lt;/h3&gt;


&lt;p&gt;针对内网用户,以及访问Internet速度较慢的用户.ZStack 1.2 提供了离线安装方式.
用户若需要离线安装ZStack,需要在目标管理节点和计算节点上安装CentOS 7.2 ZStack社区版.&lt;/p&gt;

&lt;p&gt;然后在下载了第8步中的 zstack-installer 之后,你可以通过下面方式快速完成离线安装：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    bash zstack-installer-1.2.0-rc2.bin -o
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;具体的离线安装教程和CentOS 7.2 ZStack社区版请阅读: &lt;a href=&quot;./offline-install-zstack-from-custom-iso.html&quot;&gt;ZStack离线安装教程&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;upgrade&quot;&gt;10. 升级 &lt;/h3&gt;


&lt;p&gt;一如既往的，我们支持一键无缝升级：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    wget http://download.zstack.org/releases/1.2/1.2.0/rc2/zstack-installer-1.2.0-rc2.bin
    bash zstack-installer-1.2.0-rc2.bin -u
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;多节点升级中的zstack.war请等待正式版发布。&lt;/p&gt;
</description>
        <pubDate>Fri, 22 Apr 2016 00:00:00 +0800</pubDate>
        <link>http://zstack.org/cn_blog/v1.2-rc1.html</link>
        <guid isPermaLink="true">http://zstack.org/cn_blog/v1.2-rc1.html</guid>
        
        
        <category>cn_blog</category>
        
      </item>
    
      <item>
        <title>ZStack v1.1.2 发布</title>
        <description>&lt;h2&gt;ZStack 1.1.2 版本今天发布&lt;/h2&gt;

&lt;p&gt;ZStack v1.1.2 修复了部分 zstack-ctl 的功能,以便搭建ZStack HA的集群.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#zstackctl&quot;&gt;使用zstack-ctl修改管理节点IP地址&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#install&quot;&gt;一键安装&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#offlineinstall&quot;&gt;离线安装&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#upgrade&quot;&gt;无缝升级&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;h2&gt;功能提升&lt;/h2&gt;

&lt;h3 id=&quot;zstackctl&quot;&gt;1. 使用zstack-ctl修改管理节点IP地址&lt;/h3&gt;


&lt;p&gt;在之前的版本中,如果管理节点IP变更,我们需要用户手动修改 zstack.properties的文件.
从1.1 版本开始,我们提供了全新的&lt;code&gt;zstack-ctl change_ip&lt;/code&gt;来帮助用户修改管理节点,
数据库,消息总线的IP地址. 例如:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[root@172-20-11-73 ~]# zstack-ctl change_ip --ip 172.20.11.73
Update cloudbus server ip 172.20.11.73 in /usr/local/zstack/apache-tomcat/webapps/zstack/WEB-INF/classes/zstack.properties 
Update mysql new url jdbc:mysql://172.20.11.73:3306 in /usr/local/zstack/apache-tomcat/webapps/zstack/WEB-INF/classes/zstack.properties 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;如果数据库,消息总线使用了不同的IP地址,我们也可以使用该命令进行修改.具体的参数细节,请添加-h 参数获取:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[root@172-20-11-73 ~]# zstack-ctl change_ip -h
usage: zstackctl change_ip [-h] --ip IP [--kairosdb_ip KAIROSDB_IP]
                           [--cassandra_rpc_address CASSANDRA_RPC_ADDRESS]
                           [--cassandra_listen_address CASSANDRA_LISTEN_ADDRESS]
                           [--cloudbus_server_ip CLOUDBUS_SERVER_IP]
                           [--mysql_ip MYSQL_IP]

optional arguments:
  -h, --help            show this help message and exit
  --ip IP               The new IP address of management node.This operation
                        will update the new ip address to zstack, kairosdb and
                        cassandra config file
  --kairosdb_ip KAIROSDB_IP
                        The new IP address of kairosdb, default will use value
                        from --ip
  --cassandra_rpc_address CASSANDRA_RPC_ADDRESS
                        The new IP address of cassandra_rpc_address, default
                        will use value from --ip
  --cassandra_listen_address CASSANDRA_LISTEN_ADDRESS
                        The new IP address of cassandra_listen_address,
                        default will use value from --ip
  --cloudbus_server_ip CLOUDBUS_SERVER_IP
                        The new IP address of CloudBus.serverIp.0, default
                        will use value from --ip
  --mysql_ip MYSQL_IP   The new IP address of DB.url, default will use value
                        from --ip
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&quot;install&quot;&gt; 2. 安装 &lt;/h3&gt;


&lt;p&gt;你可以通过下面方式安装：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    wget http://download.zstack.org/releases/1.1/1.1.2/zstack-installer-1.1.2.bin -O zstack-installer-1.1.2.bin
    bash zstack-installer-1.1.2.bin -R aliyun
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;&lt;p&gt;这里&lt;code&gt;-R aliyun&lt;/code&gt;参数指定使用阿里云的源进行安装，你也可以使用&lt;code&gt;-R 163&lt;/code&gt;使用网易的源。我们推荐使用阿里云的源&lt;/p&gt;&lt;/blockquote&gt;

&lt;h3 id=&quot;offlineinstall&quot;&gt; 3. 离线安装 ZStack &lt;/h3&gt;


&lt;p&gt;针对内网用户,以及访问Internet速度较慢的用户.ZStack 1.1 提供了离线安装方式.
用户若需要离线安装ZStack,需要在目标管理节点和计算节点上安装CentOS 7.2 ZStack社区版.&lt;/p&gt;

&lt;p&gt;然后在下载了第8步中的 zstack-installer 之后,你可以通过下面方式快速完成离线安装：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    bash zstack-installer-1.1.2.bin -o
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;具体的离线安装教程和CentOS 7.2 ZStack社区版请阅读: &lt;a href=&quot;./offline-install-zstack-from-custom-iso.html&quot;&gt;ZStack离线安装教程&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;upgrade&quot;&gt; 4. 升级 &lt;/h3&gt;


&lt;p&gt;一如既往的，我们支持一键无缝升级：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    wget http://download.zstack.org/releases/1.1/1.1.2/zstack-installer-1.1.2.bin -O zstack-installer-1.1.2.bin
    bash zstack-installer-1.1.2.bin -u
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;多节点升级中的zstack.war 可以从如下链接获取: http://download.zstack.org/releases/1.1/1.1.2/zstack.war&lt;/p&gt;
</description>
        <pubDate>Sat, 09 Apr 2016 00:00:00 +0800</pubDate>
        <link>http://zstack.org/cn_blog/v1.1.2.html</link>
        <guid isPermaLink="true">http://zstack.org/cn_blog/v1.1.2.html</guid>
        
        
        <category>cn_blog</category>
        
      </item>
    
      <item>
        <title>ZStack v1.1.1 发布</title>
        <description>&lt;h2&gt;ZStack 1.1.1 版本今天发布&lt;/h2&gt;

&lt;p&gt;ZStack v1.1.1 修复了 v1.1.0里两个缺陷: 默认超时过短和添加Ceph存储出错. 建议用户升级.&lt;/p&gt;

&lt;h2&gt;修复缺陷&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#timeout&quot;&gt;默认超时过短&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#ceph&quot;&gt;添加Ceph存储出错&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;h2&gt;功能提升&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#zstackctl&quot;&gt;使用zstack-ctl修改管理节点IP地址&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;h3 id=&quot;timeout&quot;&gt;1. 默认超时过短 &lt;/h3&gt;


&lt;p&gt;1.1.0 版本中默认超时存在一个缺陷,导致API的默认超时仅为300秒. 1.1.1版本已经把耗时API超时时间加长到了默认3个小时,例如下载Image的API,创建Image的API.&lt;/p&gt;

&lt;h3 id=&quot;ceph&quot;&gt;2. 添加Ceph存储出错 &lt;/h3&gt;


&lt;p&gt;1.1.0 版本中的资源添加优化程序存在一个缺陷,导致ceph存储添加可能出现错误. 1.1.1版本已经修复了该错误.&lt;/p&gt;

&lt;h3 id=&quot;zstackctl&quot;&gt;3. 使用zstack-ctl修改管理节点IP地址&lt;/h3&gt;


&lt;p&gt;在之前的版本中,如果管理节点IP变更,我们需要用户手动修改 zstack.properties的文件.
从1.1 版本开始,我们提供了全新的&lt;code&gt;zstack-ctl change_ip&lt;/code&gt;来帮助用户修改管理节点,
数据库,消息总线的IP地址. 例如:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[root@172-20-11-73 ~]# zstack-ctl change_ip --ip 172.20.11.73
Update cloudbus server ip 172.20.11.73 in /usr/local/zstack/apache-tomcat/webapps/zstack/WEB-INF/classes/zstack.properties 
Update mysql new url jdbc:mysql://172.20.11.73:3306 in /usr/local/zstack/apache-tomcat/webapps/zstack/WEB-INF/classes/zstack.properties 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;如果数据库,消息总线使用了不同的IP地址,我们也可以使用该命令进行修改.具体的参数细节,请添加-h 参数获取:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[root@172-20-11-73 ~]# zstack-ctl change_ip -h
usage: zstackctl change_ip [-h] --ip IP [--kairosdb_ip KAIROSDB_IP]
                           [--cassandra_rpc_address CASSANDRA_RPC_ADDRESS]
                           [--cassandra_listen_address CASSANDRA_LISTEN_ADDRESS]
                           [--cloudbus_server_ip CLOUDBUS_SERVER_IP]
                           [--mysql_ip MYSQL_IP]

optional arguments:
  -h, --help            show this help message and exit
  --ip IP               The new IP address of management node.This operation
                        will update the new ip address to zstack, kairosdb and
                        cassandra config file
  --kairosdb_ip KAIROSDB_IP
                        The new IP address of kairosdb, default will use value
                        from --ip
  --cassandra_rpc_address CASSANDRA_RPC_ADDRESS
                        The new IP address of cassandra_rpc_address, default
                        will use value from --ip
  --cassandra_listen_address CASSANDRA_LISTEN_ADDRESS
                        The new IP address of cassandra_listen_address,
                        default will use value from --ip
  --cloudbus_server_ip CLOUDBUS_SERVER_IP
                        The new IP address of CloudBus.serverIp.0, default
                        will use value from --ip
  --mysql_ip MYSQL_IP   The new IP address of DB.url, default will use value
                        from --ip
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&quot;install&quot;&gt; 4. 安装 &lt;/h3&gt;


&lt;p&gt;你可以通过下面方式安装：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    wget http://download.zstack.org/releases/1.1/1.1.1/zstack-installer-1.1.1.bin -O zstack-installer-1.1.1.bin
    bash zstack-installer-1.1.1.bin -R aliyun
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;&lt;p&gt;这里&lt;code&gt;-R aliyun&lt;/code&gt;参数指定使用阿里云的源进行安装，你也可以使用&lt;code&gt;-R 163&lt;/code&gt;使用网易的源。我们推荐使用阿里云的源&lt;/p&gt;&lt;/blockquote&gt;

&lt;h3 id=&quot;install&quot;&gt; 5. 离线安装 ZStack &lt;/h3&gt;


&lt;p&gt;针对内网用户,以及访问Internet速度较慢的用户.ZStack 1.1 提供了离线安装方式.
用户若需要离线安装ZStack,需要在目标管理节点和计算节点上安装CentOS 7.2 ZStack社区版.&lt;/p&gt;

&lt;p&gt;然后在下载了第8步中的 zstack-installer 之后,你可以通过下面方式快速完成离线安装：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    bash zstack-installer-1.1.1.bin -o
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;具体的离线安装教程和CentOS 7.2 ZStack社区版请阅读: &lt;a href=&quot;./offline-install-zstack-from-custom-iso.html&quot;&gt;ZStack离线安装教程&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;upgrade&quot;&gt; 6. 升级 &lt;/h3&gt;


&lt;p&gt;一如既往的，我们支持一键无缝升级：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    wget http://download.zstack.org/releases/1.1/1.1.1/zstack-installer-1.1.1.bin -O zstack-installer-1.1.1.bin
    bash zstack-installer-1.1.1.bin -u
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;多节点升级中的zstack.war 可以从如下链接获取: http://download.zstack.org/releases/1.1/1.1.1/zstack.war&lt;/p&gt;
</description>
        <pubDate>Fri, 01 Apr 2016 00:00:00 +0800</pubDate>
        <link>http://zstack.org/cn_blog/v1.1.1.html</link>
        <guid isPermaLink="true">http://zstack.org/cn_blog/v1.1.1.html</guid>
        
        
        <category>cn_blog</category>
        
      </item>
    
      <item>
        <title>ZStack v1.1 release</title>
        <description>&lt;p&gt;Hello everyone, I am Frank Zhang, the architect of ZStack. Today I am happy to
announce that ZStack v1.1 is released.&lt;/p&gt;

&lt;h1&gt;New Features And Enhancements&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#ansible&quot;&gt;Ansible Optimization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#consoleproxy&quot;&gt;Console Proxy APIs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#apitimeout&quot;&gt;API Timeout Management&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#gc&quot;&gt;Garbage Collector&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#image&quot;&gt;15 Tiny Tryout Image&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#vr&quot;&gt;Virtual Router Image Upgrade&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;h1&gt;Installation And Upgrade&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#install&quot;&gt;Installation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#upgrade&quot;&gt;Upgrade&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#upgradevr&quot;&gt;Upgrade Virtual Router Provider To Flat Network Provider&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;h2 id=&quot;ansible&quot;&gt; 1. Ansible Optimization &lt;/h2&gt;


&lt;p&gt;In this version, we create customized deployers for all ZStack agents(i.e. kvmagent, backup storage agent) directly using Ansible SDK, instead of regular Ansible playbook YAML files. As the result, the speed of agent deployment gets significantly improved, because the deployer that is a Python application will try best to avoid unnecessary time-costing steps such as accessing YUM repo; the logging also gets better, each task will post messages to a logging URL before and after execution, and the error message will clearly state the error instead of flooding out all tasks status, which regular Ansible playbook YAML files normally do.&lt;/p&gt;

&lt;h2 id=&quot;consoleproxy&quot;&gt;2. Console Proxy APIs &lt;/h2&gt;


&lt;p&gt;Two new APIs are added for console proxy, &lt;code&gt;ReconnectConsoleProxyAgent&lt;/code&gt; and &lt;code&gt;QueryConsoleProxyAgent&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Users can use &lt;code&gt;ReconnectConsoleProxyAgent&lt;/code&gt; to redeploy console proxy agents:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;        &amp;gt;&amp;gt;&amp;gt;ReconnectConsoleProxyAgent 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;or use &lt;code&gt;QueryConsoleProxyAgent&lt;/code&gt; to query agents&#39; status:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;       &amp;gt;&amp;gt;&amp;gt;QueryConsoleProxyAgent 
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;apitimeout&quot;&gt;3. API Timeout Management&lt;/h2&gt;


&lt;p&gt;As ZStack consists of a lot of microservices which communicate with each other through async-messages, it&#39;s very hard to control API timeout because the API has no idea about internal messages entailed by itself. In this version, we add a central API timeout management framework that can connect an API to all entailed internal messages and HTTP requests, and that can propagate the API&#39;s timeout to the descendants. All APIs have default configurations, users can change a configuration by editing the &lt;code&gt;zstack.properties&lt;/code&gt; file, for example:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    ApiTimeout.org.zstack.header.image.APIAddImageMsg= org.zstack.header.storage.backup.DownloadImageMsg, org.zstack.storage.backup.sftp.SftpBackupStorageCommands$DownloadCmd, org.zstack.storage.ceph.backup.CephBackupStorageBase$DownloadCmd; 6h
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This example changes the timeout of API &lt;code&gt;org.zstack.header.image.APIAddImageMsg&lt;/code&gt; to six hours. However, this way is discouraged. In 1.2 version, we will allow users to configure APIs&#39; timeout through a new API.&lt;/p&gt;

&lt;h2 id=&quot;gc&quot;&gt;4. Garbage Collector&lt;/h2&gt;


&lt;p&gt;In this version, the VM related garbage collectors are enabled. Users can destroy a VM anytime no matter the connection status of the host. For example, you can delete a VM even the network connection to the host where the VM is running is lost. The garbage collector will save user operations which cannot be completed in current situation and re-execute them once the host&#39;s network connection recovers. The garbage collector can be triggered by time-based poll and events, for example, a host reconnect event and host delete event can both trigger a VM deleting garbage collector.&lt;/p&gt;

&lt;h2 id=&quot;image&quot;&gt;5. 15M Tiny Tryout Image&lt;/h2&gt;


&lt;p&gt;A new 15 tiny image is ready for quickly try out creating VMs. The image supports runtime attaching/detaching volumes and networks. The ACPID daemon is also included so you can gracefully shutdown a VM. You can download the image from:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    http://download.zstack.org/templates/zstack-image-1.2.qcow2
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;vr&quot;&gt;6. New Virtual Router Image&lt;/h2&gt;


&lt;p&gt;The virtual router image is upgraded to 1.1 version, you can download it from:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    http://download.zstack.org/templates/zstack-virtualrouter-1.1.0.qcow2
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;&lt;p&gt;NOTE: Users still using the old 0.9 version are not necessary to upgrade. However, we suggest all new users using the new version.&lt;/p&gt;&lt;/blockquote&gt;

&lt;h2 id=&quot;install&quot;&gt;7. Installation&lt;/h2&gt;


&lt;p&gt;You can install the 1.1 release by:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    wget http://download.zstack.org/releases/1.1/1.1.0/0331/zstack-installer-1.1.0-0331.bin -O zstack-installer-1.1.0.bin
    bash zstack-installer-1.1.0.bin
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;upgrade&quot;&gt;8. Upgrade&lt;/h2&gt;


&lt;p&gt;To upgrade your ZStack to 1.1, do:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    wget http://download.zstack.org/releases/1.1/1.1.0/0331/zstack-installer-1.1.0-0331.bin -O zstack-installer-1.1.0.bin
    bash zstack-installer-1.1.0.bin -u
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;upgradevr&quot;&gt;9. Upgrade Virtual Router Provider To Flat Network Provider&lt;/h2&gt;


&lt;p&gt;If you are currently using a flat network with a previous ZStack version, you can upgrade the L3 network using the flat network provider so
you won&#39;t need the virtual router VM anymore. Assume the UUID of your L3 network is 1a82c2691978476fa6cefa36bb9d4bfd, please follow
the below steps:&lt;/p&gt;

&lt;h4&gt;1. Obtain the UUID of the virtual rotuer provider&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;    &amp;gt;&amp;gt;&amp;gt;QueryNetworkServiceL3NetworkRef l3NetworkUuid=1a82c2691978476fa6cefa36bb9d4bfd
    {
        &quot;inventories&quot;: [
            {
                &quot;l3NetworkUuid&quot;: &quot;1a82c2691978476fa6cefa36bb9d4bfd&quot;,
                &quot;networkServiceProviderUuid&quot;: &quot;5d21ea0f39c04d6fb68cfaf5a37db4ad&quot;,
                &quot;networkServiceType&quot;: &quot;DNS&quot;
            },
            {
                &quot;l3NetworkUuid&quot;: &quot;1a82c2691978476fa6cefa36bb9d4bfd&quot;,
                &quot;networkServiceProviderUuid&quot;: &quot;5d21ea0f39c04d6fb68cfaf5a37db4ad&quot;,
                &quot;networkServiceType&quot;: &quot;DHCP&quot;
            }
        ],
        &quot;success&quot;: true
    }
&lt;/code&gt;&lt;/pre&gt;

&lt;h4&gt;2. Detach the virtual router provider from the L3 network&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;        &amp;gt;&amp;gt;&amp;gt;DetachNetworkServiceFromL3Network  l3NetworkUuid=1a82c2691978476fa6cefa36bb9d4bfd networkServices=&#39;{&quot;5d21ea0f39c04d6fb68cfaf5a37db4ad&quot;:[&quot;DHCP&quot;,&quot;DNS&quot;]}&#39;
         {
             &quot;inventory&quot;: {
                 &quot;createDate&quot;: &quot;Jan 30, 2016 3:01:03 PM&quot;,
                 &quot;dns&quot;: [
                     &quot;8.8.8.8&quot;
                 ],
                 &quot;ipRanges&quot;: [
                     {
                         &quot;createDate&quot;: &quot;Jan 30, 2016 3:01:04 PM&quot;,
                         &quot;endIp&quot;: &quot;192.168.201.199&quot;,
                         &quot;gateway&quot;: &quot;192.168.200.1&quot;,
                         &quot;l3NetworkUuid&quot;: &quot;1a82c2691978476fa6cefa36bb9d4bfd&quot;,
                         &quot;lastOpDate&quot;: &quot;Jan 30, 2016 3:01:04 PM&quot;,
                         &quot;name&quot;: &quot;ipr-dk7p&quot;,
                         &quot;netmask&quot;: &quot;255.255.252.0&quot;,
                         &quot;startIp&quot;: &quot;192.168.201.180&quot;,
                         &quot;uuid&quot;: &quot;ec5fd87dd80243fdabeeace847c04427&quot;
                     }
                 ],
                 &quot;l2NetworkUuid&quot;: &quot;9ec8cad681d1424fa7eda2447edae142&quot;,
                 &quot;lastOpDate&quot;: &quot;Jan 30, 2016 3:01:03 PM&quot;,
                 &quot;name&quot;: &quot;l3-etpz&quot;,
                 &quot;networkServices&quot;: [],
                 &quot;state&quot;: &quot;Enabled&quot;,
                 &quot;system&quot;: false,
                 &quot;type&quot;: &quot;L3BasicNetwork&quot;,
                 &quot;uuid&quot;: &quot;1a82c2691978476fa6cefa36bb9d4bfd&quot;,
                 &quot;zoneUuid&quot;: &quot;4a3a78b1b9f049948b79cf9e667f0af2&quot;
             },
             &quot;success&quot;: true
         }
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;&lt;p&gt;the parameter &lt;code&gt;networkServices&lt;/code&gt; is a map where the key is a &lt;code&gt;networkServiceProviderUuid&lt;/code&gt; and the value is a list of &lt;code&gt;networkServiceType&lt;/code&gt;, which you obtain in the step 1&lt;/p&gt;&lt;/blockquote&gt;

&lt;h4&gt;3. Get the flat network provider UUID&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;        &amp;gt;&amp;gt;&amp;gt;QueryNetworkServiceProvider type=Flat
        {
            &quot;inventories&quot;: [
                {
                    &quot;attachedL2NetworkUuids&quot;: [
                        &quot;9ec8cad681d1424fa7eda2447edae142&quot;
                    ],
                    &quot;createDate&quot;: &quot;Jan 30, 2016 11:56:32 AM&quot;,
                    &quot;description&quot;: &quot;Flat Network Service Provider&quot;,
                    &quot;lastOpDate&quot;: &quot;Jan 30, 2016 11:56:32 AM&quot;,
                    &quot;name&quot;: &quot;Flat Network Service Provider&quot;,
                    &quot;networkServiceTypes&quot;: [
                        &quot;DHCP&quot;,
                        &quot;Userdata&quot;
                    ],
                    &quot;type&quot;: &quot;Flat&quot;,
                    &quot;uuid&quot;: &quot;17864f985e584a9ba4cd81de215212ce&quot;
                }
            ],
            &quot;success&quot;: true
        }
&lt;/code&gt;&lt;/pre&gt;

&lt;h4&gt;4. Get L2 UUID for the L3 network&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;        &amp;gt;&amp;gt;&amp;gt;QueryL3Network fields=l2NetworkUuid, uuid=1a82c2691978476fa6cefa36bb9d4bfd
        {
            &quot;inventories&quot;: [
                {
                    &quot;l2NetworkUuid&quot;: &quot;9ec8cad681d1424fa7eda2447edae142&quot;
                }
            ],
            &quot;success&quot;: true
        }
&lt;/code&gt;&lt;/pre&gt;

&lt;h4&gt;5. Attach the flat network provider to the L2 network&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;       &amp;gt;&amp;gt;&amp;gt;AttachNetworkServiceProviderToL2Network l2NetworkUuid=9ec8cad681d1424fa7eda2447edae142 networkServiceProviderUuid=17864f985e584a9ba4cd81de215212ce
       {
           &quot;inventory&quot;: {
               &quot;attachedL2NetworkUuids&quot;: [
                   &quot;9ec8cad681d1424fa7eda2447edae142&quot;
               ],
               &quot;createDate&quot;: &quot;Jan 30, 2016 11:56:32 AM&quot;,
               &quot;description&quot;: &quot;Flat Network Service Provider&quot;,
               &quot;lastOpDate&quot;: &quot;Jan 30, 2016 11:56:32 AM&quot;,
               &quot;name&quot;: &quot;Flat Network Service Provider&quot;,
               &quot;networkServiceTypes&quot;: [
                   &quot;DHCP&quot;,
                   &quot;Userdata&quot;
               ],
               &quot;type&quot;: &quot;Flat&quot;,
               &quot;uuid&quot;: &quot;17864f985e584a9ba4cd81de215212ce&quot;
           },
           &quot;success&quot;: true
       }
&lt;/code&gt;&lt;/pre&gt;

&lt;h4&gt;6. Attach the flat network provider to the L3 network&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;     &amp;gt;&amp;gt;&amp;gt;AttachNetworkServiceToL3Network l3NetworkUuid=1a82c2691978476fa6cefa36bb9d4bfd networkServices=&#39;{&quot;17864f985e584a9ba4cd81de215212ce&quot;:[&quot;DHCP&quot;,&quot;Userdata&quot;]}&#39;
      {
          &quot;inventory&quot;: {
              &quot;createDate&quot;: &quot;Jan 30, 2016 3:01:03 PM&quot;,
              &quot;dns&quot;: [
                  &quot;8.8.8.8&quot;
              ],
              &quot;ipRanges&quot;: [
                  {
                      &quot;createDate&quot;: &quot;Jan 30, 2016 3:01:04 PM&quot;,
                      &quot;endIp&quot;: &quot;192.168.201.199&quot;,
                      &quot;gateway&quot;: &quot;192.168.200.1&quot;,
                      &quot;l3NetworkUuid&quot;: &quot;1a82c2691978476fa6cefa36bb9d4bfd&quot;,
                      &quot;lastOpDate&quot;: &quot;Jan 30, 2016 3:01:04 PM&quot;,
                      &quot;name&quot;: &quot;ipr-dk7p&quot;,
                      &quot;netmask&quot;: &quot;255.255.252.0&quot;,
                      &quot;startIp&quot;: &quot;192.168.201.180&quot;,
                      &quot;uuid&quot;: &quot;ec5fd87dd80243fdabeeace847c04427&quot;
                  }
              ],
              &quot;l2NetworkUuid&quot;: &quot;9ec8cad681d1424fa7eda2447edae142&quot;,
              &quot;lastOpDate&quot;: &quot;Jan 30, 2016 3:01:03 PM&quot;,
              &quot;name&quot;: &quot;l3-etpz&quot;,
              &quot;networkServices&quot;: [
                  {
                      &quot;l3NetworkUuid&quot;: &quot;1a82c2691978476fa6cefa36bb9d4bfd&quot;,
                      &quot;networkServiceProviderUuid&quot;: &quot;17864f985e584a9ba4cd81de215212ce&quot;,
                      &quot;networkServiceType&quot;: &quot;DHCP&quot;
                  },
                  {
                      &quot;l3NetworkUuid&quot;: &quot;1a82c2691978476fa6cefa36bb9d4bfd&quot;,
                      &quot;networkServiceProviderUuid&quot;: &quot;17864f985e584a9ba4cd81de215212ce&quot;,
                      &quot;networkServiceType&quot;: &quot;Userdata&quot;
                  }
              ],
              &quot;state&quot;: &quot;Enabled&quot;,
              &quot;system&quot;: false,
              &quot;type&quot;: &quot;L3BasicNetwork&quot;,
              &quot;uuid&quot;: &quot;1a82c2691978476fa6cefa36bb9d4bfd&quot;,
              &quot;zoneUuid&quot;: &quot;4a3a78b1b9f049948b79cf9e667f0af2&quot;
          },
          &quot;success&quot;: true
      }
&lt;/code&gt;&lt;/pre&gt;

&lt;h4&gt;7. Delete the virtual router VM&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;        &amp;gt;&amp;gt;QueryVirtualRouterVm
         {
             &quot;inventories&quot;: [
                 {
                     &quot;allVolumes&quot;: [
                         {
                             &quot;createDate&quot;: &quot;Jan 30, 2016 3:06:50 PM&quot;,
                             &quot;description&quot;: &quot;Root volume for VM[uuid:c5a966cb87d644649952daf683f89e26]&quot;,
                             &quot;deviceId&quot;: 0,
                             &quot;format&quot;: &quot;qcow2&quot;,
                             &quot;installPath&quot;: &quot;/zstack_ps/rootVolumes/acct-36c27e8ff05c4780bf6d2fa65700f22e/vol-8eeaa9cb4c1045a2825f8815fed69d72/8eeaa9cb4c1045a2825f8815fed69d72.qcow2&quot;,
                             &quot;lastOpDate&quot;: &quot;Jan 30, 2016 3:06:59 PM&quot;,
                             &quot;name&quot;: &quot;ROOT-for-virtualRouter.l3.1a82c2691978476fa6cefa36bb9d4bfd&quot;,
                             &quot;primaryStorageUuid&quot;: &quot;4bff4e2d266f480ead596752d14ff3b5&quot;,
                             &quot;rootImageUuid&quot;: &quot;7bed05aa8ace4e5e8d6c55b284b66fb5&quot;,
                             &quot;size&quot;: 467206656,
                             &quot;state&quot;: &quot;Enabled&quot;,
                             &quot;status&quot;: &quot;Ready&quot;,
                             &quot;type&quot;: &quot;Root&quot;,
                             &quot;uuid&quot;: &quot;8eeaa9cb4c1045a2825f8815fed69d72&quot;,
                             &quot;vmInstanceUuid&quot;: &quot;c5a966cb87d644649952daf683f89e26&quot;
                         }
                     ],
                     &quot;allocatorStrategy&quot;: &quot;LeastVmPreferredHostAllocatorStrategy&quot;,
                     &quot;applianceVmType&quot;: &quot;VirtualRouter&quot;,
                     &quot;clusterUuid&quot;: &quot;10409d3e33b249c19746022930a541c7&quot;,
                     &quot;cpuNum&quot;: 1,
                     &quot;cpuSpeed&quot;: 2,
                     &quot;createDate&quot;: &quot;Jan 30, 2016 3:06:50 PM&quot;,
                     &quot;defaultRouteL3NetworkUuid&quot;: &quot;1a82c2691978476fa6cefa36bb9d4bfd&quot;,
                     &quot;hostUuid&quot;: &quot;415fa093b34e4a3d873368104b127115&quot;,
                     &quot;hypervisorType&quot;: &quot;KVM&quot;,
                     &quot;imageUuid&quot;: &quot;7bed05aa8ace4e5e8d6c55b284b66fb5&quot;,
                     &quot;instanceOfferingUuid&quot;: &quot;9cec7bd6324445a184351ffb7d32f970&quot;,
                     &quot;lastHostUuid&quot;: &quot;415fa093b34e4a3d873368104b127115&quot;,
                     &quot;lastOpDate&quot;: &quot;Jan 30, 2016 3:07:20 PM&quot;,
                     &quot;managementNetworkUuid&quot;: &quot;1a82c2691978476fa6cefa36bb9d4bfd&quot;,
                     &quot;memorySize&quot;: 536870912,
                     &quot;name&quot;: &quot;virtualRouter.l3.1a82c2691978476fa6cefa36bb9d4bfd&quot;,
                     &quot;platform&quot;: &quot;Linux&quot;,
                     &quot;publicNetworkUuid&quot;: &quot;1a82c2691978476fa6cefa36bb9d4bfd&quot;,
                     &quot;rootVolumeUuid&quot;: &quot;8eeaa9cb4c1045a2825f8815fed69d72&quot;,
                     &quot;state&quot;: &quot;Running&quot;,
                     &quot;status&quot;: &quot;Connected&quot;,
                     &quot;type&quot;: &quot;ApplianceVm&quot;,
                     &quot;uuid&quot;: &quot;c5a966cb87d644649952daf683f89e26&quot;,
                     &quot;vmNics&quot;: [
                         {
                             &quot;createDate&quot;: &quot;Jan 30, 2016 3:06:50 PM&quot;,
                             &quot;deviceId&quot;: 0,
                             &quot;gateway&quot;: &quot;192.168.200.1&quot;,
                             &quot;ip&quot;: &quot;192.168.201.195&quot;,
                             &quot;l3NetworkUuid&quot;: &quot;1a82c2691978476fa6cefa36bb9d4bfd&quot;,
                             &quot;lastOpDate&quot;: &quot;Jan 30, 2016 3:06:50 PM&quot;,
                             &quot;mac&quot;: &quot;fa:4c:01:68:77:00&quot;,
                             &quot;metaData&quot;: &quot;7&quot;,
                             &quot;netmask&quot;: &quot;255.255.252.0&quot;,
                             &quot;uuid&quot;: &quot;c44e856aa88a42bc85ec30ce8c334c6c&quot;,
                             &quot;vmInstanceUuid&quot;: &quot;c5a966cb87d644649952daf683f89e26&quot;
                         }
                     ],
                     &quot;zoneUuid&quot;: &quot;4a3a78b1b9f049948b79cf9e667f0af2&quot;
                 }
             ],
             &quot;success&quot;: true
         }

         &amp;gt;&amp;gt;&amp;gt;DestroyVmInstance uuid=c5a966cb87d644649952daf683f89e26
         {
             &quot;success&quot;: true
         }
&lt;/code&gt;&lt;/pre&gt;

&lt;h4&gt;8. Reconnect all hosts&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;         &amp;gt;&amp;gt;&amp;gt;QueryHost
         {
             &quot;inventories&quot;: [
                 {
                     &quot;availableCpuCapacity&quot;: 7180,
                     &quot;availableMemoryCapacity&quot;: 1997570048,
                     &quot;clusterUuid&quot;: &quot;4282fb61aa55458ea160de138e130298&quot;,
                     &quot;createDate&quot;: &quot;Jan 30, 2016 2:51:13 PM&quot;,
                     &quot;hypervisorType&quot;: &quot;KVM&quot;,
                     &quot;lastOpDate&quot;: &quot;Jan 30, 2016 3:03:20 PM&quot;,
                     &quot;managementIp&quot;: &quot;192.168.200.187&quot;,
                     &quot;name&quot;: &quot;host1&quot;,
                     &quot;state&quot;: &quot;Enabled&quot;,
                     &quot;status&quot;: &quot;Connected&quot;,
                     &quot;totalCpuCapacity&quot;: 7182,
                     &quot;totalMemoryCapacity&quot;: 2098233344,
                     &quot;username&quot;: &quot;root&quot;,
                     &quot;uuid&quot;: &quot;402f8304a50c410486e023512492316b&quot;,
                     &quot;zoneUuid&quot;: &quot;4a3a78b1b9f049948b79cf9e667f0af2&quot;
                 },
                 {
                     &quot;availableCpuCapacity&quot;: 14363,
                     &quot;availableMemoryCapacity&quot;: 8321593344,
                     &quot;clusterUuid&quot;: &quot;10409d3e33b249c19746022930a541c7&quot;,
                     &quot;createDate&quot;: &quot;Jan 30, 2016 3:03:14 PM&quot;,
                     &quot;hypervisorType&quot;: &quot;KVM&quot;,
                     &quot;lastOpDate&quot;: &quot;Jan 30, 2016 3:03:52 PM&quot;,
                     &quot;managementIp&quot;: &quot;192.168.200.150&quot;,
                     &quot;name&quot;: &quot;host2&quot;,
                     &quot;state&quot;: &quot;Enabled&quot;,
                     &quot;status&quot;: &quot;Connected&quot;,
                     &quot;totalCpuCapacity&quot;: 14364,
                     &quot;totalMemoryCapacity&quot;: 8371924992,
                     &quot;username&quot;: &quot;root&quot;,
                     &quot;uuid&quot;: &quot;415fa093b34e4a3d873368104b127115&quot;,
                     &quot;zoneUuid&quot;: &quot;4a3a78b1b9f049948b79cf9e667f0af2&quot;
                 }
             ],
             &quot;success&quot;: true
         }

         &amp;gt;&amp;gt;&amp;gt;ReconnectHost uuid=402f8304a50c410486e023512492316b
         {
             &quot;success&quot;: true
         }

         &amp;gt;&amp;gt;&amp;gt;ReconnectHost uuid=415fa093b34e4a3d873368104b127115
         {
             &quot;success&quot;: true
         }
&lt;/code&gt;&lt;/pre&gt;
</description>
        <pubDate>Wed, 30 Mar 2016 00:00:00 +0800</pubDate>
        <link>http://zstack.org/blog/v1.1.html</link>
        <guid isPermaLink="true">http://zstack.org/blog/v1.1.html</guid>
        
        
        <category>blog</category>
        
      </item>
    
      <item>
        <title>ZStack v1.1 release</title>
        <description>&lt;p&gt;Hello everyone, I am Frank Zhang, the architect of ZStack. Today I am happy to
announce that ZStack v1.1 is released.&lt;/p&gt;

&lt;h1&gt;New Features And Enhancements&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#ansible&quot;&gt;Ansible Optimization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#consoleproxy&quot;&gt;Console Proxy APIs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#apitimeout&quot;&gt;API Timeout Management&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#gc&quot;&gt;Garbage Collector&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#image&quot;&gt;15 Tiny Tryout Image&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#vr&quot;&gt;Virtual Router Image Upgrade&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;h1&gt;Installation And Upgrade&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#install&quot;&gt;Installation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#upgrade&quot;&gt;Upgrade&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#upgradevr&quot;&gt;Upgrade Virtual Router Provider To Flat Network Provider&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;h2 id=&quot;ansible&quot;&gt; 1. Ansible Optimization &lt;/h2&gt;


&lt;p&gt;In this version, we create customized deployers for all ZStack agents(i.e. kvmagent, backup storage agent) directly using Ansible SDK, instead of regular Ansible playbook YAML files. As the result, the speed of agent deployment gets significantly improved, because the deployer that is a Python application will try best to avoid unnecessary time-costing steps such as accessing YUM repo; the logging also gets better, each task will post messages to a logging URL before and after execution, and the error message will clearly state the error instead of flooding out all tasks status, which regular Ansible playbook YAML files normally do.&lt;/p&gt;

&lt;h2 id=&quot;consoleproxy&quot;&gt;2. Console Proxy APIs &lt;/h2&gt;


&lt;p&gt;Two new APIs are added for console proxy, &lt;code&gt;ReconnectConsoleProxyAgent&lt;/code&gt; and &lt;code&gt;QueryConsoleProxyAgent&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Users can use &lt;code&gt;ReconnectConsoleProxyAgent&lt;/code&gt; to redeploy console proxy agents:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;        &amp;gt;&amp;gt;&amp;gt;ReconnectConsoleProxyAgent 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;or use &lt;code&gt;QueryConsoleProxyAgent&lt;/code&gt; to query agents&#39; status:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;       &amp;gt;&amp;gt;&amp;gt;QueryConsoleProxyAgent 
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;apitimeout&quot;&gt;3. API Timeout Management&lt;/h2&gt;


&lt;p&gt;As ZStack consists of a lot of microservices which communicate with each other through async-messages, it&#39;s very hard to control API timeout because the API has no idea about internal messages entailed by itself. In this version, we add a central API timeout management framework that can connect an API to all entailed internal messages and HTTP requests, and that can propagate the API&#39;s timeout to the descendants. All APIs have default configurations, users can change a configuration by editing the &lt;code&gt;zstack.properties&lt;/code&gt; file, for example:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    ApiTimeout.org.zstack.header.image.APIAddImageMsg= org.zstack.header.storage.backup.DownloadImageMsg, org.zstack.storage.backup.sftp.SftpBackupStorageCommands$DownloadCmd, org.zstack.storage.ceph.backup.CephBackupStorageBase$DownloadCmd; 6h
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This example changes the timeout of API &lt;code&gt;org.zstack.header.image.APIAddImageMsg&lt;/code&gt; to six hours. However, this way is discouraged. In 1.2 version, we will allow users to configure APIs&#39; timeout through a new API.&lt;/p&gt;

&lt;h2 id=&quot;gc&quot;&gt;4. Garbage Collector&lt;/h2&gt;


&lt;p&gt;In this version, the VM related garbage collectors are enabled. Users can destroy a VM anytime no matter the connection status of the host. For example, you can delete a VM even the network connection to the host where the VM is running is lost. The garbage collector will save user operations which cannot be completed in current situation and re-execute them once the host&#39;s network connection recovers. The garbage collector can be triggered by time-based poll and events, for example, a host reconnect event and host delete event can both trigger a VM deleting garbage collector.&lt;/p&gt;

&lt;h2 id=&quot;image&quot;&gt;5. 15M Tiny Tryout Image&lt;/h2&gt;


&lt;p&gt;A new 15 tiny image is ready for quickly try out creating VMs. The image supports runtime attaching/detaching volumes and networks. The ACPID daemon is also included so you can gracefully shutdown a VM. You can download the image from:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    http://download.zstack.org/templates/zstack-image-1.2.qcow2
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;vr&quot;&gt;6. New Virtual Router Image&lt;/h2&gt;


&lt;p&gt;The virtual router image is upgraded to 1.1 version, you can download it from:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    http://download.zstack.org/templates/zstack-virtualrouter-1.1.0.qcow2
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;&lt;p&gt;NOTE: Users still using the old 0.9 version are not necessary to upgrade. However, we suggest all new users using the new version.&lt;/p&gt;&lt;/blockquote&gt;

&lt;h2 id=&quot;install&quot;&gt;7. Installation&lt;/h2&gt;


&lt;p&gt;You can install the 1.1 release by:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    wget http://download.zstack.org/releases/1.1/1.1.0/0331/zstack-installer-1.1.0-0331.bin -O zstack-installer-1.1.0.bin
    bash zstack-installer-1.1.0.bin
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;upgrade&quot;&gt;8. Upgrade&lt;/h2&gt;


&lt;p&gt;To upgrade your ZStack to 1.1, do:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    wget http://download.zstack.org/releases/1.1/1.1.0/0331/zstack-installer-1.1.0-0331.bin -O zstack-installer-1.1.0.bin
    bash zstack-installer-1.1.0.bin -u
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;upgradevr&quot;&gt;9. Upgrade Virtual Router Provider To Flat Network Provider&lt;/h2&gt;


&lt;p&gt;If you are currently using a flat network with a previous ZStack version, you can upgrade the L3 network using the flat network provider so
you won&#39;t need the virtual router VM anymore. Assume the UUID of your L3 network is 1a82c2691978476fa6cefa36bb9d4bfd, please follow
the below steps:&lt;/p&gt;

&lt;h4&gt;1. Obtain the UUID of the virtual rotuer provider&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;    &amp;gt;&amp;gt;&amp;gt;QueryNetworkServiceL3NetworkRef l3NetworkUuid=1a82c2691978476fa6cefa36bb9d4bfd
    {
        &quot;inventories&quot;: [
            {
                &quot;l3NetworkUuid&quot;: &quot;1a82c2691978476fa6cefa36bb9d4bfd&quot;,
                &quot;networkServiceProviderUuid&quot;: &quot;5d21ea0f39c04d6fb68cfaf5a37db4ad&quot;,
                &quot;networkServiceType&quot;: &quot;DNS&quot;
            },
            {
                &quot;l3NetworkUuid&quot;: &quot;1a82c2691978476fa6cefa36bb9d4bfd&quot;,
                &quot;networkServiceProviderUuid&quot;: &quot;5d21ea0f39c04d6fb68cfaf5a37db4ad&quot;,
                &quot;networkServiceType&quot;: &quot;DHCP&quot;
            }
        ],
        &quot;success&quot;: true
    }
&lt;/code&gt;&lt;/pre&gt;

&lt;h4&gt;2. Detach the virtual router provider from the L3 network&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;        &amp;gt;&amp;gt;&amp;gt;DetachNetworkServiceFromL3Network  l3NetworkUuid=1a82c2691978476fa6cefa36bb9d4bfd networkServices=&#39;{&quot;5d21ea0f39c04d6fb68cfaf5a37db4ad&quot;:[&quot;DHCP&quot;,&quot;DNS&quot;]}&#39;
         {
             &quot;inventory&quot;: {
                 &quot;createDate&quot;: &quot;Jan 30, 2016 3:01:03 PM&quot;,
                 &quot;dns&quot;: [
                     &quot;8.8.8.8&quot;
                 ],
                 &quot;ipRanges&quot;: [
                     {
                         &quot;createDate&quot;: &quot;Jan 30, 2016 3:01:04 PM&quot;,
                         &quot;endIp&quot;: &quot;192.168.201.199&quot;,
                         &quot;gateway&quot;: &quot;192.168.200.1&quot;,
                         &quot;l3NetworkUuid&quot;: &quot;1a82c2691978476fa6cefa36bb9d4bfd&quot;,
                         &quot;lastOpDate&quot;: &quot;Jan 30, 2016 3:01:04 PM&quot;,
                         &quot;name&quot;: &quot;ipr-dk7p&quot;,
                         &quot;netmask&quot;: &quot;255.255.252.0&quot;,
                         &quot;startIp&quot;: &quot;192.168.201.180&quot;,
                         &quot;uuid&quot;: &quot;ec5fd87dd80243fdabeeace847c04427&quot;
                     }
                 ],
                 &quot;l2NetworkUuid&quot;: &quot;9ec8cad681d1424fa7eda2447edae142&quot;,
                 &quot;lastOpDate&quot;: &quot;Jan 30, 2016 3:01:03 PM&quot;,
                 &quot;name&quot;: &quot;l3-etpz&quot;,
                 &quot;networkServices&quot;: [],
                 &quot;state&quot;: &quot;Enabled&quot;,
                 &quot;system&quot;: false,
                 &quot;type&quot;: &quot;L3BasicNetwork&quot;,
                 &quot;uuid&quot;: &quot;1a82c2691978476fa6cefa36bb9d4bfd&quot;,
                 &quot;zoneUuid&quot;: &quot;4a3a78b1b9f049948b79cf9e667f0af2&quot;
             },
             &quot;success&quot;: true
         }
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;&lt;p&gt;the parameter &lt;code&gt;networkServices&lt;/code&gt; is a map where the key is a &lt;code&gt;networkServiceProviderUuid&lt;/code&gt; and the value is a list of &lt;code&gt;networkServiceType&lt;/code&gt;, which you obtain in the step 1&lt;/p&gt;&lt;/blockquote&gt;

&lt;h4&gt;3. Get the flat network provider UUID&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;        &amp;gt;&amp;gt;&amp;gt;QueryNetworkServiceProvider type=Flat
        {
            &quot;inventories&quot;: [
                {
                    &quot;attachedL2NetworkUuids&quot;: [
                        &quot;9ec8cad681d1424fa7eda2447edae142&quot;
                    ],
                    &quot;createDate&quot;: &quot;Jan 30, 2016 11:56:32 AM&quot;,
                    &quot;description&quot;: &quot;Flat Network Service Provider&quot;,
                    &quot;lastOpDate&quot;: &quot;Jan 30, 2016 11:56:32 AM&quot;,
                    &quot;name&quot;: &quot;Flat Network Service Provider&quot;,
                    &quot;networkServiceTypes&quot;: [
                        &quot;DHCP&quot;,
                        &quot;Userdata&quot;
                    ],
                    &quot;type&quot;: &quot;Flat&quot;,
                    &quot;uuid&quot;: &quot;17864f985e584a9ba4cd81de215212ce&quot;
                }
            ],
            &quot;success&quot;: true
        }
&lt;/code&gt;&lt;/pre&gt;

&lt;h4&gt;4. Get L2 UUID for the L3 network&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;        &amp;gt;&amp;gt;&amp;gt;QueryL3Network fields=l2NetworkUuid, uuid=1a82c2691978476fa6cefa36bb9d4bfd
        {
            &quot;inventories&quot;: [
                {
                    &quot;l2NetworkUuid&quot;: &quot;9ec8cad681d1424fa7eda2447edae142&quot;
                }
            ],
            &quot;success&quot;: true
        }
&lt;/code&gt;&lt;/pre&gt;

&lt;h4&gt;5. Attach the flat network provider to the L2 network&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;       &amp;gt;&amp;gt;&amp;gt;AttachNetworkServiceProviderToL2Network l2NetworkUuid=9ec8cad681d1424fa7eda2447edae142 networkServiceProviderUuid=17864f985e584a9ba4cd81de215212ce
       {
           &quot;inventory&quot;: {
               &quot;attachedL2NetworkUuids&quot;: [
                   &quot;9ec8cad681d1424fa7eda2447edae142&quot;
               ],
               &quot;createDate&quot;: &quot;Jan 30, 2016 11:56:32 AM&quot;,
               &quot;description&quot;: &quot;Flat Network Service Provider&quot;,
               &quot;lastOpDate&quot;: &quot;Jan 30, 2016 11:56:32 AM&quot;,
               &quot;name&quot;: &quot;Flat Network Service Provider&quot;,
               &quot;networkServiceTypes&quot;: [
                   &quot;DHCP&quot;,
                   &quot;Userdata&quot;
               ],
               &quot;type&quot;: &quot;Flat&quot;,
               &quot;uuid&quot;: &quot;17864f985e584a9ba4cd81de215212ce&quot;
           },
           &quot;success&quot;: true
       }
&lt;/code&gt;&lt;/pre&gt;

&lt;h4&gt;6. Attach the flat network provider to the L3 network&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;     &amp;gt;&amp;gt;&amp;gt;AttachNetworkServiceToL3Network l3NetworkUuid=1a82c2691978476fa6cefa36bb9d4bfd networkServices=&#39;{&quot;17864f985e584a9ba4cd81de215212ce&quot;:[&quot;DHCP&quot;,&quot;Userdata&quot;]}&#39;
      {
          &quot;inventory&quot;: {
              &quot;createDate&quot;: &quot;Jan 30, 2016 3:01:03 PM&quot;,
              &quot;dns&quot;: [
                  &quot;8.8.8.8&quot;
              ],
              &quot;ipRanges&quot;: [
                  {
                      &quot;createDate&quot;: &quot;Jan 30, 2016 3:01:04 PM&quot;,
                      &quot;endIp&quot;: &quot;192.168.201.199&quot;,
                      &quot;gateway&quot;: &quot;192.168.200.1&quot;,
                      &quot;l3NetworkUuid&quot;: &quot;1a82c2691978476fa6cefa36bb9d4bfd&quot;,
                      &quot;lastOpDate&quot;: &quot;Jan 30, 2016 3:01:04 PM&quot;,
                      &quot;name&quot;: &quot;ipr-dk7p&quot;,
                      &quot;netmask&quot;: &quot;255.255.252.0&quot;,
                      &quot;startIp&quot;: &quot;192.168.201.180&quot;,
                      &quot;uuid&quot;: &quot;ec5fd87dd80243fdabeeace847c04427&quot;
                  }
              ],
              &quot;l2NetworkUuid&quot;: &quot;9ec8cad681d1424fa7eda2447edae142&quot;,
              &quot;lastOpDate&quot;: &quot;Jan 30, 2016 3:01:03 PM&quot;,
              &quot;name&quot;: &quot;l3-etpz&quot;,
              &quot;networkServices&quot;: [
                  {
                      &quot;l3NetworkUuid&quot;: &quot;1a82c2691978476fa6cefa36bb9d4bfd&quot;,
                      &quot;networkServiceProviderUuid&quot;: &quot;17864f985e584a9ba4cd81de215212ce&quot;,
                      &quot;networkServiceType&quot;: &quot;DHCP&quot;
                  },
                  {
                      &quot;l3NetworkUuid&quot;: &quot;1a82c2691978476fa6cefa36bb9d4bfd&quot;,
                      &quot;networkServiceProviderUuid&quot;: &quot;17864f985e584a9ba4cd81de215212ce&quot;,
                      &quot;networkServiceType&quot;: &quot;Userdata&quot;
                  }
              ],
              &quot;state&quot;: &quot;Enabled&quot;,
              &quot;system&quot;: false,
              &quot;type&quot;: &quot;L3BasicNetwork&quot;,
              &quot;uuid&quot;: &quot;1a82c2691978476fa6cefa36bb9d4bfd&quot;,
              &quot;zoneUuid&quot;: &quot;4a3a78b1b9f049948b79cf9e667f0af2&quot;
          },
          &quot;success&quot;: true
      }
&lt;/code&gt;&lt;/pre&gt;

&lt;h4&gt;7. Delete the virtual router VM&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;        &amp;gt;&amp;gt;QueryVirtualRouterVm
         {
             &quot;inventories&quot;: [
                 {
                     &quot;allVolumes&quot;: [
                         {
                             &quot;createDate&quot;: &quot;Jan 30, 2016 3:06:50 PM&quot;,
                             &quot;description&quot;: &quot;Root volume for VM[uuid:c5a966cb87d644649952daf683f89e26]&quot;,
                             &quot;deviceId&quot;: 0,
                             &quot;format&quot;: &quot;qcow2&quot;,
                             &quot;installPath&quot;: &quot;/zstack_ps/rootVolumes/acct-36c27e8ff05c4780bf6d2fa65700f22e/vol-8eeaa9cb4c1045a2825f8815fed69d72/8eeaa9cb4c1045a2825f8815fed69d72.qcow2&quot;,
                             &quot;lastOpDate&quot;: &quot;Jan 30, 2016 3:06:59 PM&quot;,
                             &quot;name&quot;: &quot;ROOT-for-virtualRouter.l3.1a82c2691978476fa6cefa36bb9d4bfd&quot;,
                             &quot;primaryStorageUuid&quot;: &quot;4bff4e2d266f480ead596752d14ff3b5&quot;,
                             &quot;rootImageUuid&quot;: &quot;7bed05aa8ace4e5e8d6c55b284b66fb5&quot;,
                             &quot;size&quot;: 467206656,
                             &quot;state&quot;: &quot;Enabled&quot;,
                             &quot;status&quot;: &quot;Ready&quot;,
                             &quot;type&quot;: &quot;Root&quot;,
                             &quot;uuid&quot;: &quot;8eeaa9cb4c1045a2825f8815fed69d72&quot;,
                             &quot;vmInstanceUuid&quot;: &quot;c5a966cb87d644649952daf683f89e26&quot;
                         }
                     ],
                     &quot;allocatorStrategy&quot;: &quot;LeastVmPreferredHostAllocatorStrategy&quot;,
                     &quot;applianceVmType&quot;: &quot;VirtualRouter&quot;,
                     &quot;clusterUuid&quot;: &quot;10409d3e33b249c19746022930a541c7&quot;,
                     &quot;cpuNum&quot;: 1,
                     &quot;cpuSpeed&quot;: 2,
                     &quot;createDate&quot;: &quot;Jan 30, 2016 3:06:50 PM&quot;,
                     &quot;defaultRouteL3NetworkUuid&quot;: &quot;1a82c2691978476fa6cefa36bb9d4bfd&quot;,
                     &quot;hostUuid&quot;: &quot;415fa093b34e4a3d873368104b127115&quot;,
                     &quot;hypervisorType&quot;: &quot;KVM&quot;,
                     &quot;imageUuid&quot;: &quot;7bed05aa8ace4e5e8d6c55b284b66fb5&quot;,
                     &quot;instanceOfferingUuid&quot;: &quot;9cec7bd6324445a184351ffb7d32f970&quot;,
                     &quot;lastHostUuid&quot;: &quot;415fa093b34e4a3d873368104b127115&quot;,
                     &quot;lastOpDate&quot;: &quot;Jan 30, 2016 3:07:20 PM&quot;,
                     &quot;managementNetworkUuid&quot;: &quot;1a82c2691978476fa6cefa36bb9d4bfd&quot;,
                     &quot;memorySize&quot;: 536870912,
                     &quot;name&quot;: &quot;virtualRouter.l3.1a82c2691978476fa6cefa36bb9d4bfd&quot;,
                     &quot;platform&quot;: &quot;Linux&quot;,
                     &quot;publicNetworkUuid&quot;: &quot;1a82c2691978476fa6cefa36bb9d4bfd&quot;,
                     &quot;rootVolumeUuid&quot;: &quot;8eeaa9cb4c1045a2825f8815fed69d72&quot;,
                     &quot;state&quot;: &quot;Running&quot;,
                     &quot;status&quot;: &quot;Connected&quot;,
                     &quot;type&quot;: &quot;ApplianceVm&quot;,
                     &quot;uuid&quot;: &quot;c5a966cb87d644649952daf683f89e26&quot;,
                     &quot;vmNics&quot;: [
                         {
                             &quot;createDate&quot;: &quot;Jan 30, 2016 3:06:50 PM&quot;,
                             &quot;deviceId&quot;: 0,
                             &quot;gateway&quot;: &quot;192.168.200.1&quot;,
                             &quot;ip&quot;: &quot;192.168.201.195&quot;,
                             &quot;l3NetworkUuid&quot;: &quot;1a82c2691978476fa6cefa36bb9d4bfd&quot;,
                             &quot;lastOpDate&quot;: &quot;Jan 30, 2016 3:06:50 PM&quot;,
                             &quot;mac&quot;: &quot;fa:4c:01:68:77:00&quot;,
                             &quot;metaData&quot;: &quot;7&quot;,
                             &quot;netmask&quot;: &quot;255.255.252.0&quot;,
                             &quot;uuid&quot;: &quot;c44e856aa88a42bc85ec30ce8c334c6c&quot;,
                             &quot;vmInstanceUuid&quot;: &quot;c5a966cb87d644649952daf683f89e26&quot;
                         }
                     ],
                     &quot;zoneUuid&quot;: &quot;4a3a78b1b9f049948b79cf9e667f0af2&quot;
                 }
             ],
             &quot;success&quot;: true
         }

         &amp;gt;&amp;gt;&amp;gt;DestroyVmInstance uuid=c5a966cb87d644649952daf683f89e26
         {
             &quot;success&quot;: true
         }
&lt;/code&gt;&lt;/pre&gt;

&lt;h4&gt;8. Reconnect all hosts&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;         &amp;gt;&amp;gt;&amp;gt;QueryHost
         {
             &quot;inventories&quot;: [
                 {
                     &quot;availableCpuCapacity&quot;: 7180,
                     &quot;availableMemoryCapacity&quot;: 1997570048,
                     &quot;clusterUuid&quot;: &quot;4282fb61aa55458ea160de138e130298&quot;,
                     &quot;createDate&quot;: &quot;Jan 30, 2016 2:51:13 PM&quot;,
                     &quot;hypervisorType&quot;: &quot;KVM&quot;,
                     &quot;lastOpDate&quot;: &quot;Jan 30, 2016 3:03:20 PM&quot;,
                     &quot;managementIp&quot;: &quot;192.168.200.187&quot;,
                     &quot;name&quot;: &quot;host1&quot;,
                     &quot;state&quot;: &quot;Enabled&quot;,
                     &quot;status&quot;: &quot;Connected&quot;,
                     &quot;totalCpuCapacity&quot;: 7182,
                     &quot;totalMemoryCapacity&quot;: 2098233344,
                     &quot;username&quot;: &quot;root&quot;,
                     &quot;uuid&quot;: &quot;402f8304a50c410486e023512492316b&quot;,
                     &quot;zoneUuid&quot;: &quot;4a3a78b1b9f049948b79cf9e667f0af2&quot;
                 },
                 {
                     &quot;availableCpuCapacity&quot;: 14363,
                     &quot;availableMemoryCapacity&quot;: 8321593344,
                     &quot;clusterUuid&quot;: &quot;10409d3e33b249c19746022930a541c7&quot;,
                     &quot;createDate&quot;: &quot;Jan 30, 2016 3:03:14 PM&quot;,
                     &quot;hypervisorType&quot;: &quot;KVM&quot;,
                     &quot;lastOpDate&quot;: &quot;Jan 30, 2016 3:03:52 PM&quot;,
                     &quot;managementIp&quot;: &quot;192.168.200.150&quot;,
                     &quot;name&quot;: &quot;host2&quot;,
                     &quot;state&quot;: &quot;Enabled&quot;,
                     &quot;status&quot;: &quot;Connected&quot;,
                     &quot;totalCpuCapacity&quot;: 14364,
                     &quot;totalMemoryCapacity&quot;: 8371924992,
                     &quot;username&quot;: &quot;root&quot;,
                     &quot;uuid&quot;: &quot;415fa093b34e4a3d873368104b127115&quot;,
                     &quot;zoneUuid&quot;: &quot;4a3a78b1b9f049948b79cf9e667f0af2&quot;
                 }
             ],
             &quot;success&quot;: true
         }

         &amp;gt;&amp;gt;&amp;gt;ReconnectHost uuid=402f8304a50c410486e023512492316b
         {
             &quot;success&quot;: true
         }

         &amp;gt;&amp;gt;&amp;gt;ReconnectHost uuid=415fa093b34e4a3d873368104b127115
         {
             &quot;success&quot;: true
         }
&lt;/code&gt;&lt;/pre&gt;
</description>
        <pubDate>Wed, 30 Mar 2016 00:00:00 +0800</pubDate>
        <link>http://zstack.org/cn/blog/v1.1.html</link>
        <guid isPermaLink="true">http://zstack.org/cn/blog/v1.1.html</guid>
        
        
        <category>blog</category>
        
      </item>
    
  </channel>
</rss>
